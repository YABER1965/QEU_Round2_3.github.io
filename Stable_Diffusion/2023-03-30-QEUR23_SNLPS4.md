---
title: QEUR23_SNLPS4:　T法(2)による Sentiment Analysis (Yelp_Review、その1)
date: 2023-03-30
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_SNLPS4:　T法(2)による Sentiment Analysis (Yelp_Review、その1)

## ～　ロジット、大胆な前提・・・　～

D先生 ： “前回まで、ナイーブ・ベイズを使ったSentiment Analysisをやってみて見事に失敗しました。まあ、あれは失敗じゃないですけどね。データの持つバイアスが予測結果に反映していました。そこで、今回はロジスティック回帰、しかもT法を使って・・・。こんな不思議な組み合わせにメリットはあるんですか？”

![imageJRL3-14-1](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-1.jpg)

QEU:FOUNDER  ： “根本的なことを言うが、小生は別にsentiment analysisをやりたいわけではないです。Stable_Diffusionのための**prompt_engineering**で使用するツールを開発するための途中経過です。そのツールの設計は、今回のT法(2)によるsentiment analysisの構造に近いんです。文字列なので、説明変数にとても多くの項目数が発生しますが、それでも予測できるでしょ？T法(2)って・・・。”

![imageJRL3-14-2](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-2.jpg)

D先生 ： “少しのデータだけで予測できるのはT法のメリットです。もちろん、ベイズでも同じですが・・・。あとは、**T法(2)には単位空間という「カスタマイズ化の武器」があります**。これが、ナイーブ・ベイズのもつ2つの弱点(↓)を若干でも克服できないか・・・。”

**（交互作用の例文）**

### Positive  : This cuisine is healthy.
### Negative : This cuisine is not healthy.

**（単語の並びの例文）**

### Positive:   銭不是問題。
### Negative:  不、銭是問題。

QEU:FOUNDER ： “「単語の並び」の件はどうにもなりません。でも、**交互作用は何とか少しだけでも助けになる**かもしれません。今回のT法(2)は、データ数を思いっきり減らしますからね。前回みたいに、計算のために長い時間待ちたくもないし・・・。”

D先生 ： “ナイーブベイズって、計算はとても簡単です。しかし、その簡単という意味と計算が速く終わるというのは別の話です。Bag_Of_Wordsファイルを生成するにあたり、データ集計作業が発生しますが、そのための検索作業に時間がかかるんです。コンピュータにとっては四則演算よりもソート作業に時間がかかるんですよね。・・・そういえば、「Bag_Of_Words」という用語について説明していなかったでしたっけ・・・。”

QEU:FOUNDER  ： “**Bag_Of_Words**はナイーブ・ベイズの用語ですよね。”

![imageJRL3-14-3](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-3.jpg)

QEU:FOUNDER  ： “文を構成しているトークンをバラバラにし、それをバックの中に投げ込み、それを集計してデータベースを生成するという意味です。**T法(2)を使っても考え方は同じ**ことになります。。”

D先生 ： “あとはロジスティック回帰なんですが、かなりイレギュラーな方法になるんでしょう？”

![imageJRL3-14-4](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-4.jpg)

QEU:FOUNDER ： “今回、使うのは**「ロジット変換」**だから普通だよ。統計ソフトに載っているロジスティック回帰のシステムはニュートン法などの、もっとややこしい方法をとっています。”

D先生 ： “ロジスティック回帰は応答変数(y)の値を0か1にしているでしょ？今回の場合では、0はnegativeであり、1はpositiveですが・・・。T法でもｙは0と1を扱うんですか？”

QEU:FOUNDER ： “これ以上の説明に関しては、今回のプロジェクトのデータ生成用のプログラムを見ながら話しをしたほうがよいですね。それではプログラムをドン。”

```python
# -----
from fastbook import *
from fastai.text.all import *

# -----
# 生データを読み込む
df_train = pd.read_csv('./yelp_reviews_org_train.csv')      # reviews_with_splits_lite(new)
df_train.head()
```

![imageJRL3-14-5](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-5.jpg)

```python
# -----
# [RAW-DATA]POSITIVE-NEGATIVEに分離する
# NEGATIVE
df_raw_negative = df_train[df_train.label=="negative"]
#df_raw_negative.head()
arr_seq_negative = df_raw_negative.loc[:,"NO"].values
print(arr_seq_negative[0:50])

# POSITIVE
df_raw_positive = df_train[df_train.label=="positive"]
#df_raw_positive.head()
arr_seq_positive = df_raw_positive.loc[:,"NO"].values
print(arr_seq_positive[0:50])
```

![imageJRL3-14-6](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-6.jpg)

QEU:FOUNDER  ： “ここで一旦、解説です。ここでやりたかったことは、**negative文とpositive文のテキストNOのリストの出力**です。”

D先生 ： “テキストNOが0から始まるのがネガティブ群、19600から始まるのがポジティブ群ですね。”

```python
# -----
# [CORPUS]コーパス・データを読み込む
df_corpus = pd.read_csv('./csv_bayes_train_second.csv')      # reviews_with_splits_lite(new)
df_corpus = df_corpus.loc[:, "text":]
df_corpus.head()
```

![imageJRL3-14-7](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-7.jpg)

```python
# -------
# 信号空間: reference NOの2次元マトリックスを生成する
# TextNOのリストを生成する
arr_textNo  = []
# signal-tani分類のリストを生成する
arr_T2Split = []

# Reference-マトリックスを生成する
mx_refNO_signal = np.array([[-1]*20 for i in range(21)])
#print(mx_refNO_signal)

icount_positive = 0
icount_negative = 0
for i in range(0,21):
    for k in range(0,i):
        mx_refNO_signal[i,k] = arr_seq_positive[icount_positive]
        arr_textNo.append(arr_seq_positive[icount_positive])
        arr_T2Split.append("signal")
        icount_positive += 1
    for j in range(i,20):
        mx_refNO_signal[i,j] = arr_seq_negative[icount_negative]
        arr_textNo.append(arr_seq_negative[icount_negative])
        arr_T2Split.append("signal")
        icount_negative += 1
print(mx_refNO_signal)

# -------
# 単位空間: reference NOの2次元マトリックスを生成する
# Reference-マトリックスを生成する
mx_refNO_tani = np.array([[-1]*20 for i in range(10)])
#print(mx_refNO_tani)

for i in range(0,10):
    for j in range(0,20):
        if i < 5:
            mx_refNO_tani[i,j] = arr_seq_positive[icount_positive]
            arr_textNo.append(arr_seq_positive[icount_positive])
            arr_T2Split.append("tani")
            icount_positive += 1
        else:
            mx_refNO_tani[i,j] = arr_seq_negative[icount_negative]
            arr_textNo.append(arr_seq_negative[icount_negative])
            arr_T2Split.append("tani")
            icount_negative += 1
print(mx_refNO_tani)
print("-----------")
print(arr_textNo)
print("-----------")
print(arr_T2Split)
```

![imageJRL3-14-8](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-8.jpg)

D先生 ： “あれ？これは信号空間の設定でしょ？一体、なにをやっているんです？マトリックスの中の数字は？”

QEU:FOUNDER  ： “これは、コーパスの中の文(text)の参照番号です。”

D先生 ： “・・・ということは、マトリックスのように**「文を一つにまとめちゃう」**ということ？”

QEU:FOUNDER  ： “従属変数(y)として確率(0～1)が欲しいんでしょ？じゃあ、以下の計算式が成り立ちます。例えば、p=0.95の場合・・・。”

### 確率 p = 0.95 の場合：　= ( 1 + 1 + … + 1 + 0 ) / 20
### ・・・
### 確率 p = 0.05 の場合：　= ( 1 + 0 + … + 0 + 0 ) / 20

D先生 ： “うわぁ・・・、これは大胆なやりかた・・・。”

QEU:FOUNDER ： “これは**「加法性が成り立つ」**という前提だね。たぶん、これでもいけると思いますよ。また、あえて確率値(p)は使わずに、**それを変換させてロジット値(ω)を使います**。ロジット値を使えば入力文が長くなったとしても、ベイズの時のような悪影響は出にくいです。”

```python
# -------
# 解析用のコーパス・データベースを生成する
df_corpus_first = df_corpus.query('text in @arr_textNo')
df_corpus_first.head()

# -------
# コーパスで使用されている単語集（重複あり）をリスト化する
arr_vocab = df_corpus_first.loc[:,"name"].values
arr_vocab, len(arr_vocab)
#(array(['terrible', 'place', 'work', ..., 'potatoes', 'broccoli', 'alone'], dtype=object), 37789)
```

![imageJRL3-14-9](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-9.jpg)

```python
# -------
# 重複を解消して、ボキャブラリをリスト化する
arr_set_vocab = list(set(arr_vocab)) 
arr_set_vocab[0:10], len(arr_set_vocab)
#3402

```

![imageJRL3-14-10](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-10.jpg)

D先生 ： “解析のために抽出したコーパスの中のトークン数は38万件であり、重複を解消して**ボキャブラリのリストを生成すると3400件**になるんですね。まあ、予測計算に支障がないのであれば扱うデータは小さい方がいいですね。あまりボキャブラリが大きくなっても困ります。”

QEU:FOUNDER  ： “今回やりたいことの概要は分かったでしょう？”

D先生 ： “そりゃ、わかりますよ。単位空間をたくさん設定した（10件）のは、ちょっと意外でしたが・・・。”

QEU:FOUNDER ： “単位空間の差異で、予測値がどれだけ変わるのかに興味があってね。”

D先生 ： “次のステップは「Bag Of Words」データベースの生成ですね。”


## ～　まとめ　～

### ・・・　つづきです　・・・

QEU:FOUNDER ： “ちょっと幻滅するかもしれんが、そもそも「資本」というのはそういうモンかもしれんよ・・・。”

[![MOVIE1](http://img.youtube.com/vi/5s1fN34uN5A/0.jpg)](http://www.youtube.com/watch?v=5s1fN34uN5A "【白井聡 ニッポンの正体】呼び出されるマルクス 〜生きづらさの根源解き明かす「資本論」〜")

QEU:FOUNDER ： “**資本は人間の幸せに関心がない。ただただ、価値増殖するだけ**のモノらしいです。”

![imageJRL3-14-11](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-11.jpg)

C部長 : “あ～あ、本音をいっちゃった・・・。今の若者の夢は**「会社員になること」**なのに・・・。”

QEU:FOUNDER ： “うん・・・。おまけにGPT4も発明され、今後はますます大変になるのにね。”

[![MOVIE2](http://img.youtube.com/vi/L_Guz73e6fw/0.jpg)](http://www.youtube.com/watch?v=L_Guz73e6fw "Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI | Lex Fridman Podcast")

QEU:FOUNDER ： “Lex Fridmanがこんなに重苦しい会話をするのは初めて聞きました。**産業革命以降、最大の「一大事」だから**・・・。”

C部長 : “あまりピンときません・・・。”

[![MOVIE3](http://img.youtube.com/vi/ebls5x-gb0s/0.jpg)](http://www.youtube.com/watch?v=ebls5x-gb0s "Introducing Microsoft 365 Copilot with Outlook, PowerPoint, Excel, and OneNote")

QEU:FOUNDER ： “このシステム(↑)にはGPT4が使われています。この新機能の便利さを見れば、GPT4を産業に応用することがそれだけのポテンシャルをもつのかがわかるでしょう？”

C部長 : “これは便利というか、**もはや革命**です。”

QEU:FOUNDER ： “パワポの進化にはゾッとしました。もし、**「パワポのプロ」という人がいれば失職は確実**だね。”
