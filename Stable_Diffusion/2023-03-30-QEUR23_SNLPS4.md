---
title: QEUR23_SNLPS4:　T法(2)による Sentiment Analysis (Yelp_Review、その1)
date: 2023-03-30
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_SNLPS4:　T法(2)による Sentiment Analysis (Yelp_Review、その1)

### ～　ロジット、大胆な前提・・・　～

D先生 ： “前回まで、**ナイーブ・ベイズを使ったSentiment Analysis**をやってみて見事に失敗しました。まあ、あれは失敗じゃないですけどね。データの持つバイアスが予測結果に反映していました。そこで、今回は**ロジスティック回帰、しかもT法**を使って・・・。こんな不思議な組み合わせにメリットはあるんですか？”

![imageJRL3-14-1](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-1.jpg)

QEU:FOUNDER  ： “根本的なことを言うが、小生は別にsentiment analysisをやりたいわけではないです。Stable_Diffusionのための**prompt_engineeringで使用するツールを開発するための途中経過**です。そのツールの設計は、今回のT法(2)によるsentiment analysisの構造に近いんです。文字列なので、説明変数にとても多くの項目数が発生しますが、それでも予測できるでしょ？T法(2)って・・・。”

![imageJRL3-14-2](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-2.jpg)

D先生 ： “少しのデータだけで予測できるのはT法のメリットです。もちろん、それはベイズでも同じですが・・・。あとは、**T法(2)には単位空間という「カスタマイズ化の武器」**があります。これが、ナイーブ・ベイズのもつ2つの弱点(↓)を若干でも克服できないか・・・。”

**（交互作用の例文）**

### Positive  : This cuisine is healthy.
### Negative : This cuisine is not healthy.

**（単語の並びの例文）**

### Positive:   銭不是問題。
### Negative:  不、銭是問題。

QEU:FOUNDER ： “「単語の並び」の件はどうにもなりません。でも、**交互作用は何とか少しだけでも助けになるかも**しれません。今回のT法(2)はデータ数を思いっきり減らしますからね。前回みたいに計算のために長い時間待ちたくもないし・・・。”

D先生 ： “ナイーブベイズって計算はとても簡単です。しかし、**その簡単という意味と計算が速く終わるというのは別の話**です。Bag_Of_Wordsファイルを生成するにあたり、データ集計作業が発生しますが、そのための**検索作業に時間がかかる**んです。コンピュータにとっては四則演算よりもソート作業に時間がかかるんですよね。・・・そういえば、「Bag_Of_Words」という用語について説明していなかったでしたっけ・・・。”

QEU:FOUNDER  ： “**Bag_Of_Wordsはナイーブ・ベイズの用語です**よね。”

![imageJRL3-14-3](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-3.jpg)

QEU:FOUNDER  ： “文を構成しているトークンをバラバラにし、それをバックの中に投げ込み、それを集計してデータベースを生成するという意味です。**T法(2)を使っても考え方は同じ**になります。。”

D先生 ： “あとはロジスティック回帰なんですが、かなりイレギュラーな方法になるんでしょう？”

![imageJRL3-14-4](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-4.jpg)

QEU:FOUNDER ： “今回、使うのは**「ロジット変換」**だから普通だよ。統計ソフトに載っているロジスティック回帰のシステムはニュートン法などの、もっとややこしい方法をとっています。”

D先生 ： “ロジスティック回帰は応答変数(y)の値を0か1にしているでしょ？今回の場合では、0はnegativeであり、1はpositiveですが・・・。T法でもｙは0と1を扱うんですか？”

QEU:FOUNDER ： “これ以上の説明に関しては、今回のプロジェクトのデータ生成用のプログラムを見ながら話しをしたほうがよいですね。それではプログラムをドン。”

```python
# -----
from fastbook import *
from fastai.text.all import *

# -----
# 生データを読み込む
df_train = pd.read_csv('./yelp_reviews_org_train.csv')      # reviews_with_splits_lite(new)
df_train.head()

```

![imageJRL3-14-5](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-5.jpg)

```python
# -----
# [RAW-DATA]POSITIVE-NEGATIVEに分離する
# NEGATIVE
df_raw_negative = df_train[df_train.label=="negative"]
#df_raw_negative.head()
arr_seq_negative = df_raw_negative.loc[:,"NO"].values
print(arr_seq_negative[0:50])

# POSITIVE
df_raw_positive = df_train[df_train.label=="positive"]
#df_raw_positive.head()
arr_seq_positive = df_raw_positive.loc[:,"NO"].values
print(arr_seq_positive[0:50])

```

![imageJRL3-14-6](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-6.jpg)

QEU:FOUNDER  ： “ここで一旦、解説です。ここでやりたかったことは、negative文とpositive文のテキストNOのリストの出力です。”

D先生 ： “コーパスにおいて、テキストNOが0から始まるのがネガティブ群、19600から始まるのがポジティブ群ですね。”

```python
# -----
# [CORPUS]コーパス・データを読み込む
df_corpus = pd.read_csv('./csv_bayes_train_second.csv')      # reviews_with_splits_lite(new)
df_corpus = df_corpus.loc[:, "text":]
df_corpus.head()
```

![imageJRL3-14-7](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-7.jpg)

```python
# ------
# パラメタの設定
# ------
# 信号空間: reference NOの2次元マトリックスを生成する
# probability　と logistic valueは21水準
arr_prob_signal  = [0.0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,
            0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1.0]
arr_logi_signal  = [-2.0,-1.2787,-0.9542,-0.7533,-0.6020,-0.4771,
            -0.3679,-0.2688,-0.1760,-0.0871,0,0.0871,0.1760,0.2688,
            0.3679,0.4771,0.6020,0.7533,0.9542,1.2787,2.0]
print("len_prob_signal: ",len(arr_prob_signal), " , arr_prob_signal: ",arr_prob_signal)
print("-------")
print("len_logi_signal: ",len(arr_logi_signal), " , arr_logi_signal: ",arr_logi_signal)

```

![imageJRL3-14-8](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-8.jpg)

QEU:FOUNDER  ： “さらにここで中断して解説です。リストの中のこれらの数字(↑)には見覚えはあるでしょ？”

D先生 ： “もちろん、先ほど紹介したロジット変換ですね。”

QEU:FOUNDER  ： “これから、T法(2)でいうところの信号空間と単位空間が形成されていきます。”

```python
# ------
# 単位空間: reference NOの2次元マトリックスを生成する
# probability　と logistic valueは10水準
arr_prob_tani  = [1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0]
arr_logi_tani  = [2.0,2.0,2.0,2.0,2.0,-2.0,-2.0,-2.0,-2.0,-2.0]
print("len_prob_tani: ",len(arr_prob_tani), " , arr_prob_tani: ",arr_prob_tani)
print("-------")
print("len_logi_tani: ",len(arr_logi_tani), " , arr_logi_tani: ",arr_logi_tani)

# ------
# リストの合成
arr_prob  = arr_prob_signal + arr_prob_tani
arr_logi  = arr_logi_signal + arr_logi_tani
print("len_arr_prob: ",len(arr_prob), arr_prob)
print("-------")
print("len_arr_logi: ",len(arr_logi), arr_logi)

# -------
# 信号空間: reference NOの2次元マトリックスを生成する
arr_seqNo   = []    # sequence textNOのリストを生成する
arr_refNo   = []    # reference textNOのリストを生成する
arr_T2Split = []    # signal-tani分類のリストを生成する

# Reference-マトリックスを生成する
mx_refNO_signal = np.array([[-1]*20 for i in range(21)])
#print(mx_refNO_signal)

icount_seq  = 0
icount_positive = 0
icount_negative = 0
for i in range(0,21):
    for k in range(0,i):
        mx_refNO_signal[i,k] = arr_seq_positive[icount_positive]
        arr_refNo.append(arr_seq_positive[icount_positive])
        icount_positive += 1
    for j in range(i,20):
        mx_refNO_signal[i,j] = arr_seq_negative[icount_negative]
        arr_refNo.append(arr_seq_negative[icount_negative])
        icount_negative += 1
    arr_seqNo.append(icount_seq)
    arr_T2Split.append("signal")
    icount_seq += 1       
print(mx_refNO_signal)

```

![imageJRL3-14-9](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-9.jpg)

D先生 ： “あれ？この部分は信号空間の設定に関するモノでしょ？一体、なにをやっているんです？あと、このマトリックスの中の数字群(↑)は、なんです？”

QEU:FOUNDER  ： “これは、コーパスの中の**文(text)の参照番号**です。”

D先生 ： “・・・ということは、このマトリックスのように**「複数の文を一つにまとめちゃう」**ということ？”

QEU:FOUNDER  ： “従属変数(y)として確率(0～1)が欲しいんでしょ？じゃあ、以下の計算式が成り立ちます。例えば、p=0.95の場合・・・。”

- ***確率 p = 0.95 の場合：　= ( 1 + 1 + … + 1 + 0 ) / 20***
- ・・・
- ***確率 p = 0.05 の場合：　= ( 1 + 0 + … + 0 + 0 ) / 20***

D先生 ： “うわぁ・・・、これは大胆なやりかた・・・。”

QEU:FOUNDER ： “これは**「加法性が成り立つ」という前提**だね。たぶん、これでもいけると思いますよ。また、あえて確率値(p)は使わずに、それを変換させて**ロジット値(ω)を使います**。ロジット値を使えば入力文が長くなったとしても、ベイズの時のような悪影響は出にくいです。”

```python
# -------
# 単位空間: reference NOの2次元マトリックスを生成する
# Reference-マトリックスを生成する
mx_refNO_tani = np.array([[-1]*20 for i in range(10)])
#print(mx_refNO_tani)

for i in range(0,10):
    for j in range(0,20):
        if i < 5:
            mx_refNO_tani[i,j] = arr_seq_positive[icount_positive]
            arr_refNo.append(arr_seq_positive[icount_positive])
            icount_positive += 1
        else:
            mx_refNO_tani[i,j] = arr_seq_negative[icount_negative]
            arr_refNo.append(arr_seq_negative[icount_negative])
            icount_negative += 1
    arr_seqNo.append(icount_seq)
    arr_T2Split.append("tani")
    icount_seq += 1   
print(mx_refNO_tani)

# -------
# 信号空間と単位空間の2次元マトリックスを合成する
mx_all = np.concatenate([mx_refNO_signal, mx_refNO_tani], axis=0)
print(mx_all)
print("-----------")
print(arr_seqNo)
print("-----------")
print(arr_T2Split)

```

![imageJRL3-14-10](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-10.jpg)

D先生 ： “もうFOUNDERの考え方に慣れてきました。信号空間のマトリックスと単位空間のそれを結合したわけですね。これが今後の解析で使用するコーパスを形成します。”

QEU:FOUNDER ： “あとは、この参照番号マトリックスをCSVファイルに保存しなきゃね。”

```python
# --------
# マトリックスのコラム名
arr_columns = ['ref{}'.format(i) for i in range(20)] 
print(arr_columns)

# -------
# 信号空間と単位空間の2次元マトリックスを合成する
df_T2Calc = pd.DataFrame(mx_all, columns=arr_columns); df_T2Calc
```

![imageJRL3-14-11](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-11.jpg)

```python
# --------
# データフレームにコラムを追加する
df_T2Calc['seqNo'] = arr_seqNo
df_T2Calc['T2Split'] = arr_T2Split
df_T2Calc['prob']  = arr_prob
df_T2Calc['logi']  = arr_logi
df_T2Calc

# CSVファイルに出力する(Corpus)
df_T2Calc.to_csv("csv_T2Calc.csv")

```

D先生 ： “テキスト参照番号をまとめたデータフレームを、ロジット情報とともにCSVファイルに保存します。**あとでT法(2)の計算をするときのタネになる**のが、このデータフレームになります。”

QEU:FOUNDER ： “あとは、今現在は**300万件**もあるコーパス・データベースを断捨離して、もっと小さくして保存しなきゃね。”

```python
# -------
# 解析用のコーパス・データベースを生成する
df_corpus_first = df_corpus.query('text in @arr_refNo')
df_corpus_first.head()

# -------
# データ数量の変化を比較する
len(df_corpus),len(df_corpus_first)

# CSVファイルに出力する(Corpus for T2 analysis)
df_corpus_first.to_csv("csv_T2Corpus_first.csv")

# -------
# コーパスで使用されている単語集（重複あり）をリスト化する
arr_vocab = df_corpus_first.loc[:,"name"].values
arr_vocab, len(arr_vocab)
#(array(['terrible', 'place', 'work', ..., 'potatoes', 'broccoli', 'alone'], dtype=object), 37789)

```

![imageJRL3-14-12](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-12.jpg)

```python
# -------
# 重複を解消して、ボキャブラリをリスト化する
arr_set_vocab = list(set(arr_vocab)) 
arr_set_vocab[0:10], len(arr_set_vocab)
#3402
```

![imageJRL3-14-13](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-13.jpg)

D先生 ： “解析のために抽出したコーパスの中のトークン数は**38万件**であり、重複を解消して**ボキャブラリのリストを生成すると3400件になる**んですね。まあ、予測計算に支障がないのであれば扱うデータは小さい方がいいですね。あまりボキャブラリが大きくなっても困ります。”

QEU:FOUNDER  ： “今回やりたいことの概要は分かったでしょう？”

D先生 ： “そりゃ、わかりますよ。単位空間をたくさん設定した（10件）のは、ちょっと意外でしたが・・・。”

QEU:FOUNDER ： “**単位空間の差異で、予測値がどれだけ変わるのか**に興味があってね。”

D先生 ： “次のステップは**「Bag Of Words」データベースの生成**ですね。”


## ～　まとめ　～

### ・・・　つづきです　・・・

QEU:FOUNDER ： “ちょっと幻滅するかもしれんが、そもそも「資本」というのはそういうモンかもしれんよ・・・。”

[![MOVIE1](http://img.youtube.com/vi/5s1fN34uN5A/0.jpg)](http://www.youtube.com/watch?v=5s1fN34uN5A "【白井聡 ニッポンの正体】呼び出されるマルクス 〜生きづらさの根源解き明かす「資本論」〜")

QEU:FOUNDER ： “**資本は人間の幸せに関心がない。ただただ、価値増殖するだけ**のモノらしいです。”

![imageJRL3-14-14](/2023-03-30-QEUR23_SNLPS4/imageJRL3-14-14.jpg)

C部長 : “あ～あ、本音をいっちゃった・・・。今の若者の夢は**「会社員になること」**なのに・・・。”

QEU:FOUNDER ： “うん・・・。おまけにGPT4も発明され、今後はますます大変になるのにね。”

[![MOVIE2](http://img.youtube.com/vi/L_Guz73e6fw/0.jpg)](http://www.youtube.com/watch?v=L_Guz73e6fw "Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI | Lex Fridman Podcast")

QEU:FOUNDER ： “Lex Fridmanがこんなに重苦しい会話をするのは初めて聞きました。**産業革命以降、最大の「一大事」だから**・・・。”

C部長 : “あまりピンときません・・・。”

[![MOVIE3](http://img.youtube.com/vi/ebls5x-gb0s/0.jpg)](http://www.youtube.com/watch?v=ebls5x-gb0s "Introducing Microsoft 365 Copilot with Outlook, PowerPoint, Excel, and OneNote")

QEU:FOUNDER ： “このシステム(↑)にはGPT4が使われています。この新機能の便利さを見れば、GPT4を産業に応用することがそれだけのポテンシャルをもつのかがわかるでしょう？”

C部長 : “これは便利というか、**もはや革命**です。”

QEU:FOUNDER ： “パワポの進化にはゾッとしました。もし、**「パワポのプロ」という人がいれば失職は確実**だね。”
