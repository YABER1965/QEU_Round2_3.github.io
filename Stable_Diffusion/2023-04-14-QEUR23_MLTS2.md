---
title: QEUR23_MLTS2:　オリエンテーション(3)～img2imgとCLIPは使いよう
date: 2023-04-14
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_MLTS2:　オリエンテーション(3)～img2imgとCLIPは使いよう

## ～　「彼(CLIP)」は何を見ているのか　～

### ・・・　正直、CLIP-interrogatorよりも良くないかい？　・・・

D先生 ： “さらにオリエンテーションは続きます。**「prompt engineeringは奥深い」**ですねえ・・・。前回と同様に、この人（↓）のコメントから、ドン！”

![imageJRL3-22-1](/2023-04-14-QEUR23_MLTS2/imageJRL3-22-1.jpg)

C部長  ： “**プロンプトは「（人間の）言語」のこと**なんで、奥深いのは当然なんですか・・・。まだ、さらに言うことが残っているとは・・・。”

QEU:FOUNDER  ： “プロンプトの話とは少しだけずれますが、**「CLIP」**について話しましょう。”

**(入力画像)**

![imageJRL3-22-2](/2023-04-14-QEUR23_MLTS2/imageJRL3-22-2.jpg)

**(プロンプトの推定)**

![imageJRL3-22-3](/2023-04-14-QEUR23_MLTS2/imageJRL3-22-3.jpg)

C部長 ： “**CLIP-interrogator**って、以前、AUTOMATIC1111の基本機能として紹介したものですね。画像を与えると適切なプロンプトが与えられるという・・・。”

QEU:FOUNDER  ： “ちなみに、interrogateは「尋問する」という意味です。今回は、CLIP(Contrastive Language–Image Pre-training)機能だけを使ってみましょう。ただし、小生はヘソ曲がりなので、そのままの機能は使わないですけどね。それではプログラムをドン・・・。”

```python
# clip basic for text(hugging face)
import numpy as np
from PIL import Image
import requests

from transformers import CLIPProcessor, CLIPModel

model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# from internet
url = "http://images.cocodataset.org/val2017/000000039769.jpg"
name_image = url
image = Image.open(requests.get(url, stream=True).raw)

# 規定のソフトで画像を閲覧
print(name_image)
image.show()

# テキストを定義する(その1)
arr_text = ["a photo of a cat", "a photo of a dog"]

# テキストを元に認識する
inputs = processor(text=arr_text, images=image, return_tensors="pt", padding=True)

outputs = model(**inputs)
logits_per_image = outputs.logits_per_image # this is the image-text similarity score
probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities
probs

# 結果を出力する
probs = probs.detach().numpy().flatten().tolist()

for i, t in enumerate(arr_text):
    print("NO:{}, text:{} , probability:{}".format(i, t, probs[i]))

```

![imageJRL3-22-4](/2023-04-14-QEUR23_MLTS2/imageJRL3-22-4.jpg)

D先生 ： “まあ、イヌまたはヌコの選択なんで・・・。人間ならば簡単に出てくる結論が計算しても出てくるということですね。”

QEU:FOUNDER  ： “これからが我々のオリジナルになります。プログラムがさらにつづきます。”

```python
# from internal files
#name_image = "genVincentvanGogh-Beeple-image-20230411_100738-SDV14-p0.png"
#name_image = "genVictorNizovtsev-Hokusai-image-20230318_003000-SDV14-p2.png"
#name_image = "genSteveHenderson-Minecraft-image-20230411_121922-SDV14-p1.png"
#name_image = "genSilvestroLega-ClaudeMonet-image-20230411_105623-SDV14-p4.png"
#name_image = "genShannonMaer-FacepunchStudios-image-20230318_003832-SDV14-p3.png"
name_image = "genReylaSlaby-RobertMcCall-image-20230317_233001-SDV14-p4.png"
#name_image = "genRangeMurata-JanStaller-image-20230321_234510-SDV14-p3.png"
#name_image = "genRajaRaviVarma-Minecraft-image-20230319_002718-SDV14-p0.png"
#name_image = "genJimWarren-JeanNouvel-image-20230317_012104-SDV14-p3.png"

image = Image.open("./inputs/" + name_image)

# 規定のソフトで画像を閲覧
print(name_image)
image.show()

# ----
# テキストを定義する(その2)
arr_text = ["a girl", "a woman", "umbrella", "parasol", "hat", "bikini", "wearing sun glass",
            "smiling", "looking at viewer", "blue eye", "brown eye", "cloud", "tree",
            "Claude Monet", "Minecraft", "ukiyoe", "illustration", "Vincent van Gogh"]

# ----
# キーワードを探す
def find_keywords(k, arr_text):

    # テキストを元に認識する
    inputs = processor(text=arr_text, images=image, return_tensors="pt", padding=True)

    outputs = model(**inputs)
    logits_per_image = outputs.logits_per_image # this is the image-text similarity score
    probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities
    #probs

    # 推測結果を出力する
    probs = probs.detach().numpy().flatten()

    for i, t in enumerate(arr_text):
        if probs[i] > 0.01:
            print("ROUND:{}, NO:{}, text:{} , probability:{}".format(k, i, t, round(probs[i],6)))

    # 最大値
    max_value   = np.max(probs)
    max_address = np.argmax(probs)

    return max_value, max_address

for k in [1, 2, 3, 4, 5]:
    print("---- k = {} ----".format(k))
    max_value, max_address = find_keywords(k, arr_text)
    arr_text.remove(arr_text[max_address])
```

![imageJRL3-22-5](/2023-04-14-QEUR23_MLTS2/imageJRL3-22-5.jpg)

QEU:FOUNDER  ： “今回はStable_Diffusionで作った画像を入力してみました。最初は、あのゴッホ先生から行きますよ。今回のロジックでは、単語ごとの重要度（確率）計算のプログラムを数回（今回は5回）回しています。そして、もっとも重要な単語は削除して、もう一回計算するというやり方です。”

C部長 ： “**ゴッホ画伯**・・・、さすがですよねえ。大変な存在感（重要度）だ・・・。”

QEU:FOUNDER  ： “ゴッホやモネは格別としても、全体的にみて画伯の作風というのは影響度が大きかったです。そして、画伯の情報をテキストから除くと、他の要素がかなり拮抗してきます。ここで、他の画像も見てみましょう。”

![imageJRL3-22-6](/2023-04-14-QEUR23_MLTS2/imageJRL3-22-6.jpg)

D先生 ： “画風である「浮世絵」がトップであるとして、「女の子(girl)」と「女性(woman)」の確率値が思ったよりも拮抗するんですね。”

QEU:FOUNDER  ： “この絵を見たとき、girlかwomanか微妙だなと思ってましたが、CLIPさんは正しい判断をしてくれたようです・・・（笑）。このように類似語を敢えて配置して比較するのも重要ですよね。次は、ちょっと「ギミック」をやります。”

![imageJRL3-22-7](/2023-04-14-QEUR23_MLTS2/imageJRL3-22-7.jpg)

D先生 ： “あれ？意外だった・・・。どう見ても、minecraftの強い画風が出ていると思っていたんですが・・・。”

QEU:FOUNDER  ： “人間の眼と機械の眼の間にはじめて不一致が出たね。おそらく、これは**学習過程で発生したもの**と思いますよ。**古いPCのドット画像が学習に入っている**とか・・・。”

D先生 ： “もし本気で計算を駆使して画像を改善したい場合、CLIP-interrogateよりも、この方法の方がいいですね。**類似語の比較もできる**し・・・。”

![imageJRL3-22-8](/2023-04-14-QEUR23_MLTS2/imageJRL3-22-8.jpg)

QEU:FOUNDER  ： “カッコつき**「名作プロンプト」を紹介しているサイトに載っているプロンプトって本当の意味で「良いプロンプト」なのか**？それを検証するのにも良いツールですよ。”

D先生 ： “画像と単語リストを入力して重要度（確率）を確認すれば重要な単語が、そして逆にいらない単語も見えてきますね。まあ、オリエンテーションはここまでにしましょうよ。次は？”

QEU:FOUNDER  ： “NLPについて、Jeremy Howardのレクチャーなどを参考にして、もう少し検討したいと思います。”

D先生 ： “あれ？さらに寄り道ですか・・・。”

![imageJRL3-22-9](/2023-04-14-QEUR23_MLTS2/imageJRL3-22-9.jpg)

QEU:FOUNDER  ： “**LLM（大規模言語モデル）が言語だけのシステムというのは、すでに過去の話**・・・。とうとう**科学分野への応用が来ました**よ。もちろん、我々は昔から来るとは言っていたけどさ・・・。”

![imageJRL3-22-10](/2023-04-14-QEUR23_MLTS2/imageJRL3-22-10.jpg)

QEU:FOUNDER  ： “「枯山水」的手法論で遊んでいる場合じゃないって・・・。”

## ～　まとめ　～

QEU:FOUNDER ： “そういえば、この人（↓）ってあの**「プリンセス・メーカー」のヒト**でしたね・・・。”

[![MOVIE1](http://img.youtube.com/vi/O00g5WV5ysU/0.jpg)](http://www.youtube.com/watch?v=O00g5WV5ysU "【過酷】AI時代の生き方知っとかないとヤバいよ？５年10年先を見ろ！【岡田斗司夫切り抜き】")

C部長 : “ボクも高校生のとき、（ゲームを）やりました！！・・・でも、なんかヘンなゲームでしたね・・・（笑）。”

![imageJRL3-22-11](/2023-04-14-QEUR23_MLTS2/imageJRL3-22-11.jpg)

QEU:FOUNDER ： “その後でT大で伝説的な講師をやったんでしたよね。まあ、すごい人だわ・・・。この人の予測だから、たぶん一考には値するんでしょうけど・・・。”

C部長 : “彼の結論はイヤですよね・・・。”

QEU:FOUNDER ： “前回も言ったが、**「好き嫌いを言うこと」は人間ができて機械ができない重要な側面**です。ここで、再び**実用宗教(LIU:Liberal Arts In Use)**っぽくなってきたな・・・。”

![imageJRL3-22-12](/2023-04-14-QEUR23_MLTS2/imageJRL3-22-12.jpg)

C部長 : “LIU（実用宗教）はすでにボツにした概念でしょ？”

### （LIUの3要素）

- ***Dignity***
- ***Integrity***
- ***Sense of Values***

QEU:FOUNDER ： “昔に設定した3つの概念が今さら重要になって来ました。**この3つがないと、「好き嫌い」も生まれないし、「価値」も生まれない**のです。”

C部長 : “そりゃそうだ・・・。”

QEU:FOUNDER ： “ChatGTPが出て来て、「教育は不要」という人がでてきてます。アホな？そんなことはありえない・・・。**人間が「好き嫌い」を言うには、とてつもなく深い教育**が必要です。それを、**人々は「教養（Liberal Arts）」といいます**。”

