---
title: QEUR23_ATTNS12: SOART 法でメトリックスを作成する(ATTENTIONを始めましょう!)
date: 2023-11-4
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_ATTNS12: SOART 法でメトリックスを作成する(ATTENTIONを始めましょう!)

## ～ SOART3は柔軟なメトリックス ～

C部長 : “それでは、ひきつづきデータのメトリックス化に進めましょう。SOART3法について、オープニングとして少しだけ説明してください。”

QEU:FOUNDER ： “そもそも論として、RT法の説明からですね。今回から、QEUシステムを使う人が出てくるはずですので・・・。RT法というのは、タグチメソッドという手法体系の一つのツールです。その土台になっているのが、「標準SN比」という概念であり、非線形な変動をもつデータに対して、標準信号を与えることで0点比例式に変換します。タグチメソッドでは、多くの場合において、0点比例式の関係式から「感度」と「SN比」という2つのメトリックスを生成します。ちなみに、タグチメソッドなんて言葉は別に覚えないでもよいから・・・（笑）。”

![imageJRL3-52-1](/2023-11-4-QEUR23_ATTNS12/imageJRL3-52-1.jpg)

C部長 : “おやおや・・・。とうとう、**「タグチメソッドなんて言葉は別に覚えないでもよいから・・・（笑）。」**ときましたか・・・。”

QEU:FOUNDER ： “強力なコンピュータ・パワーで信じられない創造力を生み出すGPTらの技術が出てきた「このご時世」において、タグチメソッドは「（笑）」にしかならないって・・・。結局のところ、コンピュータパワーがなくても、かなり良い結果が出るというのが「売り」でしょ？昔は、重宝しました・・・。さてと・・・、RT法で出てくるメトリックスは2つだけです。すごいのは、**何百何千次元のデータを入力しても2つだけしか出て出ません**。この特性はアドバンテージでもあるし、そうでもないかもしれない・・・。”

![imageJRL3-52-2](/2023-11-4-QEUR23_ATTNS12/imageJRL3-52-2.jpg)

C部長 : “「多くの次元数を持った少量のレコ―ド」を使って、統計的な分析ができるのは大きなメリットの一つ・・・。例えば、都道府県のデータを比較をしたいのであれば、他のデータを作りようがないですよね。ただし、他の分野では、コンピュータシミュレーションやファインチューニングなどの技術をつかってデータ生成が容易になってきたら、RT法の出番はなくなるでしょう。RT法をイメージとして説明すれば、標準ベクトルと計測ベクトルを比較し、**「回転成分（感度：β）」**と**「回転後にのこる残差成分（SN比：η）」**になります。さすがに、ここまでくると、RT法はデータのもつ特徴を単純化させすぎています。”

QEU:FOUNDER ： “だから、これが提案されて20年ぐらいたつのにあまり使われていないんです。おそらく、世界でもっともRT法を使い、宣伝しているのは小生かもしれない・・・（笑）。たった3つのメトリックスしか出ないのはあまりにもひどいので、メトリックスを3つにしたのがSOART3です。。”

![imageJRL3-52-3](/2023-11-4-QEUR23_ATTNS12/imageJRL3-52-3.jpg)

C部長 : “「畳み込みを使う」というのも、SOART法に入るんですか？”

QEU:FOUNDER ： “ああ・・・、説明し忘れました。畳み込みの適用もSOARTに入ります（笑）。さっき、「多くの次元数を持った少量のレコ―ド」って説明したでしょ？このようなデータは画像処理分野で頻繁に出てくるんです。ただし、SOARTの3つのメトリックスは、他の分野でも使えます。”

C部長 : “今回の場合は、どのように画像を「料理」するんですか？”

![imageJRL3-52-4](/2023-11-4-QEUR23_ATTNS12/imageJRL3-52-4.jpg)

QEU:FOUNDER ： “こんな「料理法(↑)」です・・・（笑）。あくまで実験なのですがら、最小化して**4分割だけ**にしました。じゃあ、つづいてプログラムの紹介をやりましょう。”

```python
# ---------------- 
# 標準パターンファイルを読み込み、SOARTメトリックスを計算する
# ---------------- 
# 数値計算のﾗｲﾌﾞﾗﾘ読み込み
import math
import numpy as np
import copy, random, time
import pandas as pd
# ----------------
import torch
# ---------------- 
#import matplotlib.pyplot as plt
#%matplotlib inline

#=================================================
# READ Convolutional CSV FILES
#=================================================
# 畳み込み部品パターンファイルを読み込み
def read_partscsv(file_readcsv, part_idx, part_col): 
 
    # ---------------------------
    # 畳み込み部品パターンファイルの読み込み
    df = pd.read_csv(file_readcsv, header=None) 
    # ---------------------------
    # 原因系Xs
    mx_Xs = df.iloc[0:part_idx,0:part_col].values
  
    return mx_Xs

# 計測対象パターンファイルを読み込み
def read_meascsv(file_readcsv, meas_idx, meas_col): 
 
    # ---------------------------
    # 畳み込み部品パターンファイルの読み込み
    df = pd.read_csv(file_readcsv, header=None) 
    # ---------------------------
    # 原因系Xs
    mx_Xs = df.iloc[0:meas_idx,0:meas_col].values
  
    return mx_Xs

#=================================================
# MAIN PRGRAM
#=================================================
# ---------------- 
# パラメータの定義
# ---------------- 
nam_dir = "./soart/"
nam_partdir = "SOART_PARTS/"
nam_subdir1 = "learn/"
nam_subdir2 = "normal/"
nam_subdir3 = "error/"

# ---------------- 
max_cnv_parts = 7

# ---------------- 
code_cnv_input = ['NA']*max_cnv_parts
code_cnv_input[0] = 'bend1'
code_cnv_input[1] = 'bend2'
code_cnv_input[2] = 'bend3'
code_cnv_input[3] = 'bend4'
code_cnv_input[4] = 'line1'
code_cnv_input[5] = 'line2'
code_cnv_input[6] = 'datum'
print(code_cnv_input)

# ---------------- 
# 畳み込み部品
max_cnv_idx = 5
max_cnv_col = 5
# ---------------- 
# 計測対象
max_meas_idx = 30
max_meas_col = 30

# -------------------------------
# 畳み込み用部品(8種類)を読み込む
for i_cnv in range(max_cnv_parts):    # max_cnv_parts
    # -----
    # 畳み込みファイル
    file_cnv_input = nam_dir + nam_partdir + code_cnv_input[i_cnv] + ".csv"  # ファイルパス名の生成 
    #print(file_cnv_input)
    # -----
    mx_conv = read_partscsv(file_cnv_input, max_cnv_idx, max_cnv_col)
    if i_cnv == 0:    
        tsr_bend1 = torch.tensor(mx_conv).float()
    elif i_cnv == 1:
        tsr_bend2 = torch.tensor(mx_conv).float()
    elif i_cnv == 2:
        tsr_bend3 = torch.tensor(mx_conv).float()
    elif i_cnv == 3:
        tsr_bend4 = torch.tensor(mx_conv).float()
    elif i_cnv == 4:
        tsr_line1 = torch.tensor(mx_conv).float()
    elif i_cnv == 5:
        tsr_line2 = torch.tensor(mx_conv).float()
    elif i_cnv == 6:
        tsr_datum = torch.tensor(mx_conv).float()

# -------------------------------
# 畳み込みカーネルを生成する
kernels = torch.stack([tsr_bend1, tsr_bend2, tsr_bend3, tsr_bend4, tsr_line1, tsr_line2, tsr_datum])
print(kernels)

# -------------------------------
# 標準画像を定義する
# -------------------------------
# [単位空間]image_standard
image_nameA = 'image_standard'
#print(arr_nameA)

# -------------------------------
# 学習用画像(image_learn)のリストを生成する
# -------------------------------
# list_learn
list_image = []

# ---
# 学習用-通常(ゆらぎ)
for i in range(50):
    image_nameB = nam_subdir1+'image_base_fluctuate_{}'.format(i)
    list_image.append(image_nameB)

# リストの統合
print(list_image)

#=================================================
# CONVOLUTION FUNCTIONS
#=================================================
# インスタンス化
L1_loss  = torch.nn.L1Loss()
MSE_loss = torch.nn.MSELoss()

# ---------------- 
# 計測位置の定義
arr_str_idx = [0,5,10,15,20,25]
arr_str_col = [0,5,10,15,20,25]

up_str_idx    = [0,5,10]
down_str_idx  = [15,20,25]
left_str_col  = [0,5,10]
right_str_col = [15,20,25]

max_rtm_idx = 3
max_rtm_col = 3

# ---------------- 
# 畳み込み処理を実施する関数
def apply_kernel(kernel, mx_tensor):
    return (mx_tensor * kernel).sum()

# ---------------- 
# データ範囲を切り出すための関数
def cut_DataArea(str_idx, str_col, max_cnv_idx, max_cnv_col, mx_signal):
    return (mx_signal[str_idx:str_idx+max_cnv_idx,str_col:str_col+max_cnv_col])

###################################
# RT METRICS FUNCTIONS
###################################
# 単位空間を生成する
def create_tani(mx_standard): 

    # ---------------- 
    # 単位空間のリストの定義
    acc_tani_up_left    = [] # マトリックスのリスト
    acc_tani_up_right   = [] # マトリックスのリスト
    acc_tani_down_left  = [] # マトリックスのリスト
    acc_tani_down_right = [] # マトリックスのリスト
    arr_tani_up_left    = [] # 畳み込みのリスト
    arr_tani_up_right   = [] # 畳み込みのリスト
    arr_tani_down_left  = [] # 畳み込みのリスト
    arr_tani_down_right = [] # 畳み込みのリスト

    # ---------------- 
    # 単位空間のデータ範囲の抽出、リスト化
    for i in arr_str_idx:
        for j in arr_str_col:
            sign_idx = 'NA'
            sign_col = 'NA'
            mx_cut_tani = cut_DataArea(i, j, max_cnv_idx, max_cnv_col, mx_standard)
            # テンソル化する
            mx_tsr_tani = torch.tensor(mx_cut_tani).float()
            # ---
            if i in up_str_idx:
                sign_idx = 'up'
            else:
                sign_idx = 'down'
            # ---
            if j in left_str_col:
                sign_col = 'left'
            else:
                sign_col = 'right'
            # ---
            # リストへの追加
            if sign_idx == 'up' and sign_col == 'left':
                acc_tani_up_left.append(mx_tsr_tani)
                temp_arr = []
                for k in range(7):
                    temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_tani).item(),3))
                arr_tani_up_left.append(temp_arr)
            # ---
            if sign_idx == 'up' and sign_col == 'right':
                acc_tani_up_right.append(mx_tsr_tani)
                temp_arr = []
                for k in range(7):
                    temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_tani).item(),3))
                arr_tani_up_right.append(temp_arr)
            # ---
            if sign_idx == 'down' and sign_col == 'left':
                acc_tani_down_left.append(mx_tsr_tani)
                temp_arr = []
                for k in range(7):
                    temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_tani).item(),3))
                arr_tani_down_left.append(temp_arr)
            # ---
            if sign_idx == 'down' and sign_col == 'right':
                acc_tani_down_right.append(mx_tsr_tani)
                temp_arr = []
                for k in range(7):
                    temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_tani).item(),3))
                arr_tani_down_right.append(temp_arr)

    ###################################
    # データを束ねて、NUMPY配列に変換する(単位空間：4x63)
    mx_tani_all = []
    # ---
    mx_tani_up_left = np.array(arr_tani_up_left)
    mx_tani_all.append(mx_tani_up_left.flatten())
    # ---
    mx_tani_up_right = np.array(arr_tani_up_right)
    mx_tani_all.append(mx_tani_up_right.flatten())
    # ---
    mx_tani_down_left = np.array(arr_tani_down_left)
    mx_tani_all.append(mx_tani_down_left.flatten())
    # ---
    mx_tani_down_right = np.array(arr_tani_down_right)
    mx_tani_all.append(mx_tani_down_right.flatten())
    # ---
    mx_tani_all = np.array(mx_tani_all)

    return mx_tani_all

# ---------------------------
# 信号空間を生成する
def create_signals(mx_meas): 

    # ---------------- 
    # 信号空間のリストの定義
    acc_signal_up_left    = [] # マトリックスのリスト
    acc_signal_up_right   = [] # マトリックスのリスト
    acc_signal_down_left  = [] # マトリックスのリスト
    acc_signal_down_right = [] # マトリックスのリスト
    arr_signal_up_left    = [] # 畳み込みのリスト
    arr_signal_up_right   = [] # 畳み込みのリスト
    arr_signal_down_left  = [] # 畳み込みのリスト
    arr_signal_down_right = [] # 畳み込みのリスト

    # ---------------- 
    # 信号空間のデータ範囲の抽出、リスト化
    for i in arr_str_idx:
        for j in arr_str_col:
            sign_idx = 'NA'
            sign_col = 'NA'
            mx_cut_signal = cut_DataArea(i, j, max_cnv_idx, max_cnv_col, mx_meas)     # データを切り出す 
            mx_tsr_signal = torch.tensor(mx_cut_signal).float()     # テンソル化する
            # ---
            if i in up_str_idx:
                sign_idx = 'up'
            else:
                sign_idx = 'down'
            # ---
            if j in left_str_col:
                sign_col = 'left'
            else:
                sign_col = 'right'
            # ---
            # リストへの追加
            if sign_idx == 'up' and sign_col == 'left':
                acc_signal_up_left.append(mx_tsr_signal)
                temp_arr = []
                for k in range(7):
                    temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_signal).item(),3))
                arr_signal_up_left.append(temp_arr)
            if sign_idx == 'up' and sign_col == 'right':
                acc_signal_up_right.append(mx_tsr_signal)
                temp_arr = []
                for k in range(7):
                    temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_signal).item(),3))
                arr_signal_up_right.append(temp_arr)
            if sign_idx == 'down' and sign_col == 'left':
                acc_signal_down_left.append(mx_tsr_signal)
                temp_arr = []
                for k in range(7):
                    temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_signal).item(),3))
                arr_signal_down_left.append(temp_arr)
            if sign_idx == 'down' and sign_col == 'right':
                acc_signal_down_right.append(mx_tsr_signal)
                temp_arr = []
                for k in range(7):
                    temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_signal).item(),3))
                arr_signal_down_right.append(temp_arr)

    ###################################
    # データを束ねて、NUMPY配列に変換する(信号空間：4x63)
    mx_signal_all = []
    # ---
    mx_signal_up_left = np.array(arr_signal_up_left)
    mx_signal_all.append(mx_signal_up_left.flatten())
    # ---
    mx_signal_up_right = np.array(arr_signal_up_right)
    mx_signal_all.append(mx_signal_up_right.flatten())
    # ---
    mx_signal_down_left = np.array(arr_signal_down_left)
    mx_signal_all.append(mx_signal_down_left.flatten())
    # ---
    mx_signal_down_right = np.array(arr_signal_down_right)
    mx_signal_all.append(mx_signal_down_right.flatten())
    # ---
    mx_signal_all = np.array(mx_signal_all)

    return mx_signal_all


# ---------------------------
# soaRT(3 items version)メトリックスを計算する
def calc_soaRT3(L1_loss, MSE_loss, tsr_sig_array, tsr_tani_array): 

    # ---------------------------
    # テンソル化
    y = torch.tensor(tsr_sig_array).float()
    x = torch.tensor(tsr_tani_array).float()

    # 回転を計測(BETA)
    xx = torch.dot(x,x) + 0.0001
    xy = torch.dot(x,y) + 0.0001
    beta = xy/xx

    # ユーグリッド距離(GAMMA) 
    gamma = MSE_loss(y, beta*x)
    
    # マンハッタン距離(ITA)
    mDistance   = L1_loss(y, beta*x)
    #print("mDistance: ", mDistance.item())
    
    # 値の対数変換（及び補正）
    log_beta  = math.log(beta.item())
    log_distance = math.log(mDistance.item()+1)
    log_gamma = 0.5*math.log(gamma.item()+1) - log_distance
    
    return round(log_beta,3), round(log_distance,3), round(log_gamma,3)


# ---------------------------
# 畳み込みテンソルイメージを生成する
def create_tsrConv(L1_loss, MSE_loss, mx_tani, mx_signal):

    # ----
    # 初期化
    arr_btY1 = []
    arr_snY2 = []
    arr_gmY3 = []

    # ----
    # パネルスコアを線形化する
    for i in range(4):

        tani_array   = mx_tani[i,:]
        signal_array = mx_signal[i,:]
        # soaRT(3 items version)メトリックスを計算する
        btY1, snY2, gmY3 = calc_soaRT3(L1_loss, MSE_loss, signal_array, tani_array)
        arr_btY1.append(btY1)
        arr_snY2.append(snY2)
        arr_gmY3.append(gmY3)

    return np.array(arr_btY1),np.array(arr_snY2),np.array(arr_gmY3)


# ==================================================
# MAIN ROUTINE
# ==================================================
# ---------------------------
# 標準画像を読み込む
# ---------------------------
# [単位空間]畳み込みファイル
file_standard_input = nam_dir + image_nameA + ".csv"  # ファイルパス名の生成 

# -----
# [単位空間]結果の表示
mx_standard = read_partscsv(file_standard_input, max_meas_idx, max_meas_col)

# -----
# 単位空間を生成する
mx_tani = create_tani(mx_standard)

# ---------------------------
# 学習用画像(image_learn)を読み込む
# ---------------------------
# 読み込み画像の数(image_learn)
max_images = 50

# 初期化
mx_btY1 = np.zeros((max_images,4))
mx_snY2 = np.zeros((max_images,4))
mx_gmY3 = np.zeros((max_images,4))

# <max_images>件の信号空間を読み込み
for i in range(max_images):

    # [信号空間]計測ファイル
    file_meas_input = nam_dir + list_image[i] + ".csv"  # ファイルパス名の生成 
    print(file_meas_input)

    # -----
    # [信号空間]学習用画像の結果の表示（mx_meas）
    mx_meas = read_meascsv(file_meas_input, max_meas_idx, max_meas_col)

    # -----
    # 信号空間を生成する
    mx_signal = create_signals(mx_meas)

    # ---------------------------
    # 畳み込みRTイメージを生成する
    # ---------------------------
    arr_btY1, arr_snY2, arr_gmY3 = create_tsrConv(L1_loss, MSE_loss, mx_tani, mx_signal)
    # データを追加する
    mx_btY1[i] = arr_btY1
    mx_snY2[i] = arr_snY2
    mx_gmY3[i] = arr_gmY3
# ---
print("--- arr_btY1 ---")
print(mx_btY1)
print("--- arr_snY2 ---")
print(mx_snY2)
print("--- arr_gmY3 ---")
print(mx_gmY3)


# -----
# CSVデータを出力する
# -----
# dataframeに変換
df_btY1 = pd.DataFrame(mx_btY1)
df_snY2 = pd.DataFrame(mx_snY2)
df_gmY3 = pd.DataFrame(mx_gmY3)

# CSVファイルに出力
df_btY1.to_csv('learn_btY1.csv', index=False)
df_snY2.to_csv('learn_snY2.csv', index=False)
df_gmY3.to_csv('learn_gmY3.csv', index=False)

```

QEU:FOUNDER ： “結果は、こんな簡単な結果になります。”

![imageJRL3-52-5](/2023-11-4-QEUR23_ATTNS12/imageJRL3-52-5.jpg)

C部長 : “あらら・・・。1枚の画像が、たった４つの数字に・・・（笑）。”

![imageJRL3-52-6](/2023-11-4-QEUR23_ATTNS12/imageJRL3-52-6.jpg)

QEU:FOUNDER ： “4つのデータというのは、画像を4分割しているということです。あと、SOART３には3種類のメトリックスがありますからね。”

C部長 : “これをつかって、ATTENTIONをやる。”

QEU:FOUNDER  ： “いよいよ、ATTENTIONの計算に行きましょう！是非、カンパをお願いします！！”

### [＞寄付のお願い(click here)＜](<iframe width="560" height="315" src="https://www.youtube.com/embed/9NVQnJu23Mo?si=MZIRhc0RwThRO5EQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>)
 
 
D先生 ： “よろしくお願いします。”


## ～ まとめ ～

D先生(設定年齢65歳) ： “今回は特にいいたいこともないので、ふらふらとXなどを見てたんですが・・・。 なんか、いい話題はないですか？“

![imageJRL3-52-7](/2023-11-4-QEUR23_ATTNS12/imageJRL3-52-7.jpg)

QEU:FOUNDER(設定年齢65歳) ： “こんな映画（↓）ができたらしいよ・・・。すごいと思わん？”

![imageJRL3-52-8](/2023-11-4-QEUR23_ATTNS12/imageJRL3-52-8.jpg)

D先生 ： “よくわからんが、ビンビン来ます。なんだろ？コレ・・・。 **昭和ではブラスのエネルギーに、人々が押しつぶされ・・・。**“

QEU:FOUNDER ： “**令和では負のエネルギーに押しつぶされる・・・。**まあ、本当に（この映画が）面白いのか知らんが、すごい共感があるよね。世界に充満する負のエネルギー。こんなの（↓）とか・・・。”

![imageJRL3-52-9](/2023-11-4-QEUR23_ATTNS12/imageJRL3-52-9.jpg)

D先生 ： “もっと、ひどくなるとこうなる（↓）・・・。 “

![imageJRL3-52-10](/2023-11-4-QEUR23_ATTNS12/imageJRL3-52-10.jpg)

QEU:FOUNDER ： “たしかに政治家（↑）のコメントにも問題はあるが、それ以上に、政治家から**「こんなもんだと思われている人々」**に対して負のエネルギーを感じる。”

[![MOVIE1](http://img.youtube.com/vi/9NVQnJu23Mo/0.jpg)](http://www.youtube.com/watch?v=9NVQnJu23Mo "増税？ダメ♡絶対！デモ in 横浜 山本太郎代表 2023年11月2日")

C部長 ： “あれ？放送事故か？ “

D先生 ： “そういえば、FOUNDERは最近、このイケメン（↑）の動画を見なくなりましたね。“

QEU:FOUNDER ： “このイケメンに対してはすごい正のパワーを感じるが、なぜかわからんが周辺に負のエネルギーを感じるんだよね。結論としては、見たいとは思わん。”

D先生 ： “う～ん、その感じには同意。不思議なんだよなァ・・・。 “

QEU:FOUNDER ： “これがJ国の問題の本質なんですよ。社会に負のエネルギーが充満しており、さらに人々がすでにそれに対して心地よく感じているんです。”

D先生 ： “確かに、全政党にプラスのエネルギーを感じない。さらには、そのマイナス・エネルギーが高いほど、それに人々が引き寄せられる・・・。もう大人気！ “

C部長 ： “なんか、う〇こに群がるハエみたい・・・。“

QEU:FOUNDER ： “C部長、このコメントはNGです。反省するように・・・。さて、これは本当にまじめなアドバイスです。「イケメン」に対してね・・・。彼は、この人（↓）を師匠にしたほうが良い。”

![imageJRL3-52-11](/2023-11-4-QEUR23_ATTNS12/imageJRL3-52-11.jpg)


D先生 ： “だれ？この人？ “

QEU:FOUNDER ： “とある外国で、とても人気がある風水師です。実は、風水師でもないが・・・。若い時に、西洋占星術を学びにクロアチアに留学したり、インドで修行もしていたんです。彼女が長年の修行で得た結論は、**「人間はプラス・エネルギー（正能量）を持たねばならない」**ということです。”

C部長 ： “この人、人気があるの・・・？“

D先生 ： “ある地域では、人気がとてつもなくすごいらしいです。今、調べました。あと、すごい大金持ちらしいです。あと、自分でお寺をもっており、頻繁に慈善事業をしているらしいです。 “

QEU:FOUNDER ： “そう。**慈善事業は、「正のエネルギー」を得る秘訣の一つ**だからね。ほんとに、まじめなアドバイスです。イケメンの党は、J国の党で唯一のプラスのエネルギーを持つようになってほしい。そのエネルギーは、政策の研究で得られるものじゃないですよ。小生がまた動画を見るくらいに正のエネルギーを持てば、彼は天下を取るんじゃないでしょうか。”

