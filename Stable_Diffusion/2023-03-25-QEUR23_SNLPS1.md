---
title: QEUR23_SNLPS1:　閑話休題～Fast.aiによるText-Generation (：NLP, Yelp Review, その2)
date: 2023-03-25
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_SNLPS1:　閑話休題～Fast.aiによるText-Generation (：NLP, Yelp Review, その2)

## ～　あの、「今、話題のあのテクノロジの基礎」です　～

D先生 ： “さて、今回は**「自然言語分析(Natural Language Processing)」の閑話休題**をやります。うわさの**Chat-GPT**に関してですね。あんなすごいシステムを、我々がここで作っちゃうんですか？”

QEU:FOUNDER  ： “我々が作れるのかどうかを、**Chat-GPT**に質問してみましょう。”

![imageJRL3-11-1](/2023-03-25-QEUR23_SNLPS1/imageJRL3-11-1.jpg)

D先生 ： “すると、RNNとかいうものを自作すればできるんでしょうかねぇ・・・。ただ、あれは**強化学習(RLHF)**も使っているという話を聞いています。”

QEU:FOUNDER  ： “じゃあ、もう少し質問してみましょう。”

![imageJRL3-11-2](/2023-03-25-QEUR23_SNLPS1/imageJRL3-11-2.jpg)

QEU:FOUNDER ： “一言でいうと、GPTのシステム自体は強化学習の要素はない。ただし、対話を高度にするためには強化学習を使ったほうがよいそうですね。”

D先生 ： “じゃあ、安心して「GPTごっこ」できますね。”

![imageJRL3-11-3](/2023-03-25-QEUR23_SNLPS1/imageJRL3-11-3.jpg)

QEU:FOUNDER ： “あくまで「ごっこ」だからね。今回は**軽量の言語データを使いますが、それでも40MBもあります**。ちなみに、これは前回の分析につかったレストランの口コミ情報(Yelp_Review)のデータです。それでは、Fast.aiのプログラムをドン！！”

```python
# -----
from fastbook import *
from IPython.display import display,HTML
from fastai.text.all import *

df = pd.read_csv('./reviews_with_splits_lite(new).csv')      # reviews_with_splits_lite(new)
df.head()

```

QEU:FOUNDER  ： “最初は、簡単にCSVファイルからデータフレーム情報を取り出します。”

![imageJRL3-11-4](/2023-03-25-QEUR23_SNLPS1/imageJRL3-11-4.jpg)

D先生 ： “今回はラベル、test-train情報は使うんですか？”

QEU:FOUNDER ： “次のトークン化のためにTextだけを使います。今回の分析は教師あり学習なのに、**y(従属変数)が何なのか**がわかりにくいですが、実は**「RNN独特の再帰構造」**になっています。”

```python
# -----
# 1行のコードでこのデータを含むDataBunchを作成することができます：
path = './'
data_lm = TextDataLoaders.from_df(df, path=path, text_col='text', label_col='label', is_lm= True, valid_pct=0.1, bs=64)

# -----
data_lm.show_batch(max_n=3)

```

QEU:FOUNDER  ： “それではCSVファイルのtext文をトークンの集まりに変換した結果を見てみましょう。ただし、同時にRNN学習のための特殊なXとYの構造に変換されていることに気を付けて・・・。”

![imageJRL3-11-5](/2023-03-25-QEUR23_SNLPS1/imageJRL3-11-5.jpg)

QEU:FOUNDER  ： “**RNNは「ある文章を入力して、その次に出てくる単語を予測」します。**”

D先生 ： “あれ？xやyの中に変な記号(xxbosなど)が見られます。”

QEU:FOUNDER  ： “これは、**Fastaiが開発したTokenizer**が取り決めた特殊記号です。そこらへん、詳しくは自分でしらべてください。ただし、その概要だけを知りたいのならば、以下のプログラムを実行すれば一目瞭然です。”

```python
# -----
# fastaiは次に、Tokenizerクラスでトークン化処理にいくつかの追加機能を追加します。
spacy = WordTokenizer()
tkn = Tokenizer(spacy)
coll_repr(tkn('&copy;   Fast.ai www.fast.ai/INDEX'), 31)

```

D先生 ： “ん・・・、このプログラムを動かすと・・・。”

![imageJRL3-11-6](/2023-03-25-QEUR23_SNLPS1/imageJRL3-11-6.jpg)

D先生 ： “なるほど。こうなるわけですね・・・（笑）。”

QEU:FOUNDER ： “このデータをRNN学習器(Learner)に入力します。”

```python
# -----
# Fine-Tuning the Language Model
# 学習済みモデルの埋め込みは、学習済み語彙にない単語に対してランダムに追加される埋め込みとマージされます。
# これはlanguage_model_learnerの内部で自動的に処理されます。
learn = language_model_learner(
    data_lm, AWD_LSTM, drop_mult=0.3, 
    metrics=[accuracy, Perplexity()]).to_fp16()

# -----
# fine_tuneはそれをやってくれないのでfit_one_cycleを使います。
# cnn_learnerと同様、language_model_learnerはプリトレーニングモデルを使用する場合（デフォルト）、
# 自動的にfreezeを呼び出すので、これは埋め込み（ランダムに初期化された重みを含むモデルの唯一の部分、
# つまりIMDbボキャブにあるがプリトレーニングモデルのボキャブにない単語に対する埋め込み）だけを学習させます。
learn.fit_one_cycle(1, 2e-2)

# -----
# 初期学習が完了したら、凍結解除後にモデルの微調整を続けることができます。
learn.unfreeze()
learn.fit_one_cycle(10, 2e-3)
```

QEU:FOUNDER  ： “・・・しまった。オリジナルのfast.aiのコース課題と同様に10回学習したのだが、ちょっと多すぎた。実際には8回で十分でした。”

![imageJRL3-11-7](/2023-03-25-QEUR23_SNLPS1/imageJRL3-11-7.jpg)

D先生 ： “Accuracyの値の推移からみると、そう判断できますね。まあ、そんなこと、あらかじめにはわからないんだからしょうがない。でも、予測的中率が30％というのは、それほど悪くはないです。”

QEU:FOUNDER  ： “このRNN学習器の特徴を生かせば、冒頭の句を与えれば、残りの分を予測することができます。それでは、今回のレストランの口コミDBのデータを使ってText Generationをやってみましょう。”

```python
# -----
# Text Generation (1)
# このモデルを使ってランダムなレビューを生成してみます。
# このモデルは文の次の単語を推測するように訓練されているので、このモデルを使って新しいレビューを書くことができます。
TEXT = "I liked this Chinese food because"
N_WORDS = 40
N_SENTENCES = 2
preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) 
         for _ in range(N_SENTENCES)]
print("\n".join(preds))

```

QEU:FOUNDER  ： “まずは、あの人気のC国料理から・・・。ポジティブな表現が出力できるように冒頭句を設定しました。”

D先生 ： “さらに、文字数は40個だけ、文を2つ出力できるようにしました。”

![imageJRL3-11-8](/2023-03-25-QEUR23_SNLPS1/imageJRL3-11-8.jpg)

D先生 ： “文の構造自体は自然ですが、はたしてこれは(料理を)誉めているのかそれとも・・・(笑)。”

QEU:FOUNDER ： “学習にはデータを50000レコードぐらい入力しましたが、各センテンスが短いので**総情報量が足らない**んでしょうね。次は、皆さまがお好きな「おフレンチ」を・・・”

```python
# -----
# Text Generation(2)
TEXT = "I liked this French food because"
N_WORDS = 40
N_SENTENCES = 2
preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) 
         for _ in range(N_SENTENCES)]
print("\n".join(preds))

```

![imageJRL3-11-9](/2023-03-25-QEUR23_SNLPS1/imageJRL3-11-9.jpg)

QEU:FOUNDER  ： “この返答は、C華料理の返答よりもまとまっているかな？”

D先生 ： “こんなに簡単にコメントを作ることができるんですか？じゃあ、このシステムがおもしろいので、J国料理の場合も同様にやってみましょう。”

```python
# -----
# Text Generation(3)
TEXT = "I liked this Japanese food because"
N_WORDS = 40
N_SENTENCES = 2
preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) 
         for _ in range(N_SENTENCES)]
print("\n".join(preds))

```

![imageJRL3-11-10](/2023-03-25-QEUR23_SNLPS1/imageJRL3-11-10.jpg)

QEU:FOUNDER  ： “文にはなっているが、ちょっと何を言っているのかわからない・・・（笑）。”

D先生 ： “スシは出てきますが、オレンジ・チキンとは？まあ、取りあえずはおもしろいのでヨシとします。このシステムが、あのCHAT-GXTの中に入っているんですか？”

QEU:FOUNDER ： “そうらしいよ・・・。もちろん、こんなに簡単なロジックじゃないですからね。”

D先生 ： “本来の我々のターゲットは**sentiment analysis**をやることじゃなかったでしたっけ？”

QEU:FOUNDER ： “今回のシステムでも、sentiment analysisができます。すごい高性能なのがね・・・。ただし、我々がやりたいT法(2)を応用したシステムとは全く違うのでベースラインとしては不適当です。”

D先生 ： “次は、もっとシンプルなsentiment analysisをやってみたいですね。”

QEU:FOUNDER  ： “じゃあ、その方向で次回につづく・・・。”



## ～　まとめ　～

QEU:FOUNDER ： “この前我々が話題にしたら、いきなり、こんな話(↓)がでてきましたね。”

![imageJRL3-11-11](/2023-03-25-QEUR23_SNLPS1/imageJRL3-11-11.jpg)

C部長 : “また**「自分は変わらない」**をやったの？まぁ・・・、自己愛の激しいお年頃でしょうからね。”

![imageJRL3-11-12](/2023-03-25-QEUR23_SNLPS1/imageJRL3-11-12.jpg)

QEU:FOUNDER ： “こういう考え方が社会に蔓延していますね。”

[![MOVIE1](http://img.youtube.com/vi/AKT8wCM522E/0.jpg)](http://www.youtube.com/watch?v=AKT8wCM522E "三浦瑠麗氏、夫逮捕で会社でスタッフ共々ヤケクソ酒盛り。その上、自身の逮捕について否定せず。")

C部長 : “そういえば、聖書に**「自分を愛するように、あなたの隣人を愛しなさい」**という言葉があるって知っていました？普通は、「隣人を愛しなさい」しか知られていませんが・・・。”

![imageJRL3-11-13](/2023-03-25-QEUR23_SNLPS1/imageJRL3-11-13.jpg)

QEU:FOUNDER ： “コレはマタイ（福音書）にあるんだよね。小生の好きなヨハネにはなかった。これは意外・・・。”

C部長 : “深い、深い、宗教のお話でした・・・。”

