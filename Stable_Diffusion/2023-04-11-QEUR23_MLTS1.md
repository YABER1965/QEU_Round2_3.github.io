---
title: QEUR23_MLTS1:　オリエンテーション(2)～Prompt Engineering as “Software 3.0
date: 2023-04-11
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_MLTS1:　オリエンテーション(2)～Prompt Engineering as “Software 3.0

## ～　評価メトリックスの有用性　～

### ・・・　またまた深いんです（鼎談の続き）　・・・

D先生 ： “前回のオリエンテーションの続きです。何しろ、この「prompt engineeringは奥深い」んで・・・。この人（↓）のコメントをドン！”

![imageJRL3-21-1](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-1.jpg)

C部長  ： “なんと**「ソフトウェア3.0」**といいますか・・・。それにしても、T社のヒトの話を引用元がM社って？”

QEU:FOUNDER  ： “これがA国の実情なんです。技術的な情報を高度に共有しながら競争しています。一社だけでは今起きていること（ある種の革命）を理解するには力不足であることを実感しているんだろうね。それでは、prompt engineering(PE)について、さらにもうちょっと雑談を深めましょう。最近、G社がダメダメだと言われていますが、実は小生はそうは思ってなくって・・・。”

![imageJRL3-21-2](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-2.jpg)

C部長 ： “「ダメダメ」って、自分のところのBOTの評判が良くないですからね。例えば、このTwitterのQ&A(↑)の出来なんかは無茶苦茶じゃないですか？5月がMayuaryなんて聞いたことがない・・・。”

[![MOVIE1](http://img.youtube.com/vi/Mds8Bgfm1Vs/0.jpg)](http://www.youtube.com/watch?v=Mds8Bgfm1Vs "ChatGPTの競合大本命「Google Bard」が期待外れで世界中がガッカリしてる件")

QEU:FOUNDER  ： “ちなみに本件の引用はこの動画（↑）です。でも、小生は逆に「驚愕」しました、**「なんてすごいモノをG社が作った」**んだって・・・。なんと、ヒトでもない**「AIが造語をしている」**んです。一般にはNLP（自然言語処理）の生成AIは造語をしません。なぜなら、その言語学習のためには文章データを分解する必要があり、トークン(token)という区切り(単位)を自分で設定しています。そして、ほとんどの場合にはトークンは単語の大きさに等しくなるんです。だから、我々が期待したアウトプットをしなかった（単語で分解しない）というのが、逆にすごいことに・・・。”

![imageJRL3-21-3](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-3.jpg)

D先生 ： “ああ・・・。この論文も「あいつら（G社）」が作ったのか・・・。”

C部長 ： “たぶん、あいつらはすごいモノを作りすぎて「飼いならす」のに「てこずっている」んだ・・・。”

QEU:FOUNDER  ： “まあ、C部長の「飼いならす」というのは、OpenAI流にいえば、「RLHF（Reinforcement Learning with Human Feedback）」というよね。さて、我々が攻めていきたい分野は「ソコ」じゃないから・・・。さてと、またStable_Diffusionに戻りましょう。以前やった実験をもう一度みてみましょうか。”

**（アーティストを1人だけ使ったプロンプト）**
***prompt   = '(1girl in style of {0}:1.3),standing,looking at viewer,　beach, などなど’***

**(アーティストを2人使ったプロンプト)**
***prompt   = '((1girl:1.3),blue eye,in style of {0},standing,looking at viewer), (beach, in style of {1}:1.1),　などなど '***

QEU:FOUNDER  ： “（ポジティブ）プロンプトを1人から2人に変えてみました。まあ、そうすると驚く結果が・・・。”

![imageJRL3-21-4](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-4.jpg)

D先生 ： “たくさん実験（作画）をやったが、ほとんどで同じ傾向がみられました。1人のアーティストを入力したら、8歳程度の少女が出て来て、しかも申し訳ないが画像がつまらなかった・・・（笑）。しかし、2人のアーティストに変更すると、画像がトンでもなく「華やか」になったんですよね。中には、芸術品レベルのものもありました。”

QEU:FOUNDER  ： “この原因はいくつか考えられます。１つはアーティストの交互作用が、とてつもないプラス側（良い絵を描く）の作用で存在すること・・・。ベースのプロンプトは「girl(人物) on the beach(風景)」ですが、アーティストを人と物に同時に「紐づけ」すると効果が得られない。ちなみに、「1girl on the beach」って出力させてみたことはあったっけ？”

D先生 ： “ありますよ・・・。1アーティストのプロンプトを使った例に近くなります。もちろん、もっとひどい状況になりえます。中にはnsfw(not suitable for work)のものも・・・。”

QEU:FOUNDER  ： “これひとつ見ても、Stable_Diffusion（画像生成AI）にはChatBOTにはない独特のPrompt Engineeringのノウハウがあるんです。だから、あのKaggleもあえて大々的にコンペを開くわけで・・・。”

![imageJRL3-21-5](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-5.jpg)

D先生 ： “賞金が全然安いですが・・・(笑)。”

QEU:FOUNDER  ： “ここまでが前回のおさらいプラスアルファ（+α）かな・・・。今回は、Stable_Diffusionのプロンプト解析について、すこしだけ深い議論をしましょう。ChatGPTとStable_Diffusionのprompt_Engineering上の難しさの差異は記号論で説明できます。”

![imageJRL3-21-6](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-6.jpg)

QEU:FOUNDER  ： “Stable_Diffusionの場合、フィニシアンであるpromptから画像の形でフィニシエが生成されるわけです。Chat.BOTでは、それが送り手と受け手の間で抽象化されているわけで・・・。翻訳の分野における「言葉の通じなさ」の背景にこれ（↑）があります。”

D先生 ： “一方、Stable_Diffusionの場合には2つの要素（フィニシアンとフィニシエ）がダイレクトに結合されており、その分、最適化のための解析がしやすいですね。”

![imageJRL3-21-7](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-7.jpg)

QEU:FOUNDER  ： “どの言語でも類似語がたくさんあるよね。でも、**その中でもそれぞれニュアンスがあるからプロンプトに入れると表示される画像が変わってきます**。だから、それでもSDのPEは結構難しいよ・・・。とくに、英語以外を母国語にしている人にとっては・・・。”

D先生 ： “フン、しやすいといっても、「できるとは言っていない」・・・（笑）。もうそろそろ、なにか技術的なことをやってみましょうか・・・。Kaggleのコンペでは、結果の良し悪しは**「コサイン類似度（距離）で評価します」**と書いていますね。あれ？なんでしょうかね？”

![imageJRL3-21-8](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-8.jpg)

QEU:FOUNDER  ： “議論するにあたり、**「評価技術から入る」のは「より品質的」でステキ**ですね（笑）。さて、それに関して面白いサイトを見つけました。著者（↑）がつくったPythonコードが公開されていたので、それを一部だけ使って遊んでみましょう。”

![imageJRL3-21-9](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-9.jpg)

D先生 ： “コサイン類似度って、そんなにスゴイものだったっけ・・・。”

![imageJRL3-21-10](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-10.jpg)

QEU:FOUNDER  ： “あの**G社様が作ったTransformer**というNLPが関係しているらしいよ。単純なベクトルの比較のわけがないじゃん。”

![imageJRL3-21-11](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-11.jpg)

D先生 ： “すいません、ちょっとやってみたい検証実験が・・・。ひょっとしたら、1Artistのプロンプトにおいて、つまんない画像しか出ないのは、**「ワードオーダー(word order:語彙の並び)」の影響がある**のでは？”

```python
# original
# girl , solo, standing, beach, looking at viewer, high quality, blue eye, twintail, in style of James Guthrie

# order changed
# girl , solo, in style of James Guthrie, standing, beach, looking at viewer, high quality, blue eye, twintail

```

QEU:FOUNDER  ： “じゃあ、上記2種類のプロンプトを用意して実験をやってみましょうか。プログラムを行きます。ドン！！”

```python
# Setup (run this once)
!pip install -q transformers ftfy regex tqdm

import torch
from torch.nn import CosineSimilarity
from transformers import CLIPTokenizer, CLIPModel, CLIPTextModel
from torch.nn.functional import normalize

# ---
torch_device = "cuda" if torch.cuda.is_available() else "cpu"

cossim = CosineSimilarity(dim=0, eps=1e-6)

def dist(v1, v2):
    return float(cossim(v1, v2))

def get_embeddings(prompts, torch_device="cpu"):
    text_inputs = tokenizer(prompts, padding="max_length", return_tensors="pt").to(torch_device)
    text_embeddings = torch.flatten(text_encoder(text_inputs.input_ids.to(torch_device))['last_hidden_state'],1,-1)

    return text_embeddings

def calculate_similarities(main_prompt, terms, torch_device):
    prompts = [main_prompt] + [main_prompt.replace(t, "") for t in terms]

    text_embeddings = get_embeddings(prompts, torch_device)

    similarities = [
        (term, dist(text_embeddings[0], text_embeddings[i1 + 1]))
        for i1, term in enumerate(terms)
    ]
    sorted_similarities = sorted(similarities, key=lambda x: x[1])

    return sorted_similarities

def display_similarities(main_prompt, terms, torch_device):
  similarities = calculate_similarities(main_prompt, terms, torch_device)
  for term, similarity in similarities:
    print(f"{term}: {similarity:.2f}")

def compare_prompts(base_prompt, prompt2, torch_device):
  text_embeddings = get_embeddings([base_prompt, prompt2], torch_device)
  return dist(text_embeddings[0], text_embeddings[1])

def batch_compare(base_prompt, prompts, torch_device):
  all_prompts = [base_prompt] + prompts
  text_embeddings = get_embeddings(all_prompts, torch_device)
  base_embedding = text_embeddings[0]
  other_embeddings = text_embeddings[1:]
  scores = [(embedding, dist(base_embedding, embedding)) for embedding in other_embeddings]
  
  return scores

def fmt_score(val):
  return f"{val:.2f}"

# Select a clip model to use to calculate similarities
model_name = "clip-vit-large-patch14" #@param ["clip-vit-base-patch16", "clip-vit-base-patch32", "clip-vit-large-patch14"]
models = [ 
    'openai/clip-vit-base-patch32',
    'openai/clip-vit-base-patch16',
    'openai/clip-vit-large-patch14',
]

model_id = f"openai/{model_name}"

tokenizer = CLIPTokenizer.from_pretrained(model_id)
text_encoder = CLIPTextModel.from_pretrained(model_id).to(torch_device)
model = CLIPModel.from_pretrained(model_id).to(torch_device)

# ワードオーダーが変わるとどうなるか
# 全体的な差異の把握
prompt = "girl, solo, standing, beach, looking at viewer, high quality, blue eye, twintail, in style of James Guthrie" 
alternate_prompt = "girl, solo, in style of James Guthrie, standing, beach, looking at viewer, high quality, blue eye, twintail"
similarity = compare_prompts(prompt, alternate_prompt, torch_device)
print(f"The cosine similarity is {fmt_score(similarity)}. It's clear that these two prompts are very far apart in latent space.")

# 意味のない語彙を追加する
prompt = "girl, solo, standing, beach, looking at viewer, high quality, blue eye, twintail, in style of James Guthrie" 
alternate_prompt = "girl, solo, standing, beach, looking at viewer, high quality, blue eye, twintail, in style of James Guthrie, www"
similarity = compare_prompts(prompt, alternate_prompt, torch_device)
print(f"The cosine similarity is {fmt_score(similarity)}. Added word is meaningless for image crea-tion.")

```

![imageJRL3-21-12](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-12.jpg)

QEU:FOUNDER  ： “まずはワードオーダーを敢えて変えた2つのプロンプトを比較しました。**「コサイン類似度が0.76である」**という数字がでました。ただし、その数字の評価ができないので次の実験をしました。”

D先生 ： “ベースのプロンプトの後ろに**意味のない「www」という単語を追加**しました。その時の**類似度は0.96**です。これをベースラインとして比較すると、ワードオーダー変更の影響が0.76というのはかなり大きな数字です。”

QEU:FOUNDER  ： “次は、単語別の影響を比較しましょう。”

```python
## 分解して語句の重要度を把握する(1)
# オーダーはオリジナル
prompt = "girl, solo, standing, beach, looking at viewer, high quality, blue eye, twintail, in style of James Guthrie"
terms = ["girl", "solo", "standing", "beach", "looking at viewer", "high quality", "blue eye", "twin-tail", "in style of James Guthrie"]
display_similarities(prompt, terms, torch_device)

```

![imageJRL3-21-13](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-13.jpg)

QEU:FOUNDER ： “この単語別の評価法は、当該の単語(term)を外したプロンプトを使って画像生成に影響があるのかをコサイン類似度で評価しました。つまり、この数字が小さくなればなるほど、その単語の重要度が大きくなります。”

D先生 ： “我々がプロンプトの後ろにつなげた場合には、スタイル指定の重要度が高い（ワードあるなしの画像への影響が大きい）とはいえません。それでは、次にワードオーダーを変えてみましょう。”

```python
## 分解して語句の重要度を把握する(2)
# 無駄を追加しました
alternate_prompt = "girl, solo, standing, beach, looking at viewer, high quality, blue eye, twintail, in style of James Guthrie, www"
terms = ["girl", "solo", "standing", "beach", "looking at viewer", "high quality", "blue eye", "twin-tail", "in style of James Guthrie"]
display_similarities(alternate_prompt, terms, torch_device)
```

![imageJRL3-21-14](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-14.jpg)

```python
## 分解して語句の重要度を把握する(3)
# オーダーを変更しました
alternate_prompt = "girl, solo, in style of James Guthrie, standing, beach, looking at viewer, high quality, blue eye, twintail"
terms = ["girl", "solo", "standing", "beach", "looking at viewer", "high quality", "blue eye", "twin-tail", "in style of James Guthrie"]
display_similarities(alternate_prompt, terms, torch_device)

```

![imageJRL3-21-15](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-15.jpg)

D先生 ： “**スタイル指定の重要度が一気にあがりました**ね。私の推理はアタリでしょ（笑）？”

QEU:FOUNDER  ： “なるほど、スタイルを使うときには気をつけないといけないですね。プロンプトは深いよねえ・・・。”


## ～　まとめ　～

QEU:FOUNDER ： “「あの技術（↓）」の影響はすごいよね。社会的な影響がデカいだろうなぁ・・・。それでも、生産性向上のための強力なツールだから、これを使わないと（競争に）負けるからなァ・・・。”

[![MOVIE2](http://img.youtube.com/vi/dTg9Q88VnDI/0.jpg)](http://www.youtube.com/watch?v=dTg9Q88VnDI "【ChatGPTがもたらす悲劇の結末】『全人類は補欠化する』完全解説編総まとめ【岡田斗司夫】")

C部長 : “もう使うしか選択肢がないのであれば、**より「楽しく使う」しかない**でしょうね。ちなみに、言っている自分でも「楽しく使う」って意味が分かりませんが・・・（笑）。”

![imageJRL3-21-16](/2023-04-11-QEUR23_MLTS1/imageJRL3-21-16.jpg)

QEU:FOUNDER ： “**ヤツ（AI）らが不得意な部分を攻めて人類の価値をより高めるしかない**んでしょうね。その動きが実際に世界的にあるわけで・・・。あとね・・・、肉体労働以外にも、我々にはヤツらには苦手な「必殺技」があります。”

C部長 : “なんですか？”

QEU:FOUNDER ： “**「好き嫌いを言うこと」**は、人間ができて機械ができない重要な側面です。”

C部長 : “たしかに、その側面はヤツらにはできないでしょうね。でも、そのアドバンテージは経済には有効に作用するのでしょうか・・・。**最新技術(イノベーション)で経済的にメリット（GDPが上がる）こと**は、世の中がおかしくならないための必須の条件でしょう。”

[![MOVIE3](http://img.youtube.com/vi/7sDwOpxJ4V0/0.jpg)](http://www.youtube.com/watch?v=7sDwOpxJ4V0 "経済学者・水野和夫氏出演！ 「世界経済・ニッポン経済の行方と資本主義の現在」")

QEU:FOUNDER ： “そのための一番良い方法の一つは、**人間が「好き嫌いをベースとしてモノをつくる」ということ**です。”

C部長 : “そんなことできるの？”

QEU:FOUNDER ： “それを、今、我々がやろうとしているわけね。”

