---
title: QEUR23_ATTNS12: SOART 法でメトリックスを作成する(ATTENTIONを始めましょう!)
date: 2023-11-4
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_ATTNS13: SOART メトリックスからATTENTIONを計算する（異常分析）

## ～ まだまだ発展途上のATTENTIONメトリックスだが・・・ ～

QEU:FOUNDER ： “さあ、SOART3メトリックスのデータが出来たのでATTENTIONを計算してみましょう。実行する前に2つ、ちょっと「注意事項」をば・・・。”

![imageJRL3-53-1](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-1.jpg)

C部長 : “おやおや・・・。なんですか・・・。”

QEU:FOUNDER ： “今回のATTENTION応用シリーズの冒頭で紹介した以下の比喩を思い出してください。ATTENTIONとは**「コンクールの採点作業」**です。”

![imageJRL3-53-2](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-2.jpg)

C部長 : “Q,K,Vの3つのマトリックスが、多くの人々を「？（はてな）」とさせるのですが、この3種のマトリックスの中に**「審査員が詰まっている」**と考えてればいいんですね。”

![imageJRL3-53-3](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-3.jpg)

QEU:FOUNDER ： “あとは、小生がこれから公開するプログラムを使う前に、JB先生のATTENTIONのプログラムを使ってみてください。より、ATTENTIONがわかりやすくなりますよ。”

C部長 : “JB先生のプログラムだけではわかりにくいですか？”

QEU:FOUNDER ： “あのプログラムはQ,K,Vマトリックスの中の数字を乱数で設定しているんです。あれでは、アテンションの**「特定のものに注目(Attention)する」**という意味は体感できますが、「なぜATTENTION値がそうなるのか」という詳細は分かんないです。”

C部長 : “今回のプログラムは、Q,K,Vマトリックスの中に何を入れているのですか？”

QEU:FOUNDER ： “SOART3では、うまいことに3種類のメトリックスが出てくるでしょう？だから、QKVそれぞれに、そのメトリックス（Y1,Y2,Y3）を当てはめたわけです。本件は、今回のAttentionプログラムの本質になるので、プログラムの紹介の後に議論しましょう。それでは、プログラムを紹介します。”

```python
# ---------------- 
# SOARTメトリックスを読み込み、ATTENTIONメトリックスを計算する
# ---------------- 
# 数値計算のﾗｲﾌﾞﾗﾘ読み込み
import fastbook
import math
import numpy as np
import copy, random, time
import pandas as pd
#import matplotlib.pyplot as plt
#%matplotlib inline

#=================================================
# READ image CSV FILES
#=================================================
# データの種類
# (学習用) : learn_btY1, learn_snY2, learn_gmY3
# (検証用) : valid_btY1, valid_snY2, valid_gmY3
# ---------------------------
# 画像csvファイルを読み込み
def read_partscsv(file_readcsv): 
 
    # ---------------------------
    # 画像csvファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    #print(df)
    # ---------------------------
    # 原因系Xsマトリックス
    mx_Xs = df.loc[:,"X0":"X3"].values
    #print("----- mx_Xs:{0} -----".format(file_readcsv))
    #print(mx_Xs)
  
    return mx_Xs

# -----
# DB引用先
#list_learn = ['learn_btY1_class', 'learn_snY2_class', 'learn_gmY3_class']
list_learn = ['learn_btY1_gs_ab', 'learn_snY2_gs_ab', 'learn_gmY3_gs_ab']
list_valid = ['valid_btY1_gs', 'valid_snY2_gs', 'valid_gmY3_gs']

# -----
# 学習用データベース(list_learn)
# -----
# query
file_learn = list_learn[0] + ".csv"  # ファイルパス名の生成 
#print(file_learn)
mx_query = read_partscsv(file_learn)
# 統計値の生成
val_meanY1 = np.mean(mx_query)
val_maxY1  = np.max(mx_query)
val_minY1  = np.min(mx_query)
# 正規化
mx_query = (mx_query - val_minY1) / (val_maxY1 - val_minY1)*2
# 転置
mx_query_T = mx_query.transpose()
print("--- mx_query_T ---")
print(mx_query_T)
# -----
# key
file_learn = list_learn[1] + ".csv"  # ファイルパス名の生成 
mx_key = read_partscsv(file_learn)
# 統計値の生成
val_meanY2 = np.mean(mx_key)
val_maxY2  = np.max(mx_key)
val_minY2  = np.min(mx_key)
# 正規化
mx_key = (mx_key - val_minY2) / (val_maxY2 - val_minY2)*2
# 転置
mx_key_T = mx_key.transpose()
print("--- mx_key_T ---")
print(mx_key_T)
# -----
# value
file_learn = list_learn[2] + ".csv"  # ファイルパス名の生成 
mx_value = read_partscsv(file_learn)
# 統計値の生成
val_meanY3 = np.mean(mx_value)
val_maxY3  = np.max(mx_value)
val_minY3  = np.min(mx_value)
# 正規化
mx_value = (mx_value - val_minY3) / (val_maxY3 - val_minY3)*2
# 転置
mx_value_T = mx_value.transpose()
print("--- mx_value_T ---")
print(mx_value_T)

# -----
# 学習用データベースをさらに補正する
# -----
max_row = mx_value.shape[0]
max_col = mx_value.shape[1]
for i in range(max_row):
    for j in range(max_col):
        # Q
        if mx_query[i,j] < 0.5:
            mx_query[i,j] = 0
        else:
            mx_query[i,j] = mx_query[i,j] ** 2.0
        # K
        if mx_key[i,j] < 0.5:
            mx_key[i,j] = 0
        else:
            mx_key[i,j] = mx_key[i,j] ** 2.0
        # V
        if mx_value[i,j] < 0.5:
            mx_value[i,j] = 0
        else:
            mx_value[i,j] = mx_value[i,j] ** 2.0
# 表示
#print(mx_query)
#print(mx_key)
#print(mx_value)
# 転置
mx_query_T = mx_query.transpose()
print(mx_query_T)
mx_key_T = mx_key.transpose()
print(mx_key_T)
mx_value_T = mx_value.transpose()
print(mx_value_T)

```

QEU:FOUNDER ： “この学習データを保管する部分で、かなりの「特殊な処理」をしています。”

![imageJRL3-53-4](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-4.jpg)

C部長 : “確かに、**要素の値を２乗**していますし、0値もたくさんあります。そもそも、以下のような変な式（↓）がありますね。”

```python
# 正規化
mx_value = (mx_value - val_minY3) / (val_maxY3 - val_minY3)*2

```

C部長 : “「正規化」とは言っていますが、これは**全部の値をプラスにするための処理**ですよね。マトリックスにマイナス値があるって、だめですかねえ・・・。”

![imageJRL3-53-5](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-5.jpg)

QEU:FOUNDER ： “JB先生のデモ用のプログラムでは、全てのマトリックス要素の数字が0以上かつ3以下になっていたでしょう？今回は、その範囲に数字が収まるようにしました。あと、その後の値を2乗することにより、要素間の変化が激しくなるようしました。”

C部長 : “よくわかりました。”

```python
# -----
# 検証用データベース(list_valid)
# -----
# query
file_valid = list_valid[0] + ".csv"  # ファイルパス名の生成 
#print(file_valid)
mx_query_valid = read_partscsv(file_valid)
# 正規化
mx_query_valid = (mx_query_valid - val_minY1) / (val_maxY1 - val_minY1)
#print(mx_query_valid)
# -----
# key
file_valid = list_valid[1] + ".csv"  # ファイルパス名の生成 
mx_key_valid = read_partscsv(file_valid)
# 正規化
mx_key_valid = (mx_key_valid - val_minY2) / (val_maxY2 - val_minY2)
#print(mx_key_valid)
# -----
# value
file_valid = list_valid[2] + ".csv"  # ファイルパス名の生成 
mx_value_valid = read_partscsv(file_valid)
# 正規化
mx_value_valid = (mx_value_valid - val_minY3) / (val_maxY3 - val_minY3)
#print(mx_value_valid)

# -----
# 検証用データベースをさらに補正する
# -----
max_row = mx_value_valid.shape[0]
max_col = mx_value_valid.shape[1]
for i in range(max_row):
    for j in range(max_col):
        # Q
        if mx_query_valid[i,j] < 0.3:
            mx_query_valid[i,j] = 0
        else:
            mx_query_valid[i,j] = mx_query_valid[i,j] ** 2.0
        # K
        if mx_key_valid[i,j] < 0.3:
            mx_key_valid[i,j] = 0
        else:
            mx_key_valid[i,j] = mx_key_valid[i,j] ** 2.0
        # V
        if mx_value_valid[i,j] < 0.3:
            mx_value_valid[i,j] = 0
        else:
            mx_value_valid[i,j] = mx_value_valid[i,j] ** 2.0
# 表示
print(mx_query_valid)
print(mx_key_valid)
print(mx_value_valid)

# ----------
# input data(WORDS) SETUP
from numpy import array
from numpy import random
from numpy import dot
from scipy.special import softmax

acc_words = []
for i in range(3):
    if i == 0:
        acc_words.append(mx_query_valid)
    if i == 1:
        acc_words.append(mx_key_valid)
    if i == 2:
        acc_words.append(mx_value_valid)
print(acc_words)

# ----
# CALCULATION OF ATTENTIONS
# ----
acc_att = []
for i in range(3):

    # ----------
    # INPUT(WORDS)を読み込み
    words = acc_words[i]

    # ----------
    # CALCULATION OF ATTENTION
    # generating the weight matrices
    #W_Q = mx_query_T
    #W_K = mx_key_T
    W_Q = mx_value_T    # mxvalue -> gamma値
    W_K = mx_query_T    # mxquery -> 感度(beta値)
    W_V = mx_key_T      # mxkey -> SN比(ita値)

    # generating the queries, keys and values
    Q = words @ W_Q
    K = words @ W_K
    V = words @ W_V

    # scoring the query vectors against all key vectors
    scores = Q @ K.transpose()

    # computing the weights by a softmax operation
    weights = softmax(scores / K.shape[1] ** 0.5, axis=1)

    # computing the attention by a weighted sum of the value vectors
    attention = weights @ V
    for row in range(30):
        for col in range(10):
            attention[row,col] = round(attention[row,col],5)
    acc_att.append(attention.tolist())
    
# ----
# 生データを出力する 
acc_att = np.array(acc_att)
#print(acc_att)
# ----
# 結果を分割して、見やすく出力する
# ----
for i in range(3):
    attention_out = acc_att[i]
    print("---- NORMAL ----")
    print(attention_out[0:10])
    # ----
    print("---- ERROR(A) ----")
    print(attention_out[10:20])
    # ----
    print("---- ERROR(B) ----")
    print(attention_out[20:30])

```


QEU:FOUNDER ： “ここまでATTENTIONの生の値が出力されます。”


**（Y1を入力したときの、NORMAL-ERRORA）**

![imageJRL3-53-6](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-6.jpg)

**（Y1を入力したときの、ERRORB）**

![imageJRL3-53-7](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-7.jpg)

**（Y2を入力したときの、NORMAL-ERRORA）**

![imageJRL3-53-8](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-8.jpg)


**（Y2を入力したときの、ERRORB）**

![imageJRL3-53-9](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-9.jpg)

**（Y3を入力したときの、NORMAL-ERRORA）**

![imageJRL3-53-10](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-10.jpg)

**（Y3を入力したときの、ERRORB）**

![imageJRL3-53-11](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-11.jpg)

C部長 : “なるほど、これは「コンクールの採点作業」ですね。整数値レベルのマクロからと、マトリックスには**学習データのメンバ毎の特徴がでています**。それにしても、計測データ毎の差異って小さいんですね。”

QEU:FOUNDER ： “審査員の特徴を現すマクロ・レベルの変動は消してしまっても良いと思いますよ。”

C部長 : “そうですね。そういえば、ちょっと質問があります。プログラムを見ていて、ちょっとヘンに思ったものですから・・・。”

```python
    # ----------
    # CALCULATION OF ATTENTION
    # generating the weight matrices
    #W_Q = mx_query_T
    #W_K = mx_key_T
    W_Q = mx_value_T    # mxvalue -> gamma値
    W_K = mx_query_T    # mxquery -> 感度(beta値)
    W_V = mx_key_T      # mxkey -> SN比(ita値)
```

C部長 : “せっかく当てはめたQ,K,Vマトリックスを変えちゃったじゃないですか？”

QEU:FOUNDER ： “よいところに気が付いたね。これは試行錯誤の過程なのだが、敢て残しておいた。Q->Y3(γ), K->Y1(β), V->Y2(η)というのがもっともバランスがいいと思ったんです。”

![imageJRL3-53-12](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-12.jpg)

QEU:FOUNDER ： “強化学習を使ってメトリックス間の相関を把握したときがあったでしょ？Y2とY3には相関が必ずあるわけです。ATTENSIONの計算ロジックから言えば、KをY1にするのが最もよいバランスになると考えたわけです。ただし、他の組み合わせを試してみても構いませんよ。”

C部長 : “わかりました。”

```python
# ----
# 結果を分割して、見やすく出力する(その2)
# ----
# 出力された結果を補正する
acc_att2 = []
for i in range(3):
    attention2 = acc_att[i,:,:]
    for j in range(10):
        attention2[:,j] = attention2[:,j] - np.mean(attention2[:,j])
        attention2[:,j] = attention2[:,j] / (np.max(attention2[:,j]) - np.min(attention2[:,j]))
    for row in range(30):
        for col in range(10):
            attention2[row,col] = round(attention2[row,col],4)
    acc_att2.append(attention2.tolist())
# numpy配列化
acc_att2 = np.array(acc_att2)
# ----
# 出力する
# ----
for i in range(3):
    attention2 = acc_att2[i]
    print("---- Y{} ----".format(i+1))
    print("[Y{}]---- NORMAL ----".format(i+1))
    print(attention2[0:10,:])
    print("[Y{}]---- ERROR(A) ----".format(i+1))
    print(attention2[10:20,:])
    print("[Y{}]---- ERROR(B) ----".format(i+1))
    print(attention2[20:30,:])
```


QEU:FOUNDER ： “以下のような3次元リスト（マトリックス）が出力されました。”


**（Y1を入力したときの、NORMAL-ERRORA）**

![imageJRL3-53-13](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-13.jpg)

**（Y1を入力したときの、ERRORB）**

![imageJRL3-53-14](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-14.jpg)

QEU:FOUNDER ： “まずは、Y1（感度：β）を入力した値の補正結果を見てみて、どう思いますか？”

D先生: “補正した後の方が、はるかにわかりやすいです。生データでは、各学習メンバ毎に大きな値の差がありました。しかし、その大きな差異を除いてみると計測対象毎の差がでてきます。補正後では、どの学習メンバでも、どれでも傾向に大きな差があるわけじゃないですね。ERROR(A)とERROR(B)の差異は明確ですが、それらとNORMALの差は明確ではないようです。”

QEU:FOUNDER ： “そのような結果になるのは、NORMALの中間的な特性上、しようがないですね。つづく、Y2(SN比：η)を入力した結果を見てみましょう。”

**（Y2を入力したときの、NORMAL-ERRORA）**

![imageJRL3-53-15](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-15.jpg)

**（Y2を入力したときの、ERRORB）**

![imageJRL3-53-16](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-16.jpg)

C部長 : “Y2値(SN比)を入れたときには、Y1の場合よりも、だいぶん判別が容易になりましたね。”

QEU:FOUNDER ： “そうですね。それでは、最後にY3(ガンマ値)でやってみましょう。ただし、特殊なメトリックスなので、判別用には個人的にはあまり期待していないが・・・。”

**（Y3を入力したときの、NORMAL-ERRORA）**

![imageJRL3-53-17](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-17.jpg)

**（Y3を入力したときの、ERRORB）**

![imageJRL3-53-18](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-18.jpg)

C部長 : “あらあら・・・。**Y3値の入力では全く判別できない**や・・・。”

QEU:FOUNDER ： “このメトリックスは、図形の輪郭を見ているものではなく、もっと細かな状態を見るんです。ですから、このメトリックスを入力しても判別精度はあがりません。”

![imageJRL3-53-19](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-19.jpg)

QEU:FOUNDER ： “以上のAttentionの分析は、3種類の図形の判別です。もう一度見てみましょう。人間であるならば、簡単な判別問題なのに、これを数学にやらせると途端に難しくなる・・・。最後にまとめとして、簡単な特徴量の抽出をやってみましょう。学習メンバ毎のデータがほとんど変わらないため、以下のようにMIN-MAXでまとめることができます。”

```python
# ----
# 結果を分割して、見やすく出力する(その2)
# ----
# 出力された結果を補正する
acc_att2 = []
for i in range(3):
    attention2 = acc_att[i,:,:]
    for j in range(10):
        attention2[:,j] = attention2[:,j] - np.mean(attention2[:,j])
        attention2[:,j] = attention2[:,j] / (np.max(attention2[:,j]) - np.min(attention2[:,j]))
    for row in range(30):
        for col in range(10):
            attention2[row,col] = round(attention2[row,col],4)
    acc_att2.append(attention2.tolist())
# numpy配列化
acc_att2 = np.array(acc_att2)
# ----
# 出力する
# ----
for i in range(3):
    attention2 = acc_att2[i]
    print("---- Y{} ----".format(i+1))
    print("[Y{}]---- NORMAL ----".format(i+1))
    print(attention2[0:10,:])
    print("[Y{}]---- ERROR(A) ----".format(i+1))
    print(attention2[10:20,:])
    print("[Y{}]---- ERROR(B) ----".format(i+1))
    print(attention2[20:30,:])
```


QEU:FOUNDER ： “列は、Y1のmax-min、Y2のmax-min、そしてY3のmax-minを表します。”

**（NORMAL群）**

![imageJRL3-53-20](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-20.jpg)

**（ERROR-A群）**

![imageJRL3-53-21](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-21.jpg)

**（ERROR-B群）**

![imageJRL3-53-22](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-22.jpg)

C部長 : “ERROR(A)群は、単純なしきい値の導入にて識別可能ですね。あとのNormal-Error(B)の間は、重なり合っており複雑な関係になっています。もちろん、全てのデータをディープラーニングやSVMなどの手法に入力して処理すればやれないことはないです。”

![imageJRL3-53-23](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-23.jpg)

QEU:FOUNDER ： “現時点の判別能力が低い根本的な問題は、「グレースケールを使っている」からだと思うよ。少なくとも、この手法の良し悪しはＲＧＢで議論しないと決着できないです。”

D先生: “ATTENTIONって、難しいことをやっている割には計算はとても簡単です。でも、「これ一発」で識別できるのはすごいですね。コンピュータによる外観検査は技術的・コスト的にハードルが高かったですが、ATTENTIONを使えばRaspberry Piでも負荷的に全然OKになります。・・・それにしても、Q,K,Vマトリックスの中には、どのようなメンバを入れたのですか？”

![imageJRL3-53-24](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-24.jpg)

D先生: “品質管理では異常だけを検出すればいいので、Q,K,Vには正常群だけをいれればいいです。もし、より細かな判別をしたければ、いろいろな（ERROR）群を入れる必要がありますね。”

QEU:FOUNDER ： “「Raspberry Piを使った外観検査」どころか、「Raspberry Piを使ったリアルタイム外観検査」が可能です。さて、今回のQKVは正常群のみを採用しています。つまり、メンバには少量のゆらぎを加えた正常な画像が９つ入っています。”

D先生: “今回は9つの画像をQ,K,Vに入れた根拠は？”

QEU:FOUNDER ： “（メンバ数の根拠は）ないよ・・・。例えば、QKVに4つのデータを導入してATTENTIONを動かすことも、理屈上は十分に可能です。”

C部長 : “なんという簡単な方法なんだ！！たった４つの画像で学習できるなんて！！！”

QEU:FOUNDER  ： “まあ、そこまで「小躍り」せんでもよろしい・・・（笑）。RGBデータを使って評価しないと、本当のところはわからないんだから・・・。これが今回の発明の概要です！是非、カンパをお願いします！！”

### [＞寄付のお願い(click here)＜](<iframe width="560" height="315" src="https://www.youtube.com/embed/9NVQnJu23Mo?si=MZIRhc0RwThRO5EQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>)
 
 
D先生 ： “皆さん！発明ですよ！！ご検討をよろしくお願いします。”


## ～ まとめ ～

D先生(設定年齢65歳) ： “マイナスのエネルギーを議論していると、なんと政治の話になってしまいました。 それにしても、近年のなんとなく「マイナス感覚」ってなんなんでしょうね？逆にいうと、「プラス」とは？“

![imageJRL3-53-25](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-25.jpg)

QEU:FOUNDER(設定年齢65歳) ： “「何かをやりたい」という気持ちがプラスであり、**「報われたい（または、あやかりたい）」というのがマイナス**だと思うよ。別に、それらには「良し・悪し」があるわけじゃなくて、このプラスとマイナスが循環することで世の中が回っているんです。”

![imageJRL3-53-26](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-26.jpg)

QEU:FOUNDER ： “昭和にはプラスのエネルギーが充満していたんですよね。いまでも、アニメやコンテンツの世界には「何かをやりたい」が残っています。だから、あの業界は今でも「すごい」。”

D先生 ： “でも、今の世の中には「べつにやりたいことはない（プラスでもマイナスでもない：ゼロ）」というのが「大多数」じゃないですか？ “

QEU:FOUNDER ： “たしかに「大勢」だよね。それでも、それらの「ゼロ」を資源としてモノを生み出す技術というのがあるんだ。それが、**世にいう「管理」**です。”

[![MOVIE1](http://img.youtube.com/vi/lasZw_ArkJs/0.jpg)](http://www.youtube.com/watch?v=lasZw_ArkJs "院内集会「日本の没落」―登壇：内田樹氏（神戸女学院大学名誉教授）")

QEU:FOUNDER ： “もし、野球チームの全員が「大谷」、「イチロー」、「松井」だったら・・・。こんなチームに監督はいると思う？”

D先生 ： “そりゃそうだ。“

### おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」

### オッサン（＠車中、N社検査不正について）： 「“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ・・・」

### オッサン（海外工場のあいさつにて）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」

QEU:FOUNDER ： “問題は、平成の時代にその「ありがたき管理様」がマイナス・エネルギーを吐き散らしながら、世の中を回してきたことなんです。”

D先生 ： “う～ん。でも、**その「管理様」って、結局は「報われたい」・「あやかりたい」人たちの群れ**だったわけでしょ？ “

![imageJRL3-53-27](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-27.jpg)

QEU:FOUNDER ： “あ～あ・・・。改めて問いたい、管理とは何か？そして、品質とは？昔、あるQC大会にて、お偉い品質コンサルタント様が大会後の総評として「このお言葉（↓）」を語り、小生はひっくり返るほど驚いたんだよね。”

### おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」


D先生 ： “なんだ、FOUNDERは、いままで「ある人から聞いた話」と言っていましたが、聞いたのは本人だったわけですね。思わず怒りくるったでしょ？このセリフ（↑）を聞いたときに？“

![imageJRL3-53-28](/2023-11-10-QEUR23_ATTNS13/imageJRL3-53-28.jpg)

QEU:FOUNDER ： “思わず、このイラスト（↑）を思い出したね（笑）。ただし、この彼のコメントがQEUシステムを15年たってもつづいている原動力になっているんだ。”

D先生 ： “本当に感謝しなければならないですね。この大先生（↑）に・・・。 “

QEU:FOUNDER ： “アホなことを言うな！このマイナス・エネルギーが何人の人間をボロボロにしたと思う？悪い品質だけでは人は大してﾀﾋなないんですよ。むしろ、良い品質を実現するために「良くないやり方」を社会で推進する過程で、大変に大きな犠牲を払うんです。”
