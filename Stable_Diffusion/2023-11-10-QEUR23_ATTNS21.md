---
title: QEUR23_ATTNS21: SOART メトリックスからATTENTIONを計算する(判別分析用verB)
date: 2023-11-10
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_ATTNS21: SOART メトリックスからATTENTIONを計算する(判別分析用verB)

## ～ ひょっとして、「Q」に問題があったか？ ～

QEU:FOUNDER ： “C部長、良い動画があるので、ちょっと見てください。いままで、我々はQをgamma値にしていたが、ひょっとしてQを他に入れ替えなければならないと思っています。”

[![MOVIE1](http://img.youtube.com/vi/FFoLqib6u-0/0.jpg)](http://www.youtube.com/watch?v=FFoLqib6u-0 "【深層学習】忙しい人のための Transformer と Multi-Head Attention【ディープラーニングの世界 vol.29 】")

C部長 : “すんません。ボクは数式を見ると、「さぶいぼ」が出ます（笑）。”

QEU:FOUNDER ： “我々はあくまで「ユーザ」なので、むずかしい理解なんかはなしで「ノリだけ」でいいですよ。そもそも、**なぜAttentionはQ,K,VのすべてにベクトルXを掛ける**のか？具体的に言うと図にあらわされる**「フォーク状」記号**のことです。”

![imageJRL3-61-1](/2023-11-10-QEUR23_ATTNS21/imageJRL3-61-1.jpg)

C部長 : “そう言われてみると・・・。やっぱり、わけがわかりませんね（笑）。”

QEU:FOUNDER ： “この先生の線形数学に対する解釈というのは簡単です。**行列の役割は（ベクトル）の回転であり、内積の役割は類似度の計算です**。Attentionの場合、QにXを掛けるのは類似度を計算するためであり、KとVにXを掛けるのはXを回転させるためです。もちろん、KとVを使ってXと回転させた後でも、もとのXと比較して類似度を求めるんですが・・・。ただし、小生は一つ付け加えたい。ここで、Qの役割とは何か？”

C部長 : “そうそう・・・、そうねえ・・・。降参です。それで、変人（FOUNDER）さんのご意見は？”

QEU:FOUNDER ： “ベクトルXを整形して、つづくKとVによって処理できるように形を整えているためにQが必要なだけなんです。これは、Transformerで出てくるself-attentionで根拠を見ることができます。Self-attentionって、Qはいらないんです。あるのはKとVだけです。”

C部長 : “なぜ、Qだけがいらないんですか？”

QEU:FOUNDER ： “self-attentionの前には、必ずattentionがあります。つまり、self-attentionにとって、すでにK,Vの処理ができるように形が整っているんです。”

![imageJRL3-61-2](/2023-11-10-QEUR23_ATTNS21/imageJRL3-61-2.jpg)

C部長 : “なるほど、これはtransformerが根拠なのか・・・。じゃあ、今回の場合、Qをどうすればいいんですか？”

QEU:FOUNDER ： “いまはY3(Gamma値)を使っているでしょ？いまのところ入力はY2(SN比)が最適であるとしているが、もし入力：Y2にQ：Y3を掛けるとせっかくの類似度を劣化させるだけなんじゃないか？”

C部長 : “でも、Ｙ２って、あとで使うんでしょ？”

![imageJRL3-61-3](/2023-11-10-QEUR23_ATTNS21/imageJRL3-61-3.jpg)

QEU:FOUNDER ： “いまは「判別分析型」のＫ，Ｖを使っているんですから、ＱのY2は「異常分析型」のものを使えばいいんじゃない？”

![imageJRL3-61-4](/2023-11-10-QEUR23_ATTNS21/imageJRL3-61-4.jpg)

C部長 : “なるほどね。**ＲＴメトリックスの「標準ベクトルと同じタイプ」をＱマトリックスとして使えばいいということ**ですね。一方、ＫとＶは全ての（異常）モードをぶち込むべしと・・・。”

QEU:FOUNDER ： “うむ・・・。さて、つづいて計算した結果を見てみましょうか・・・。今回は、プログラムの公開はなし・・・。（プログラムは）ほとんど同じだからね・・・。Qマトリックスの参照先だけが変わります。今回は前回のver.Aと今回のver.Bの結果をEXCEL上で比較しています。”

![imageJRL3-61-5](/2023-11-10-QEUR23_ATTNS21/imageJRL3-61-5.jpg)

C部長 : “あれ？**テーブルを転置**しましたね？計測対象が「列」で、学習データが「行」になっている・・・。”

QEU:FOUNDER ： “こうすればverAとBの比較ができて、わかりやすくなったでしょ？”

C部長 : “そうですね。でも、rawデータによると、Qの影響って、それほどないのかなァ・・・。”

QEU:FOUNDER ： “例によって、差異のみを見てみましょう。”

![imageJRL3-61-6](/2023-11-10-QEUR23_ATTNS21/imageJRL3-61-6.jpg)

C部長 : “あれ？新しく**「プラス-マイナス表」**を付けましたね？”

QEU:FOUNDER ： “より直感的に、わかりやすくなったでしょ？”

D先生: “プラス-マイナスが極端に偏ったほうがいいとの認識とすると、やはりQマトリックスをY2（標準ベクトル）にしたほうがいいです。それにしても、現状のやり方ではnormal群を判別するのは無理のような気がします。このままでは検出力はあがりませんね。”

C部長 : “そうだ！！いま、RTメトリックスの計算に使っている標準ベクトルはnormal群ですよね？normal群の標準ベクトルを使って、normal群を判別するのは無理なんじゃないですか？”

QEU:FOUNDER ： “・・・つまり、C部長のアイデアによると、標準ベクトルを種々に変えてAttentionを計算したほうがいいんじゃないかと・・・？”

C部長 : “そうです。”

![imageJRL3-61-7](/2023-11-10-QEUR23_ATTNS21/imageJRL3-61-7.jpg)

D先生: “C部長の考え方によると、均質群を種々変えてRT距離を計測して判別するRT法と基本的考え方が同じになります。我々のやり方がRT法と違うのはマハラノビス距離を使わずにATTENTIONメトリックスを使うということです。”

QEU:FOUNDER  ： “これは面白い！さらに開発をつづけましょう！これが今回の発明がより明確になってきました。C部長に大感謝！！是非、カンパをお願いします！！”

## [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-created&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)
 
 
D先生 ： “皆さん！発明ですよ！！ご検討をよろしくお願いします。”


## ～ まとめ ～

D先生(設定年齢65歳) ： “Vision Transformerってしっています？Transformerで画像を判別する技術です。 “

[![MOVIE2](http://img.youtube.com/vi/tkZMj1VKD9s/0.jpg)](http://www.youtube.com/watch?v=tkZMj1VKD9s "Vision Transformers explained")

QEU:FOUNDER(設定年齢65歳) ： “現在、トライアル中です。GPUが必須になるので、計算量が多いんだよね。やっぱり・・・。”

D先生 ： “画像判別で、CNNよりもスゴイんですかねえ？ “

QEU:FOUNDER ： “さあね・・・。詳細は、小生がテストを完了した後で小生なりの評価をコメントしますよ。”


