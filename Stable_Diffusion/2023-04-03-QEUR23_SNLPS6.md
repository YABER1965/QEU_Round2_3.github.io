---
title: QEUR23_SNLPS6:　T法(2)による Sentiment Analysis (Yelp_Review、その3)
date: 2023-04-03
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_SNLPS6:　T法(2)による Sentiment Analysis (Yelp_Review、その3)

## ～　ベイズとT法の類似性（後編）　～

QEU:FOUNDER  ： “それでは、**Bag_Of_WordsをT法(2)で作ってみましょう**。ナイーブ・ベイズの場合には検索による計算時間の問題がありました。一方、T法の場合には単位空間の取り扱いの面倒くささがあります。まあ、ここでいうところの「面倒くささ」って・・・。”

![imageJRL3-16-1](/2023-04-03-QEUR23_SNLPS6/imageJRL3-16-1.jpg)

D先生 ： “その「面倒くささ」というのは、見方を変えれば**カスタマイズができるメリットである**とも言えます。T法(2)では単位空間を変えて単語間の交互作用を計測できるので、ナイーブ・ベイズよりも計測精度があがるかもしれません。”

**（交互作用の例文）**

### Positive  : This cuisine is healthy.
### Negative : This cuisine is not healthy.


**（単語の並びの例文）**

### Positive:   銭不是問題。
### Negative:  不、銭是問題。

D先生 ： “T法（2）の総合推定値の式を下図に示します。βが感度、ηがSN比です。回帰分析における係数に相当するのはβを「ηの按分」で重みづけした値になります。”

![imageJRL3-16-2](/2023-04-03-QEUR23_SNLPS6/imageJRL3-16-2.jpg)

QEU:FOUNDER  ： “おいおい。「按分なんていう難しい説明」は無しでいこう、ちょっと見るだけでわかる！それではプログラムをドン！”

```python
# -----
# Bag_Of_Wordsを計算する(For T-method(2))
# -----
from fastbook import *
from fastai.text.all import *
from collections import Counter
# -----
# 散布図を描きます
import matplotlib.pyplot as plt
%matplotlib inline

# -----
# Bag_Of_Wordsデータを読み込む
df_T2_BgOfWd = pd.read_csv('./csv_T2_BgOfWd_first.csv')      # reviews_with_splits_lite(new)
df_T2_BgOfWd

# -----
# 信号空間データを読み込む
df_vocab_sig  = df_T2_BgOfWd.loc[:,"sig0":"sig20"]
df_vocab_sig

# -----
# 単位空間データを読み込む
df_vocab_tani = df_T2_BgOfWd.loc[:,"tani0":"tani9"]
df_vocab_tani

# -----
# T法(2)計算シートデータを読み込む
df_T2_Calc = pd.read_csv('./csv_T2Calc_first.csv')      # reviews_with_splits_lite(new)
df_T2_Calc

# -----
# T法(2)計算シートデータの信号空間をリスト化する
df_T2_Calc_signal = df_T2_Calc[df_T2_Calc["T2Split"]=="signal"].loc[:,"mod_logi"]
arr_Ylogi_signal = df_T2_Calc_signal.values
print(arr_Ylogi_signal)

# -----
# T法(2)計算シートデータの単位空間をリスト化する
df_T2_Calc_tani = df_T2_Calc[df_T2_Calc["T2Split"]=="tani"].loc[:,"mod_logi"]
arr_Ylogi_tani = df_T2_Calc_tani.values
print(arr_Ylogi_tani)

# -----
# 単語(vocab)リストを生成する
arr_vocab = df_T2_BgOfWd.loc[:, "vocab"].values
print(arr_vocab[0:16])

# -----
# ベイズ確率のパフォーマンス(log_ratio)リストを生成する
arr_positive = df_T2_BgOfWd.loc[:, "positive"].values
arr_negative = df_T2_BgOfWd.loc[:, "negative"].values
arr_ratios   = []
for i in range(len(df_T2_BgOfWd)):
    val_ratio = math.log((arr_positive[i]+1)/(arr_negative[i]+1))
    arr_ratios.append(round(val_ratio, 5))
arr_ratios = np.array(arr_ratios)
print(arr_ratios[0:16])

# ---------------------------
# T法(2)のメトリックス計算のためのパラメタ
len_signals = 21
len_vocabs  = len(df_vocab_sig)
len_tani    = 10

# -----
# 10個の単位空間のYノルム値マトリックスを計算する
# リストの初期化
mx_Ylogi_norm  = np.zeros([len_tani, len_signals])
# -----
# jTaniは単位空間の番号
for jTani in range(len_tani):
    # -----
    # [Y]:単位空間がregNO=０の場合
    val_Ylogi_tani = arr_Ylogi_tani[jTani]
    #print(val_Ylogi_tani)
    mx_Ylogi_norm[jTani, :] = arr_Ylogi_signal - val_Ylogi_tani
# -----
print(mx_Ylogi_norm)


# ---------------------------
# Xsリストをノルム化する関数
def create_Xnorm(jTani):
    # -----
    # リストの初期化
    mx_Xvocab_norm = np.zeros([len(df_vocab_sig), len_signals])
    # -----
    # iVocabはボキャブラリの番号 409水準
    # kSigは信号空間の番号 21水準
    # jTaniは単位空間の番号 10水準
    for iVocab in range(len(df_vocab_sig)):
        # -----
        # [X]:信号空間：説明変数(X)を生成する
        arr_Xvocab_sig = df_vocab_sig.loc[iVocab, "sig0":"sig20"].values
        #print(arr_Xvocab_sig)
        # -----
        # [X]:単位空間がregNO = jTani である場合
        val_Xvocab_tani = df_vocab_tani.loc[iVocab, "tani{}".format(jTani)]
        arr_Xvocab_norm = arr_Xvocab_sig - val_Xvocab_tani
        #print(arr_Xvocab_norm)
        # -----
        mx_Xvocab_norm[iVocab, :] = arr_Xvocab_norm
    # -----
    return mx_Xvocab_norm


# ---------------------------
# ボキャブラリ(あおくまでグラフ表示用で全１６種類)を単位空間（全10種類）のもとで散布図にてプロットする
def draw_plot(jTani):

    # -----
    # X_normを形成する
    mx_Xvocab_norm = create_Xnorm(jTani)

    # -----
    # プロットする
    fig = plt.figure(figsize=(14, 10))
    # ---
    ax1 = fig.add_subplot(2, 2, 1)
    ax1.set_title('vocabNO: 0-3 for taniNO:{}'.format(jTani))
    ax1.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[0], label=arr_vocab[0], color="blue")
    ax1.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[1], label=arr_vocab[1], color="red")
    ax1.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[2], label=arr_vocab[2], color="green")
    ax1.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[3], label=arr_vocab[3], color="orange")
    ax1.set_xlabel('Y-norm')
    ax1.set_ylabel('X-norm')
    ax1.legend(loc='best')
    ax1.grid(which = 'major', color='red', linestyle='--')
    # ---
    ax2 = fig.add_subplot(2, 2, 2)
    ax2.set_title('vocabNO: 4-7 for taniNO:{}'.format(jTani))
    ax2.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[4], label=arr_vocab[4], color="blue")
    ax2.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[5], label=arr_vocab[5], color="red")
    ax2.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[6], label=arr_vocab[6], color="green")
    ax2.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[7], label=arr_vocab[7], color="orange")
    ax2.set_xlabel('Y-norm')
    ax2.set_ylabel('X-norm')
    ax2.legend(loc='best')
    ax2.grid(which = 'major', color='red', linestyle='--')
    # ---
    ax3 = fig.add_subplot(2, 2, 3)
    ax3.set_title('vocabNO: 8-11 for taniNO:{}'.format(jTani))
    ax3.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[8], label=arr_vocab[8], color="blue")
    ax3.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[9], label=arr_vocab[9], color="red")
    ax3.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[10], label=arr_vocab[10], color="green")
    ax3.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[11], label=arr_vocab[11], color="orange")
    ax3.set_xlabel('Y-norm')
    ax3.set_ylabel('X-norm')
    ax3.legend(loc='best')
    ax3.grid(which = 'major', color='red', linestyle='--')
    # ---
    ax4 = fig.add_subplot(2, 2, 4)
    ax4.set_title('vocabNO: 12-15 for taniNO:{}'.format(jTani))
    ax4.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[12], label=arr_vocab[12], color="blue")
    ax4.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[13], label=arr_vocab[13], color="red")
    ax4.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[14], label=arr_vocab[14], color="green")
    ax4.scatter(mx_Ylogi_norm[jTani], mx_Xvocab_norm[15], label=arr_vocab[15], color="orange")
    ax4.set_xlabel('Y-norm')
    ax4.set_ylabel('X-norm')
    ax4.legend(loc='best')
    ax4.grid(which = 'major', color='red', linestyle='--')
    # ---
    plt.show()

# -----
# 単位空間の１０水準を描く
for jTani in range(len_tani):
    draw_plot(jTani)
```

**(POSITIVE文を単位空間にした事例)**

![imageJRL3-16-3](/2023-04-03-QEUR23_SNLPS6/imageJRL3-16-3.png)

**(NEGATIVE文を単位空間にした事例)**

![imageJRL3-16-4](/2023-04-03-QEUR23_SNLPS6/imageJRL3-16-4.png)

D先生 ： “まあ、ぱっと見た目は何が何だかわかりません。”

QEU:FOUNDER ： “なんとなく**０点比例の分布**になっているような単語はないですか？そういうタイプの単語のSN比は高くなっています。”

D先生 ： “それでは、ひきつづき**メトリックス（感度β、SN比η）**を計算しましょう。”

```python
# ---------------------------
# T2メトリックス計算の関数定義
def calc_metricsT2m(len_signals, len_vocabs, mx_Xs_norm, arr_Y_norm):
    # -----
    # 感度とSN比
    arr_beta    = np.zeros(len_vocabs)
    arr_snr     = np.zeros(len_vocabs) 
    # -----
    # 有効除数の計算
    yuko = 0.0
    for jCol in range(len_signals):
        yuko += float(arr_Y_norm[jCol]) ** 2
    #print('有効除数=:{0:.4f}'.format(yuko))
    # -----
    if yuko > 0.0:
        for iRow in range(len_vocabs):
            # -----
            # 線形式の計算
            sum_array = 0.0
            for jCol in range(len_signals):
                sum_array += float(arr_Y_norm[jCol]) * mx_Xs_norm[iRow][jCol]
                #print('配列ix={0},jy={1}の合計値{2}'.format(iRow,jCol,sum_array))
            lnr_yvalue = sum_array
            beta_yvalue = sum_array / float(yuko)
            # print('レコードix={0}の線形式：{1}'.format(iRow,lnr_yvalue[0:5]))
            # print('レコードix={0}の感度：{1}'.format(iRow,beta_yvalue[0:5]))
            # -----
            # 全変動ST及び各種中間指標SB,SE,VE,η
            sum_array = 0.0
            for jCol in range(len_signals):
                sum_array += float(mx_Xs_norm[iRow][jCol]) ** 2
                # print('配列i={0},jy={1}の合計値{2}'.format(iRow,iRow,sum_array))
            st_yvalue = sum_array
            sb_yvalue = lnr_yvalue ** 2 / float(yuko)
            se_yvalue = st_yvalue - sb_yvalue
            # -----
            ve_yvalue = se_yvalue / float(len_vocabs - 1.0)
            # print('レコードix={0}の比例項変動：{1}'.format(iRow,sb_yvalue[0:5]))
            # print('レコードix={0}の感度：{1}'.format(iRow,beta_yvalue[0:5]))
            # -----
            # 代入
            arr_beta[iRow]  = round(beta_yvalue, 8)
            arr_snr[iRow]   = round(sb_yvalue / se_yvalue, 8)
        return arr_beta, arr_snr
    else:
        # -----
        # 異常処理
        return [0], [0]

# ---------------------------
# 単位空間毎の感度とSN比を計算する
mx_beta = np.zeros([len_tani,len_vocabs])     # 単位空間数(10) x ボキャブラリ数
mx_snr  = np.zeros([len_tani,len_vocabs])     # 単位空間数(10) x ボキャブラリ数
for jTani in range(len_tani):
    # -----
    # mx_Xvocab_normを形成する
    mx_Xvocab_norm = create_Xnorm(jTani)
    #print(mx_Xvocab_norm)
    # -----
    # arr_Yvocab_normを形成する
    arr_Yvocab_norm = mx_Ylogi_norm[jTani]
    #print(arr_Yvocab_norm)
    arr_beta, arr_snr = calc_metricsT2m(len_signals, len_vocabs, mx_Xvocab_norm, arr_Yvocab_norm)
    #print("--- jTani: {} ---".format(jTani))
    #print("arr_beta: ", arr_beta)
    #print("arr_snr: ", arr_snr)
    # -----
    mx_beta[jTani,:] = arr_beta
    mx_snr[jTani,:]  = arr_snr
# -----
#print(mx_beta.T)
#print("---------")
#print(mx_snr.T)

# -----
# データフレームをCSVファイルに出力する
arr_column_bt = ["bt{}".format(i) for i in range(len_tani)]
arr_column_sn = ["sn{}".format(i) for i in range(len_tani)]
arr_column = arr_column_bt + arr_column_sn

mx_output = np.concatenate([mx_beta.T, mx_snr.T], axis=1)
df_output = pd.DataFrame(mx_output, columns=arr_column)

# -----
# データフレームにボキャブラリ情報を追加する
df_output["ratio"] = arr_ratios[0:len_vocabs]
df_output["vocab"] = arr_vocab[0:len_vocabs]
df_output

# -----
# SAVE CSV FILE
df_output.to_csv("csv_vocab_T2ratio.csv")

# -----
# データフレームにボキャブラリ情報を追加する
ratio        = df_output.loc[:, 'ratio'].values
# ---
sn0_positive = df_output.loc[:, 'sn0'].values
sn1_positive = df_output.loc[:, 'sn1'].values
sn2_positive = df_output.loc[:, 'sn2'].values
sn3_positive = df_output.loc[:, 'sn3'].values
sn5_negative = df_output.loc[:, 'sn5'].values
sn6_negative = df_output.loc[:, 'sn6'].values
sn7_negative = df_output.loc[:, 'sn7'].values
sn8_negative = df_output.loc[:, 'sn8'].values
# ---
bt0_positive = df_output.loc[:, 'bt0'].values
bt1_positive = df_output.loc[:, 'bt1'].values
bt2_positive = df_output.loc[:, 'bt2'].values
bt3_positive = df_output.loc[:, 'bt3'].values
bt5_negative = df_output.loc[:, 'bt5'].values
bt6_negative = df_output.loc[:, 'bt6'].values
bt7_negative = df_output.loc[:, 'bt7'].values
bt8_negative = df_output.loc[:, 'bt8'].values
# ---
T2R0_positive, T2R0_ratio  = [], []
T2R1_positive, T2R1_ratio  = [], []
T2R2_positive, T2R2_ratio  = [], []
T2R3_positive, T2R3_ratio  = [], []
T2R5_negative, T2R5_ratio  = [], []
T2R6_negative, T2R6_ratio  = [], []
T2R7_negative, T2R7_ratio  = [], []
T2R8_negative, T2R8_ratio  = [], []

# -----
# ベイズ確率とSN比の関係をプロットする
fig = plt.figure(figsize=(14, 6))
# ---
ax1 = fig.add_subplot(1, 2, 1)
ax1.set_title('log_ratio vs Coefficient')
ax1.scatter(ratio, sn0_positive, label='sn0_pos', color="blue")
ax1.scatter(ratio, sn1_positive, label='sn1_pos', color="red")
ax1.scatter(ratio, sn5_negative, label='sn5_neg', color="green")
ax1.scatter(ratio, sn6_negative, label='sn6_neg', color="orange")
ax1.set_xlabel('log_ratio')
ax1.set_ylabel('SN-ratio')
ax1.legend(loc='best')
ax1.grid(which = 'major', color='red', linestyle='--')
# ---
ax2 = fig.add_subplot(1, 2, 2)
ax2.set_title('log_ratio vs Coefficient')
ax2.scatter(ratio, sn2_positive, label='sn2_pos', color="blue")
ax2.scatter(ratio, sn3_positive, label='sn3_pos', color="red")
ax2.scatter(ratio, sn7_negative, label='sn7_neg', color="green")
ax2.scatter(ratio, sn8_negative, label='sn8_neg', color="orange")
ax2.set_xlabel('log_ratio')
ax2.set_ylabel('SN-ratio')
ax2.legend(loc='best')
ax2.grid(which = 'major', color='red', linestyle='--')
# ---
plt.show()
```

![imageJRL3-16-5](/2023-04-03-QEUR23_SNLPS6/imageJRL3-16-5.png)

D先生 ： “えっ？こんな分布になるんですか？単位空間がPositive の場合には、主にPositiveなボキャブラリが反応（SN比が高くなる）するんですか？”

QEU:FOUNDER ： “結果として**「V字形の分布」**になりました。つまり、PositiveでもなくNegativeでもない性質**(log_ratioが0付近)**のボキャブラリのSN比は低い傾向にあります。それでも、単位空間によって変わりますけどね・・・。”

D先生 ： “それでも、単位空間によってこれほど変わるのかと驚きです。”

QEU:FOUNDER ： “それでは、βとηを使って各項目の**回帰係数(Coefficient)**を作成しましょう。”

```python
# ---
# リストのリセット
T2R0_positive, T2R0_ratio, T2R0_snr  = [], [], []
T2R1_positive, T2R1_ratio, T2R1_snr  = [], [], []
T2R2_positive, T2R2_ratio, T2R2_snr  = [], [], []
T2R3_positive, T2R3_ratio, T2R3_snr  = [], [], []
T2R5_negative, T2R5_ratio, T2R5_snr  = [], [], []
T2R6_negative, T2R6_ratio, T2R6_snr  = [], [], []
T2R7_negative, T2R7_ratio, T2R7_snr  = [], [], []
T2R8_negative, T2R8_ratio, T2R8_snr  = [], [], []

# -----
# リストにボキャブラリ情報を追加する
for i in range(len_vocabs):
    # ----- Positive ---
    if sn0_positive[i] > 0.8:
        T2R0_ratio.append(ratio[i])
        T2R0_snr.append(sn0_positive[i])
        T2R0_positive.append(round(sn0_positive[i] / bt0_positive[i], 5))
    # ---
    if sn1_positive[i] > 0.8:
        T2R1_ratio.append(ratio[i])
        T2R1_snr.append(sn1_positive[i])
        T2R1_positive.append(round(sn1_positive[i] / bt1_positive[i], 5))
    # ---    
    if sn2_positive[i] > 0.8:
        T2R2_ratio.append(ratio[i])
        T2R2_snr.append(sn2_positive[i])
        T2R2_positive.append(round(sn2_positive[i] / bt2_positive[i], 5))
    # ---    
    if sn3_positive[i] > 0.8:
        T2R3_ratio.append(ratio[i])
        T2R3_snr.append(sn3_positive[i])
        T2R3_positive.append(round(sn3_positive[i] / bt3_positive[i], 5))
    # ----- Negative ---
    if sn5_negative[i] > 0.8:
        T2R5_ratio.append(ratio[i])
        T2R5_snr.append(sn5_negative[i])
        T2R5_negative.append(round(sn5_negative[i] / bt5_negative[i], 5))
    if sn6_negative[i] > 0.8:
        T2R6_ratio.append(ratio[i])
        T2R6_snr.append(sn6_negative[i])
        T2R6_negative.append(round(sn6_negative[i] / bt6_negative[i], 5))
    if sn7_negative[i] > 0.8:
        T2R7_ratio.append(ratio[i])
        T2R7_snr.append(sn7_negative[i])
        T2R7_negative.append(round(sn7_negative[i] / bt7_negative[i], 5))
    if sn8_negative[i] > 0.8:
        T2R8_ratio.append(ratio[i])
        T2R8_snr.append(sn8_negative[i])
        T2R8_negative.append(round(sn8_negative[i] / bt8_negative[i], 5))

# -----
# データをSN比トータル値で基準化する
# -----
T2R0_positive = np.array(T2R0_positive) / np.sum(T2R0_snr)
T2R1_positive = np.array(T2R1_positive) / np.sum(T2R1_snr)
T2R2_positive = np.array(T2R2_positive) / np.sum(T2R2_snr)
T2R3_positive = np.array(T2R3_positive) / np.sum(T2R3_snr)
# -----
T2R5_negative = np.array(T2R5_negative) / np.sum(T2R5_snr)
T2R6_negative = np.array(T2R6_negative) / np.sum(T2R6_snr)
T2R7_negative = np.array(T2R7_negative) / np.sum(T2R7_snr)
T2R8_negative = np.array(T2R8_negative) / np.sum(T2R8_snr)

# -----
# ベイズ確率と回帰係数(SN比/感度)の関係をプロットする(しきい値0.2)
fig = plt.figure(figsize=(14, 6))
# ---
ax1 = fig.add_subplot(1, 2, 1)
ax1.set_title('log_ratio vs Coefficient, threshold = 0.8, normalized')
ax1.scatter(T2R0_ratio, T2R0_positive, label='sn0_pos', color="blue")
ax1.scatter(T2R1_ratio, T2R1_positive, label='sn1_pos', color="red")
ax1.scatter(T2R5_ratio, T2R5_negative, label='sn5_neg', color="green")
ax1.scatter(T2R6_ratio, T2R6_negative, label='sn6_neg', color="orange")
ax1.set_xlabel('log_ratio')
ax1.set_ylabel('Coefficient')
ax1.legend(loc='best')
ax1.grid(which = 'major', color='red', linestyle='--')
# ---
ax2 = fig.add_subplot(1, 2, 2)
ax2.set_title('log_ratio vs Coefficient, threshold = 0.8, normalized')
ax2.scatter(T2R2_ratio, T2R2_positive, label='sn2_pos', color="blue")
ax2.scatter(T2R3_ratio, T2R3_positive, label='sn3_pos', color="red")
ax2.scatter(T2R7_ratio, T2R7_negative, label='sn7_neg', color="green")
ax2.scatter(T2R8_ratio, T2R8_negative, label='sn8_neg', color="orange")
ax2.set_xlabel('log_ratio')
ax2.set_ylabel('Coefficient')
ax2.legend(loc='best')
ax2.grid(which = 'major', color='red', linestyle='--')
# ---
plt.show()

```

![imageJRL3-16-6](/2023-04-03-QEUR23_SNLPS6/imageJRL3-16-6.png)

D先生 ： “**しきい値(0.8)**を設定してフィルタリングをしていますね。”

QEU:FOUNDER  ： “SN比が小さいボキャブラリを除いています。単位空間の効果に、またまた驚くでしょ？”

D先生 ： “なんというか・・・。Negative文を単位空間に使ったときには回帰係数は（多くは）マイナスに、Positive文を使ったらプラスになります。しかし・・・、それにしても単位空間によってバラツキの様子が全然違うわ・・・。”

QEU:FOUNDER ： “T法(2)は「単位空間X信号空間」という形でボキャブラリの相互作用を検出しているだと思います。”

D先生 ： “ほとんどの回帰係数がプラスまたはマイナスに偏るのはなぁ・・・。”

### Y_norm = Y_signal – Y_tani
### X_norm = X_signal – X_tani

QEU:FOUNDER  ： “XとYの値がノルム（正規）化されていますので、総合推定式で計算してみないとわからないですよ。”

D先生 ： “こんなに単位空間によって変わっちゃうと、結局のところ何を信じていいのやら・・・。”

![imageJRL3-16-7](/2023-04-03-QEUR23_SNLPS6/imageJRL3-16-7.jpg)

QEU:FOUNDER  ： “**バギング(bagging)**する・・・(笑)？”

D先生 ： “ふ～ん・・・、バギングねえ・・・。”


## ～　まとめ　～

QEU:FOUNDER ： “また、GPT関連ですごいことが起こったようですね。”

![imageJRL3-16-8](/2023-04-03-QEUR23_SNLPS6/imageJRL3-16-8.jpg)

C部長 : “ああ・・・、この人は**Sam Altmanが話題にしていた人**ですね。本当に、最近のM社はアグレッシブだなぁ。このツールを使えば、Microsoft 365 copilotのデモで見たような革命的な、ショッキングな風景を見れるのでしょうか？”

[![MOVIE1](http://img.youtube.com/vi/8_0DJ9FOlOM/0.jpg)](http://www.youtube.com/watch?v=8_0DJ9FOlOM "GitHub Copilot X Explained | A big step forward...")

QEU:FOUNDER ： “率直に言う、小生はプログラミングがうまくないんで・・・。それでも、これは言えると思います。あんまり「ピン！」とは来なかった・・・。”

C部長 : “アンタがヘタだからでしょ・・・。”

QEU:FOUNDER ： “すでに「そうだ（ドのつく下手）」と白状しているだろうが・・・。**プログラミングにはパターンがない**んだよね。逆に言えば、ユーザーの作業を簡単にする**（パターン化する）**ためにプログラムがあるわけで・・・。それでも、ユーザーに近い言語であるhtmlとかphpだったら「ピン！！」ときますよ。”

[![MOVIE2](http://img.youtube.com/vi/j5wa9soV5Co/0.jpg)](http://www.youtube.com/watch?v=j5wa9soV5Co "VSCode拡張機能「 ChatGPT - genie AI - 」AI時代の使い方 入門")

C部長 : “つまり、**自分が実現したいプログラムをAIにどれだけ簡単かつ十分かつ正確に説明できるかでしょう？”

QEU:FOUNDER ： “・・・とはいえ、出来上がったプログラムに注釈を入れたりコードを最適化する機能、KerasをPytorchに変換できる機能はいいなぁ・・・。**CopilotXは有料**だけど、欲しい・・。”

