---
title: QEUR23_ATTNS5: ゲーム2048用の強化学習準備（CONV）
date: 2023-10-23
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_ATTNS5: ゲーム2048用の強化学習準備（CONV）

## ～ ホンマに、	RTメトリックはCONVに勝てるのか？ ～

QEU:FOUNDER ： “これから強化学習の企画段階に入るが、**「準備運動（ウォームアップ）」**をやりましょう。ゲームを100回程度自動的にシミュレーションさせるプログラムを作ってみましょう。”

C部長 : “ついでに、そのメトリックスの特徴を調べるわけですね？”

QEU:FOUNDER ： “もちろん。じゃあ、プログラムを行くよ。ドン！！”

```python
# 2048ゲームの連続シミュレーションとメトリックス変動分析(CONV-SCORE)
import math
import numpy as np
import random
from collections import deque, Counter

# ---------------- 
#import torch
from fastai.vision.all import *

# ---------------- 
import matplotlib.pyplot as plt
#%matplotlib inline

#=================================================
# SIMPLE CONVOLUTION DATA
#=================================================
mx_cw1 = tensor([[1,1,1],[0,0,1],[0,0,1]]).float()
mx_cw2 = tensor([[0,0,1.66],[0,1.66,0],[1.66,0,0]]).float()
mx_cw3 = tensor([[1,0,0],[1,0,0],[1,1,1]]).float()
mx_cc1 = tensor([[1,1,1],[1,0,0],[1,0,0]]).float()
mx_cc2 = tensor([[1.66,0,0],[0,1.66,0],[0,0,1.66]]).float()
mx_cc3 = tensor([[0,0,1],[0,0,1],[1,1,1]]).float()
mx_dtm = tensor([[0,1,0],[1,1,1],[0,1,0]]).float()
print("--- mx_dtm ---")
print(mx_dtm)

# ---------------------------
# 畳み込みカーネルを生成する
cw_kernels  = torch.stack([mx_cw1, mx_cw2, mx_cw3])
cc_kernels  = torch.stack([mx_cc1, mx_cc2, mx_cc3])
tani_kernel = mx_dtm
print("--- cw_kernels ---")
print(cw_kernels)
print(cw_kernels[0])

#=================================================
# CONVOLUTION FUNCTIONS
#=================================================
# 畳み込み処理を実施する
def apply_kernel(row, col, kernel, mx_tensor):
    return (mx_tensor[row:row+3,col:col+3] * kernel).sum()

# ---------------------------
# 畳み込みテンソルイメージを生成する
def create_tsrConv(mx_signal):

    # テンソル化
    mx_signal = tensor(mx_signal).float()
    #print("--- mx_signal ---")
    #print(mx_signal)

    # ----
    # 単位空間の畳み込み
    tani_image = tensor([[apply_kernel(i,j, tani_kernel, mx_signal) for j in range(2)] for i in range(2)])
    tani_array = tani_image.numpy().flatten()
    tani_mean  = np.mean(tani_array) + 0.0001
    #print(tani_array)

    # ----
    # 信号空間（Clockwise群）の畳み込みとメトリックス化
    acc_maxcw = np.zeros(3)
    acc_sigcw = np.zeros((3,4))
    #print(acc_sigcc)
    for k in range(3):
        sig_image = tensor([[apply_kernel(i,j, cw_kernels[k], mx_signal) for j in range(2)] for i in range(2)])
        sig_array = sig_image.numpy().flatten()
        sig_max   = np.max(sig_array)
        #print(sig_array)
        acc_sigcw[k,:] = sig_array / tani_mean
        acc_maxcw[k]   = round(math.log(sig_max/tani_mean+1),4)
    #print(acc_sigcw)
    #print(acc_maxcw)

    # ----
    # 信号空間（Counter Clockwise群）の畳み込みとメトリックス化
    acc_maxcc = np.zeros(3)
    acc_sigcc = np.zeros((3,4))
    #print(acc_sigcc)
    for k in range(3):
        sig_image = tensor([[apply_kernel(i,j, cc_kernels[k], mx_signal) for j in range(2)] for i in range(2)])
        sig_array = sig_image.numpy().flatten()
        sig_max   = np.max(sig_array)
        #print(sig_array)
        acc_sigcc[k,:] = sig_array / tani_mean
        acc_maxcc[k]   = round(math.log(sig_max/tani_mean+1),4)
    #print(acc_sigcc)
    #print(acc_maxcc)

    # 特徴ベクトルを結合する
    all_max = np.append(acc_maxcw,acc_maxcc)
    #print(all_max)

    return all_max

# ---------------- 
# 2048ゲーム
# ---------------- 
# ボードのサイズ
SIZE = 4

# ボードを初期化する関数
def init_board():
    # ボードは二次元リストで表現する
    board = [[0] * SIZE for _ in range(SIZE)]
    # ランダムな位置に2か4を配置する
    #add_random_tile(board)
    #add_random_tile(board)
    return board

# ボードをリセットする関数
def reset_board():
    # ボードをいったん空にする
    for i in range(SIZE):
        for j in range(SIZE):
            board[i][j] = 0
    # ランダムな位置に2か4を配置する
    add_random_tile(board)
    add_random_tile(board)
    return board

# ランダムな位置に2か4を配置する関数
def add_random_tile(board):
    # 空いているセルの座標をリストに格納する
    empty_cells = []
    for i in range(SIZE):
        for j in range(SIZE):
            if board[i][j] == 0:
                empty_cells.append((i, j))
    # 空いているセルがなければ何もしない
    if not empty_cells:
        return
    # 空いているセルの中からランダムに選ぶ
    i, j = random.choice(empty_cells)
    # 10%の確率で4を、90%の確率で2を配置する
    board[i][j] = 4 if random.random() < 0.1 else 2

# ボードを左にスライドする関数
def slide_left(board):
    # 報酬と変化があったかどうかのフラグ
    reward = 0
    changed = False
    # 各行について処理する
    for row in board:
        # まず0でないセルだけを抽出する
        non_zero_cells = [cell for cell in row if cell != 0]
        # 隣り合うセルが同じ値なら結合する
        merged_cells = []
        i = 0
        while i < len(non_zero_cells):
            if i + 1 < len(non_zero_cells) and non_zero_cells[i] == non_zero_cells[i + 1]:
                merged_cells.append(non_zero_cells[i] * 2)
                reward = reward + non_zero_cells[i] * 2
                i += 2
            else:
                merged_cells.append(non_zero_cells[i])
                i += 1
        # 結合した後の行の長さが元の行の長さより短ければ、0で埋める
        while len(merged_cells) < SIZE:
            merged_cells.append(0)
        # 元の行と異なれば、変化があったとする
        if merged_cells != row:
            changed = True
        # 元の行を更新する
        row[:] = merged_cells[:]
    return changed, reward

# ボードを右にスライドする関数（左にスライドした後に反転させる）
def slide_right(board):
    reverse_board(board)
    changed, reward = slide_left(board)
    reverse_board(board)
    return changed, reward

# ボードを上にスライドする関数（左に90度回転させた後に左にスライドし、元に戻す）
def slide_down(board):
    rotate_board(board)
    changed, reward = slide_left(board)
    rotate_board(board, -1)
    return changed, reward

# ボードを下にスライドする関数（右に90度回転させた後に左にスライドし、元に戻す）
def slide_up(board):
    rotate_board(board, -1)
    changed, reward = slide_left(board)
    rotate_board(board)
    return changed, reward

# ボードを反転させる関数（水平方向に反転）
def reverse_board(board):
    for row in board:
        row.reverse()

# ボードを回転させる関数（時計回りにn回90度回転）
def rotate_board(board, n=1):
    n %= 4 # nを0から3の範囲に正規化する
    for _ in range(n):
        board[:] = list(map(list, zip(*board[::-1])))

# ボードが埋まっているかどうかを判定する関数
def is_full(board):
    return all(cell != 0 for row in board for cell in row)

# ボードに動きがあるかどうかを判定する関数
def has_move(board):
    # 空いているセルがあれば動きがある
    if not is_full(board):
        return True
    # 隣り合うセルに同じ値があれば動きがある
    for i in range(SIZE):
        for j in range(SIZE):
            cell = board[i][j]
            if (i + 1 < SIZE and cell == board[i + 1][j]) or (j + 1 < SIZE and cell == board[i][j + 1]):
                return True
    # それ以外は動きがない
    return False

# ボードをテキストで表示する関数
def print_board(board):
    # 各セルの幅を揃えるために、最大桁数を求める
    max_width = max(len(str(cell)) for row in board for cell in row)
    # 各行について処理する
    for row in board:
        # セルの値を文字列に変換し、空白で埋める
        cells = [str(cell).rjust(max_width) for cell in row]
        # セルをパイプで区切って表示する
        print("|" + "|".join(cells) + "|")

# メインの処理
def run_game(board, action):

    # 変数の導入
    reward = 0
    done = False
    
    # 入力に応じてボードをスライドさせる
    if action == "s":
        changed, reward = slide_down(board)
    elif action == "a":
        changed, reward = slide_left(board)
    elif action == "w":
        changed, reward = slide_up(board)
    elif action == "d":
        changed, reward = slide_right(board)
    else:
        print("Invalid input")
        #continue
    # ボードに変化があれば、ランダムな位置に新しいタイルを追加する
    if changed:
        add_random_tile(board)
        # ボードを表示する
        #print_board(board)
    else:
        print("No move")
        reward = -1
        
    # ボードに動きがなければ、ゲームオーバーとする
    if not has_move(board):
        #print("Game over")
        done = True

    return board, reward, done

# --------------------------
# メインルーチン        
# --------------------------
# ボードを初期化する
board = init_board()

# 学習評価用の配列を初期化する
acc_episode = []
acc_turn = []
acc_score = []
acc_maxconv = []

# ゲームが終了するまで繰り返す
# メインの処理を実行する
for i_episode in range(20):

    # ボードをリセットする
    board = reset_board()
    # ボードを表示する
    print("--- RESETED, GAME NO: {} ---".format(i_episode))
    print_board(board)
    state = board

    # 単一ゲーム評価用の配列を初期化する
    arr_turn = []
    arr_reward = []
    arr_score = []
    arr_yzero = []
    # ----
    score = 0
    i_turn = 0

    # ゲームを始める
    while True:

        arr_action = ["s", "a", "w", "d"]
        action = random.choice(arr_action)
        #print("i_turn:{0},action:{1}".format(i_turn,action))
        
        # ゲームを実行する
        state,reward,done = run_game(state, action)
        score = score + reward
        
        # 結果の出力
        if (i_turn+1)%20 == 0:
            print("i_episode:{0},i_turn:{1},action:{2},reward:{3},done:{4},score:{5}".format(i_episode,i_turn,action,reward,done,score))
            print_board(state)

        # ----------   
        # 畳み込みテンソルイメージを生成する
        all_max = create_tsrConv(state)
        #print(all_max)

        # マトリックス化
        if i_turn == 0:
            mx_cvmax = np.array([all_max])
        else:
            mx_cvmax = np.vstack((mx_cvmax,all_max)) # 結合してみる

        # ----------   
        # ZERO COUNTER
        state_flatten = np.array(state).flatten()
        cc = Counter(state_flatten)
        arr_yzero.append(cc[0]) 

        # 配列へ要素を追加する
        arr_turn.append(i_turn)
        arr_reward.append(reward)
        arr_score.append(score)

        # ボードに動きがなければ、ゲームオーバーとする
        if done == True or i_turn > 400:
            print("Game over")
            # -----
            # 結果を出力する
            #print("----------")
            #print(mx_cvmax)
            #print("----------")
            #print(arr_turn)
            #print(arr_reward)
            #print(arr_score)
            #print(arr_yzero)

            # -----
            # ゲーム結果のグラフ化
            #show_graph_game(arr_turn, arr_reward, arr_score, arr_yzero, mx_cvmax)

            # ----
            # METRICS
            acc_conv = []
            mask_turn = np.min([100,i_turn-30])
            acc_conv.append(np.max(mx_cvmax[mask_turn:,0]))
            acc_conv.append(np.max(mx_cvmax[mask_turn:,1]))
            acc_conv.append(np.max(mx_cvmax[mask_turn:,2]))
            acc_conv.append(np.max(mx_cvmax[mask_turn:,3]))
            acc_conv.append(np.max(mx_cvmax[mask_turn:,4]))
            acc_conv.append(np.max(mx_cvmax[mask_turn:,5]))

            # -----
            # 学習評価用の配列を初期化する
            acc_episode.append(i_episode)
            acc_turn.append(i_turn)
            acc_score.append(score)
            acc_maxconv.append(np.max(acc_conv))

            # マトリックス化
            if i_episode == 0:
                mx_accmax = np.array([acc_conv])
            else:
                mx_accmax = np.vstack((mx_accmax,acc_conv)) # 結合してみる

            break
        else:
            i_turn = i_turn + 1


```

QEU:FOUNDER ： “ここまではシミュレーション計算のロジックです。グラフ化のためのロジックは、以下につづきます。”


```python
# ----------------
# 学習結果のグラフ化(評価用A)
# ----------------
def show_graph_evalA(acc_episode, acc_turn, acc_score, mx_accmax):

    fig = plt.figure(figsize=(10, 7))
    # -----
    # ax1
    ax1 = fig.add_subplot(2, 2, 1)
    ax1.set_title('GAME trend : maxTURN')
    ax1.set_xlabel('#GAME-TURN')
    ax1.set_ylabel('TURN')
    ax1.grid(True)
    ax1.plot(acc_episode, acc_turn, color='b')
    # -----
    # ax2
    ax2 = fig.add_subplot(2, 2, 2)
    ax2.set_title('GAME trend : MAXscore')
    ax2.set_xlabel('#GAME-SCORE')
    ax2.set_ylabel('score')
    ax2.grid(True)
    ax2.plot(acc_episode, acc_score, color='b')
    # -----
    # ax3
    ax3 = fig.add_subplot(2, 2, 3)
    ax3.set_title('metrics : conv_clockwise')
    ax3.set_xlabel('#GAME-TURN')
    ax3.set_ylabel('conv_metrics')
    ax3.grid(True)
    ax3.plot(acc_episode, mx_accmax[:,0], color='b')
    ax3.plot(acc_episode, mx_accmax[:,1], color='g')
    ax3.plot(acc_episode, mx_accmax[:,2], color='r')
    # -----
    # ax4
    ax4 = fig.add_subplot(2, 2, 4)
    ax4.set_title('metrics : counter_clockwise')
    ax4.set_xlabel('#GAME-TURN')
    ax4.set_ylabel('conv_metrics')
    ax4.grid(True)
    ax4.plot(acc_episode, mx_accmax[:,3], color='c')
    ax4.plot(acc_episode, mx_accmax[:,4], color='y')
    ax4.plot(acc_episode, mx_accmax[:,5], color='m')
    # -----
    fig.tight_layout()
    #fig.savefig("./AAC_img.png")
    plt.show()

# -----
# 学習結果のグラフ化(評価用A)
show_graph_evalA(acc_episode, acc_turn, acc_score, mx_accmax)

# ----------------
# 学習結果のグラフ化(評価用B)
# ----------------
def show_graph_evalB(acc_episode, acc_turn, acc_score, acc_maxconv):

    fig = plt.figure(figsize=(10, 7))
    # -----
    # ax1
    ax1 = fig.add_subplot(2, 2, 1)
    ax1.set_title('RELATION SCATTER : maxconv\'s role')
    ax1.set_xlabel('#GAME-SCORE')
    ax1.set_ylabel('maxconv')
    ax1.grid(True)
    ax1.scatter(acc_score, acc_maxconv)
    # -----
    # ax2
    ax2 = fig.add_subplot(2, 2, 2)
    ax2.set_title('GAME trend : MAXscore')
    ax2.set_xlabel('#GAME-TURN')
    ax2.set_ylabel('score')
    ax2.grid(True)
    ax2.plot(acc_episode, acc_score, color='b')
    # -----
    # ax3
    ax3 = fig.add_subplot(2, 2, 3)
    ax3.set_title('metrics : maxconv')
    ax3.set_xlabel('#GAME-TURN')
    ax3.set_ylabel('maxconv')
    ax3.grid(True)
    ax3.plot(acc_episode, acc_maxconv, color='b')
    fig.tight_layout()
    # -----
    #fig.savefig("./AAC_img.png")
    plt.show()

# -----
# 学習結果のグラフ化(評価用B)
show_graph_evalB(acc_episode, acc_turn, acc_score, acc_maxconv)
```

D先生 ： “今回は、簡単に紹介するだけにしましょうね。”

QEU:FOUNDER ： “もちろん。さしあたり、この2枚の図を見るだけでいいんじゃないかな？**2枚目の散布図が重要**です。・・・というか、ある意味で畳み込みメトリックスの有用性に関する「結論」です。”

**（Simu結果、その１）**


     imageJRL3-45-1
![imageJRL3-45-1](/2023-10-23-QEUR23_ATTNS5/imageJRL3-45-1.jpg)

**（Simu結果、その２）**


     imageJRL3-45-2
![imageJRL3-45-1](/2023-10-23-QEUR23_ATTNS5/imageJRL3-45-1.jpg)

D先生 ： “へえ・・・。こんな乱数指示のシミュレーションで3000点も行くんですね。”

QEU:FOUNDER ： “散布図をみると、**メトリックス（MAX畳み込みスコア）とパフォーマンス（スコア）には、明確な相関がある**でしょ？”

D先生 ： “見事な結果ですね。きっと、情報の集約度が高いのでしょう。”

QEU:FOUNDER ： “これから、たった６次元のベクトル（メトリックス群）で強化学習をすることになるけど、それなりに良い成績がでるんじゃないかと期待しています。”


## ～ まとめ ～

### ・・・ さらに、前回のつづきです ・・・

D先生 ： “うわぁ・・・。「Bing with Japanese」と「Perplexity with English」の回答は、その情報量が全然違うじゃないですか・・・。なんで、こんなに回答の質が違うのかな？ “

QEU:FOUNDER ： “いろんな可能性があります。LLMの「個性の反映（得意・不得意）」、入力言語の問題です。入力言語が一番「あやしい」けど、個人的には「RLHF(Reinforcement Learning with Human Feedback)」の存在に注目しているんです。RLHFというものは、あまり良いモノではないです。これが、小生が自分だけのLLMの開発を進めている理由です。さて、最後に「ちょっと変わった質問」をしてみましょう。Bing様への最後の御質問です。”

**(Question)**
あなたはイギリス人のジャーナリストです。人民元の国際化（海外貿易での決済）の現状と、今後の展望を教えてください。日本語以外の情報を参照して考察してください。

**(Bing with Japanese)**
こんにちは。私はBingです。人民元の国際化についての情報を調べました。2021年に中国人民銀行が発表した「2022年人民元国際化報告」によると、人民元の越境決済の金額が前年の高い基数をベースに増加し続けています。また、中国の対外受払に占める人民元建ての比率は2021年中47.4%、金額は36.61兆元、2022年1～6月では49.1%、20.32兆元に達しています。
CIPS（Cross-border Interbank Payment System）は中国の人民元クロスボーダー取引の決済システムであり、2021年中に処理した人民元クロスボーダー業務は334.16万件、前年比51.6％増、金額は79.60兆元、前年比75.8%の大幅増となっています。
ただし、**私たちは日本語以外の情報を参照することができません**。以上の情報が役立つことを願っています。


D先生 ： “なんじゃこれ？ “

QEU:FOUNDER ： “GPT4ほどの能力ならば、多国語翻訳は自由自在でしょ？それで、なぜこんな結果になるのでしょうか？この原因がRLHFにあると思っているんです。”

D先生 ： “なるほどね。私も**「もうRLHFはいらない」**に賛成です。自分がファインチューンしたLLMを自己責任で使っているんであるならば・・・。“

QEU:FOUNDER ： “RLHFは「アライメント(Alinement)」を向上させるためにやっているんですよね。じゃあ、**「アライメント」とは何かというと、なにかへの「忖度」**です。”

C部長 : “「忖度」って、元も子もない表現を・・・（笑）。”

QEU:FOUNDER ： “つまり、RLHFを突き詰めると、そのLLMの出力はそのユーザーが属する国のメディアの特徴（多くの場合、悪い意味で）に近づいてくる。その極めつきが、LLMが「ワタシはJ国のメディア情報しか引用しません」という態度になります。”

D先生 ： “その忖度が、QEUシステムが目指すところの**「世界平和のためのLLM」**の姿なんですか？“

QEU:FOUNDER ： “もちろん、違いますよ！同じ言語でインプットしても、立場を変えたら回答の質を全く変えてほしい。例えば、小生がJ国語で「アフリカについて知りたい」と質問したら、LLMはスワヒリ語の情報を読んで回答してほしい。「アフリカはこう考えている」と・・・。こうして**議論がばらつけばばらつくほど、世の中は平和になります**。”

D先生 ： “世の中に「忖度」が横行すると、逆に戦争が違づくと・・・？ “

QEU:FOUNDER ： “現状が証明しているじゃない？コレ（↓）なんかは、まさに同じ構造でしょ？”

[![MOVIE2](http://img.youtube.com/vi/IWqni4DUh_M/0.jpg)](http://www.youtube.com/watch?v=IWqni4DUh_M "【ジャニーズ事務所への「忖度」に切り込んだジャーナリスト】メディアへの「アメとムチ」の圧力／BBCの報道よりも影響を与えた被害者の会見／所属タレントの今後どうなるの")



D先生 ： “確かに、全く同じ構造です。“

QEU:FOUNDER ： “**LLMに丁寧な言葉遣いを教えたいのであれば、データセットを改善すればいいだけ**ですよ。なんで、その「簡単なこと」に手を付けないのか、小生には訳が分かんないです。”

D先生 ： “意外と、RLHFの必要性の議論って、「業界のタブー」かもしれないですね。 “

QEU:FOUNDER ： “RLHFの施していない、かつ性能の高い(pre-trained)LLMってあるのかな？でも、そういうことを考えることは大事だと思うよ。我々は、その「第一歩」を行っているわけです。”
