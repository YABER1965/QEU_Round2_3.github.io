---
title: QEUR23_ATTNS20: SOART メトリックスからATTENTIONを計算する(判別分析用verA)
date: 2023-11-10
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_ATTNS20: SOART メトリックスからATTENTIONを計算する(判別分析用verA)

## ～ この(Attention)メトリックスには「何かが」足りない・・・ ～

QEU:FOUNDER ： “じゃあ、今回は簡単にいきましょう。QKVマトリックスの内容を変えてみましょう。**「審査員」を入れ替えます。**”

![imageJRL3-60-1](/2023-11-10-QEUR23_ATTNS20/imageJRL3-60-1.jpg)

C部長 : “そうですね。判別用に、NORMAL,ERROR(A),ERROR(B)のメンバにしましょう。”

![imageJRL3-60-2](/2023-11-10-QEUR23_ATTNS20/imageJRL3-60-2.jpg)

QEU:FOUNDER ： “それでは、補足はない、さくっとプログラムをドン。”

```python
# ---------------- 
# SOARTメトリックスを読み込み、ATTENTIONメトリックスを計算する(Classification-ver.A)
# ---------------- 
# 数値計算のﾗｲﾌﾞﾗﾘ読み込み
import fastbook
import math
import numpy as np
import copy, random, time
import pandas as pd
#import matplotlib.pyplot as plt
#%matplotlib inline

#=================================================
# READ image CSV FILES
#=================================================
# データの種類
# (学習用) : learn_btY1, learn_snY2, learn_gmY3
# (検証用) : valid_btY1, valid_snY2, valid_gmY3
# ---------------------------
# 画像csvファイルを読み込み
def read_partscsv(file_readcsv): 
 
    # ---------------------------
    # 画像csvファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    #print(df)
    # ---------------------------
    # 原因系Xsマトリックス
    mx_Xs = df.loc[:,"X0":"X3"].values
    #print("----- mx_Xs:{0} -----".format(file_readcsv))
    #print(mx_Xs)
  
    return mx_Xs

# -----
# DB引用先
#list_learn = ['learn_btY1_class', 'learn_snY2_class', 'learn_gmY3_class']
list_learn = ['learn_btY1_gs_class', 'learn_snY2_gs_class', 'learn_gmY3_gs_class']
list_valid = ['valid_btY1_gs', 'valid_snY2_gs', 'valid_gmY3_gs']

# -----
# 学習用データベース(list_learn)
# -----
# query
file_learn = list_learn[0] + ".csv"  # ファイルパス名の生成 
#print(file_learn)
mx_query = read_partscsv(file_learn)
# 統計値の生成
val_meanY1 = np.mean(mx_query)
val_maxY1  = np.max(mx_query)
val_minY1  = np.min(mx_query)
# 正規化
mx_query = (mx_query - val_minY1) / (val_maxY1 - val_minY1)*2
# 転置
mx_query_T = mx_query.transpose()
print("--- mx_query_T ---")
print(mx_query_T)
# -----
# key
file_learn = list_learn[1] + ".csv"  # ファイルパス名の生成 
mx_key = read_partscsv(file_learn)
# 統計値の生成
val_meanY2 = np.mean(mx_key)
val_maxY2  = np.max(mx_key)
val_minY2  = np.min(mx_key)
# 正規化
mx_key = (mx_key - val_minY2) / (val_maxY2 - val_minY2)*2
# 転置
mx_key_T = mx_key.transpose()
print("--- mx_key_T ---")
print(mx_key_T)
# -----
# value
file_learn = list_learn[2] + ".csv"  # ファイルパス名の生成 
mx_value = read_partscsv(file_learn)
# 統計値の生成
val_meanY3 = np.mean(mx_value)
val_maxY3  = np.max(mx_value)
val_minY3  = np.min(mx_value)
# 正規化
mx_value = (mx_value - val_minY3) / (val_maxY3 - val_minY3)*2
# 転置
mx_value_T = mx_value.transpose()
print("--- mx_value_T ---")
print(mx_value_T)

# -----
# 学習用データベースをさらに補正する
# -----
max_row = mx_value.shape[0]
max_col = mx_value.shape[1]
for i in range(max_row):
    for j in range(max_col):
        # Q
        if mx_query[i,j] < 0.5:
            mx_query[i,j] = 0
        else:
            mx_query[i,j] = mx_query[i,j] ** 2.0
        # K
        if mx_key[i,j] < 0.5:
            mx_key[i,j] = 0
        else:
            mx_key[i,j] = mx_key[i,j] ** 2.0
        # V
        if mx_value[i,j] < 0.5:
            mx_value[i,j] = 0
        else:
            mx_value[i,j] = mx_value[i,j] ** 2.0
# 転置
mx_query_T = mx_query.transpose()
print(mx_query_T)
mx_key_T = mx_key.transpose()
print(mx_key_T)
mx_value_T = mx_value.transpose()
print(mx_value_T)

# -----
# 検証用データベース(list_valid)
# -----
# query
file_valid = list_valid[0] + ".csv"  # ファイルパス名の生成 
#print(file_valid)
mx_query_valid = read_partscsv(file_valid)
# 正規化
mx_query_valid = (mx_query_valid - val_minY1) / (val_maxY1 - val_minY1)*2
#print(mx_query_valid)
# -----
# key
file_valid = list_valid[1] + ".csv"  # ファイルパス名の生成 
mx_key_valid = read_partscsv(file_valid)
# 正規化
mx_key_valid = (mx_key_valid - val_minY2) / (val_maxY2 - val_minY2)*2
#print(mx_key_valid)
# -----
# value
file_valid = list_valid[2] + ".csv"  # ファイルパス名の生成 
mx_value_valid = read_partscsv(file_valid)
# 正規化
mx_value_valid = (mx_value_valid - val_minY3) / (val_maxY3 - val_minY3)*2
#print(mx_value_valid)

# -----
# 検証用データベースをさらに補正する
# -----
max_row = mx_value_valid.shape[0]
max_col = mx_value_valid.shape[1]
for i in range(max_row):
    for j in range(max_col):
        # Q
        if mx_query_valid[i,j] < 0.3:
            mx_query_valid[i,j] = 0
        else:
            mx_query_valid[i,j] = mx_query_valid[i,j]
        # K
        if mx_key_valid[i,j] < 0.3:
            mx_key_valid[i,j] = 0
        else:
            mx_key_valid[i,j] = mx_key_valid[i,j]
        # V
        if mx_value_valid[i,j] < 0.3:
            mx_value_valid[i,j] = 0
        else:
            mx_value_valid[i,j] = mx_value_valid[i,j]
# 表示
print(mx_query_valid)
print(mx_key_valid)
print(mx_value_valid)

# ----------
# input data(WORDS) SETUP
# ----------
from numpy import array
from numpy import random
from numpy import dot
from scipy.special import softmax

acc_words = []
for i in range(3):
    if i == 0:
        acc_words.append(mx_query_valid)
    if i == 1:
        acc_words.append(mx_key_valid)
    if i == 2:
        acc_words.append(mx_value_valid)
#print(acc_words)

# ----
# CALCULATION OF ATTENTIONS
# ----
acc_att = []
for i in range(3):

    # ----------
    # INPUT(WORDS)を読み込み
    words = acc_words[i]

    # ----------
    # CALCULATION OF ATTENTION
    # generating the weight matrices
    #W_Q = mx_query_T
    #W_K = mx_key_T
    W_Q = mx_value_T    # mxvalue -> gamma値
    W_K = mx_query_T    # mxquery -> 感度(beta値)
    W_V = mx_key_T      # mxkey -> SN比(ita値)

    # generating the queries, keys and values
    Q = words @ W_Q
    K = words @ W_K
    V = words @ W_V

    # scoring the query vectors against all key vectors
    scores = Q @ K.transpose()

    # computing the weights by a softmax operation
    weights = softmax(scores / K.shape[1] ** 0.5, axis=1)

    # computing the attention by a weighted sum of the value vectors
    attention = weights @ V
    for row in range(30):
        for col in range(9):
            attention[row,col] = round(attention[row,col],5)
    acc_att.append(attention.tolist())
    
# ----
# 生データを出力する 
acc_att = np.array(acc_att)
#print(acc_att)
# ----
# 結果を分割して、見やすく出力する
# ----
for i in range(3):
    attention_out = acc_att[i]
    print("---- Y{} ----".format(i))
    print("---- NORMAL ----")
    print(attention_out[0:10])
    # ----
    print("---- ERROR(A) ----")
    print(attention_out[10:20])
    # ----
    print("---- ERROR(B) ----")
    print(attention_out[20:30])
    # -----
    # CSVデータを出力する(RAW)
    # -----
    # dataframeに変換
    df_out = pd.DataFrame(attention_out)
    # CSVファイルに出力
    name_fileout = 'attention_Y{}_raw_verA.csv'.format(i+1)
    df_out.to_csv(name_fileout)

```

QEU:FOUNDER ： “今回は見やすくするためにEXCELで結果を出力しています。Cさん、満足したかな？”

![imageJRL3-60-3](/2023-11-10-QEUR23_ATTNS20/imageJRL3-60-3.jpg)

C部長 : “もちろん、わかりやすくなりました。行が計測画像であり、列が学習マトリックス（審査員メンバ）ですね。審査員の影響が強くでており、計測対象の影響は相対的に小さいです。計測対象の影響を見るには、もうちょっと工夫が必要ですね。”

QEU:FOUNDER ： “じゃあ、計測対象の差異のみに注目するようにテーブルの値を処理しましょう。”

![imageJRL3-60-4](/2023-11-10-QEUR23_ATTNS20/imageJRL3-60-4.jpg)

C部長 : “さすがに差分だけを抽出すると、変化がよくわかりやすくなります。ただ、テーブル上にドバーっと値が多量に出てくるので、うまく解釈できません。どういう風に解釈すればいいんですかね？”

QEU:FOUNDER ： “罫線で区切ったブロックがありますが、この範囲内で似たような値が出てくる頻度を数えるのが、良いんじゃないでしょうか？”

C部長 : “どういう意味？”

QEU:FOUNDER ： “**範囲内のすべての値がマイナス、もしくは全部がプラスになる。**”

C部長 : “もしも0値に近いと、マイナスとプラスが半々になっている・・・。この観点で見ると、学習データがnormalのときには、0値に近いのでしょうね。その他のerrorAやerrorBのパフォーマンスもまだまだですね。このパフォーマンスを改善する方法はないんでしょうか？”

QEU:FOUNDER ： “すこし気になることがあるから調査中ですが、手法を変えてみれば良くなるかもしれません。是非、カンパをお願いします！！”

## [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-created&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)
 
D先生 ： “ただいま発明中です。ご寄付のご検討をよろしくお願いします。”


## ～ まとめ ～

D先生(設定年齢65歳) ： “この人（↓）、理学博士のタマゴ！？それにしても、毎回すごく良い解説動画を出し続けています。・・・でも、このAttentionの解説はよくわからなかったですが・・・。 “

[![MOVIE1](http://img.youtube.com/vi/bPdyuIebXWM/0.jpg)](http://www.youtube.com/watch?v=bPdyuIebXWM "【深層学習】Attention - 全領域に応用され最高精度を叩き出す注意機構の仕組み【ディープラーニングの世界 vol. 24】")

QEU:FOUNDER(設定年齢65歳) ： “これは、機械翻訳の立場からAttentionを見ています。あと、このテクノロジの効果に注目して解説しているので、我々が関心のある数理（↓）とはずれているんです。”

![imageJRL3-60-5](/2023-11-10-QEUR23_ATTNS20/imageJRL3-60-5.jpg)

D先生 ： “肝心のAttentionの数理が出てこないんじゃ困りますね。もっといいもの（動画）はないかな・・・。“

[![MOVIE2](http://img.youtube.com/vi/50XvMaWhiTY/0.jpg)](http://www.youtube.com/watch?v=50XvMaWhiTY "【深層学習】Transformer - Multi-Head Attentionを理解してやろうじゃないの【ディープラーニングの世界vol.28】")

QEU:FOUNDER ： “これ（↑）はよくできています。我々にピッタリ！”

D先生 ： “コレコレ！！これを勉強して続きにいきましょう。“
