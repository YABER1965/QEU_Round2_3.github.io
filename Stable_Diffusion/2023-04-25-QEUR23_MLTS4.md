---
title: QEUR23_MLTS4:　閑話休題～「Embedding」ってなんだ！？ 
date: 2023-04-25
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_MLTS4:　閑話休題～「Embedding」ってなんだ！？ 

## ～　「天下統一」により、全部やり直し！　～

QEU:FOUNDER  ： “ああ・・・、失敗した・・・。”

[![MOVIE1](http://img.youtube.com/vi/CBZWzQVcXE4/0.jpg)](http://www.youtube.com/watch?v=CBZWzQVcXE4 "【深層学習】GPT-3 ①-1 モデルと Sparse Trans-former について【ディープラーニングの世界vol.39】")

D先生 ： “この動画（↑）についてですか？今、話題の**「アレ(GPT)」**の話ですが・・・。”

C部長  ： “FOUNDERは、このチャンネルを数年前から見てましたよねえ・・・。最近は見てなかったの？”

QEU:FOUNDER  ： “うん。率直、最近は見てなかった・・・（笑）。これを見てわかったんですが、LLM（大規模言語モデル）って、かなり前から**「大変身(Transformer)」**を遂げていたんですね。そして、今、話題のコレ（↓）もずいぶん前から話題になっていた・・・。”

![imageJRL3-24-1](/2023-04-25-QEUR23_MLTS4/imageJRL3-24-1.jpg)

C部長 ： “ あ？Few-shotの件？つまりPrompt_Engineeringの事ですね。あのO社の天才の集まりがやった一大プロジェクトなんだから、この程度の手法について気が付かないわけがないですよね。”

QEU:FOUNDER  ： “小生も、もうちょっと前に知っていたら、まだ知らない人たち相手に**「私のとっておきの方法を教えます」**とかいって大きな顔が出来たかも・・・（笑）。でも、このように技術の全容を把握出来たら、「とうとう天下統一か・・・」と感慨深いものがあったね。”

C部長  ： “皆が生きてるうちにはないだろうと思っていた、**「真のイノベーション」**というのを見ることになりました。”

QEU:FOUNDER  ： “一方、昔は戦国時代であり、**「なんでも言ったもん勝ち」**でした。**「〇〇はイノベーション」とか、「〇〇は一石全鳥」とか気軽に言えた**わけ・・・。・・・でも、ホントのイノベーション、一石全鳥がでてきて・・・。”

![imageJRL3-24-2](/2023-04-25-QEUR23_MLTS4/imageJRL3-24-2.jpg)

D先生： “**誰でも「イノベーション！！」と言うのは勝手だが、聞き手からは「いまさら何をいっとる？」とも思われる時代の到来**ですね。まさに天下統一後の世界！！”

QEU:FOUNDER  ： “そもそもの話、J国にイノベーションがあったならば、今の状況がこうなっていないって・・・(笑)。さて、今後、新しい手法を提案するにあたって**「ソレを知らなくて議論する」**とか、さらには**「ソレを敢えて無視する」**というのは**「ほとんど犯罪（行為）」**でしょう？逆に言うと、ソレを使いこなせている人があえて別の方法を使っているとなっていないと・・・。”

C部長  ： “つまり、最近、FOUNDERのブログのアップが遅くなっているのは天下統一による影響なんですね・・・。”

QEU:FOUNDER  ： “しゃあないよね。さて、今回は閑話休題としてCollaboration_Filteringをやります。もちろん、あのFast.aiをベースとして・・・。”

![imageJRL3-24-3](/2023-04-25-QEUR23_MLTS4/imageJRL3-24-3.jpg)

QEU:FOUNDER  ： “Rachel Thomas先生の教えなのか知りませんが、Fast.aiを勉強した学生が自分の言葉で語るためにブログをたくさん上げています。もちろん、Jeremy Howard大先生のnotebookを見るのがもっとも確かでしょうが、他の人のブログを読むのも一興だよね。”

C部長 ： “・・・ということは、今回は思わず過去を反省し、「素直にPyTorchベースでCollaboration_filteringをやります」とか・・・。”

QEU:FOUNDER  ： “それはどうかな？それではプログラムをドン・・・。諸先輩方と同じプログラムだし、しかも一部なので現実には参考にならないよ。”

```python
# collaboration_filtering_fastai
from fastbook import *
from fastai.collab import *
from fastai.tabular.all import *
path = untar_data(URLs.ML_100k);path

# -----
ratings = pd.read_csv(path/'u.data', delimiter='\t', header=None,
                      names=['user','movie','rating','timestamp'])
ratings.head()

```

![imageJRL3-24-4](/2023-04-25-QEUR23_MLTS4/imageJRL3-24-4.jpg)

```python
# -----
last_skywalker = np.array([0.98,0.9,-0.9])
user1 = np.array([0.9,0.8,-0.6])
(user1*last_skywalker).sum()

# -----
casablanca = np.array([-0.99,-0.3,0.8])
(user1*casablanca).sum()

```

C部長  ： “潜在変数(latent_factors)を設定して、その**内積をとる**というのがCollabolation_Filteringの本質なんですね。”

QEU:FOUNDER  ： “データはエクセルで簡単な表にまとまります。”

![imageJRL3-24-5](/2023-04-25-QEUR23_MLTS4/imageJRL3-24-5.jpg)

QEU:FOUNDER  ： “でも、当たり前ながら、その潜在変数をどのように計算するのかが重要で、ここでディープラーニングを使います。”

```python
# -----
movies = pd.read_csv(path/'u.item',  delimiter='|', encoding='latin-1',
                     usecols=(0,1), names=('movie','title'), header=None)
movies.head()

```

![imageJRL3-24-6](/2023-04-25-QEUR23_MLTS4/imageJRL3-24-6.jpg)

```python
# -----
ratings = ratings.merge(movies)
ratings.head()

# -----
dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)
dls.show_batch()

```

![imageJRL3-24-7](/2023-04-25-QEUR23_MLTS4/imageJRL3-24-7.jpg)

```python
# -----
class DotProduct(Module):
    def __init__(self, n_users, n_movies, n_factors):
        self.user_factors = Embedding(n_users, n_factors)
        self.movie_factors = Embedding(n_movies, n_factors)
        
    def forward(self, x):
        users = self.user_factors(x[:,0])
        movies = self.movie_factors(x[:,1])
        return (users * movies).sum(dim=1)

# -----
model = DotProduct(n_users, n_movies, 50)
learn = Learner(dls, model, loss_func=MSELossFlat())
learn.fit_one_cycle(5, 5e-3)

```

![imageJRL3-24-8](/2023-04-25-QEUR23_MLTS4/imageJRL3-24-8.jpg)

QEU:FOUNDER  ： “ここで、小生はわからなくなってやめました。**Embeddingってなんだ**？”

C部長 ： “ Jeremy Howardは、その講義で解説を行っていないの？”

QEU:FOUNDER  ： “**Fast.aiは実践を優先する講座なので**、ここの説明はスキップしているっぽい・・・。Fast.aiというのは、他にも高度な画像認識技術などを説明しているんですが、ディープラーニングの詳細はあえて説明しないようにしているんです。逆に言うと、それを説明しなくても良いんです。なぜなら、ResNetなどのPre-Trainingされたモデルを使うのが前提ですから・・・。”

D先生 ： “我々は、ずっと汎用関数の当てはめ手段としてディープラーニングを使ってきました。だから、テーマごとに何層の関数にするか、ノード数を何個にするとかの設計が必要でした。”

QEU:FOUNDER  ： “そういう背景をもつ我々からしてみたら、全く別体系のEmbeddingがいきなり来たので、「えっ！？」と立ち止まるわけ・・・。”

[![MOVIE2](http://img.youtube.com/vi/0CXCqxQAKKQ/0.jpg)](http://www.youtube.com/watch?v=0CXCqxQAKKQ "【深層学習】word2vec - 単語の意味を機械が理解する仕組み【ディープラーニングの世界 vol. 21】")

QEU:FOUNDER  ： “そして、Embeddingを語るのには、さらに**word2vec技術**のあたりまでさかのぼっちゃうわけ・・・。”

D先生 ： “そういえば、Fast.aiは、昔、Rachel先生が**自然言語処理（NLP）についての講義**をやっていました・・・。”

QEU:FOUNDER  ： “必要ならば、そこら辺まで戻らないと何も始まらないわけ。もう、**世は「天下統一」されちゃった**から・・・。”


## ～　まとめ　～

QEU:FOUNDER ： “あたらしいコンペがあるらしいよ。またもや賞金が安すぎ（50,000USD）ですが・・・。”

![imageJRL3-24-9](/2023-04-25-QEUR23_MLTS4/imageJRL3-24-9.jpg)

C部長 : “なるほど。**SfM(Structure from Motion)**技術の応用ですね。ただし、実際には非常に大きなブレークスルーを目指しています。例えば、インターネットでピサの斜塔の画像を収集したとします。そのバラバラなデータ群（画像）を解析して、本当に3次元データが生成できるかという。てか、そんなモンできるか・・・（笑）。”

![imageJRL3-24-10](/2023-04-25-QEUR23_MLTS4/imageJRL3-24-10.jpg)

QEU:FOUNDER ： “ただし、今の主流のSfMは画像のバラツキが少ないこと（おなじ時間で撮る、場所を少しだけずらして撮る、おなじカメラで撮るetc）が前提ですね。インターネットの画像を集めて、本当に3次元のデータができるのかなぁ・・・。”

C部長 : “ただし、このコンペの主催者には**「あのG社」**がいるらしいです。彼らからしてみたら、もうすでにできているのかもしれません。FOUNDERだったら、このテーマにどう対応しますか？”

![imageJRL3-24-11](/2023-04-25-QEUR23_MLTS4/imageJRL3-24-11.jpg)

QEU:FOUNDER ： “そもそものSfMはOpenCVなどで採用されている特徴点検出(SIFT,ORB,etc)で2次元座標を算出し、各画像の一致した特徴点の位置の差異から画像を撮った位置と角度を推定し、徐々に3次元情報を生成します。しかし、撮った時間（太陽の様子、季節単位の差異）が違えば、それらの特徴点が本当に安定するのか？”

![imageJRL3-24-12](/2023-04-25-QEUR23_MLTS4/imageJRL3-24-12.jpg)

C部長 : “**単純に特徴点マッチング技術をベースにはできません**ね・・・。”

QEU:FOUNDER ： “むしろ、CNN（畳み込みニューラルネット）で画像を撮影した位置や角度を推定したほうが楽かもしれません。そして、CNNの推定をもとに特徴点の距離も少し補正できればバラツキの大きなインターネットからの収集画像間でも特徴点の一致度が上がるでしょう。”

C部長 : “ＣＮＮによる撮影位置の推定はディープラーニングである程度はできるとして、肝心の特徴点（距離）を補正するシステムを構築するには学習データが必要になります。Blenderなどで生成した3D仮想空間で撮った画像データが必要になります。しかし、今回のKaggleコンペでは、それは準備されていないでしょ？これはコード・コンペだし・・・。”

QEU:FOUNDER ： “あのＧ社なんだし、こんな難しい課題に対しても「腹案」があるんだろうなぁ・・・。最近は、こういうことを考えているので、単純にＴ法の応用例を「たれ流す」のをためらっているんですよ。もうちょっとでも「ちゃんとしよう」って・・・（笑）。”

C部長 : “・・・ともあれ、ようやく世の中の**SoTA(State of The Art)**との距離を意識するようになったのは、まあ見上げた意識向上です。”

