---
title: QEUR23_ATTNS15: グレースケールからRGBへ（判別用QKV）
date: 2023-11-7
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_ATTNS15: グレースケールからRGBへ（判別用QKV）

## ～ 結論：あまりお勧めしない ～

QEU:FOUNDER ： “さて、ＲＧＢデータを使った「単一メトリックス、3種データのぶっこみ」型のSOART3メトリックスでATTENTIONを計算してみました。これでも、異常判定としてQKVにnormalメンバを入れた場合には、ある程度の画像判別が可能だとわかりました。それでは、ＱＫＶの内容を種類判別型に変えてみるとどうなるのか？”

![imageJRL3-55-1](/2023-11-7-QEUR23_ATTNS15/imageJRL3-55-1.jpg)

C部長 : “以前はnormal群のメンバしかありませんでしたが、今回のトライアルではnormal,ErrorA,ErrorB群が均等に割り付けられています。FOUNDERの「コンクールの例え」の直感によると、かなり結果が変わりそうな気がします。”

QEU:FOUNDER ： “参考までに、前回のATTENTIONの計算結果を示します。”

**（前回：NORMAL）**

![imageJRL3-55-2](/2023-11-7-QEUR23_ATTNS15/imageJRL3-55-2.jpg)

**(ERROR-A)**

![imageJRL3-55-3](/2023-11-7-QEUR23_ATTNS15/imageJRL3-55-3.jpg)

**(ERROR-B)**

![imageJRL3-55-4](/2023-11-7-QEUR23_ATTNS15/imageJRL3-55-4.jpg)

QEU:FOUNDER ： “それでは、RGBによる評価を前回と同様に各種N=10でいきましょう。”

![imageJRL3-55-5](/2023-11-7-QEUR23_ATTNS15/imageJRL3-55-5.jpg)

QEU:FOUNDER ： “今回の晒しプログラムは、ATTENTIONの計算部分のみです。このプログラムはほとんど変わっていないので、参考までです。ドン！！”

```python
# ---------------- 
# SOARTメトリックスを読み込み、ATTENTIONメトリックスを計算する(Classification)
# ---------------- 
# 数値計算のﾗｲﾌﾞﾗﾘ読み込み
import fastbook
import math
import numpy as np
import copy, random, time
import pandas as pd
#import matplotlib.pyplot as plt
#%matplotlib inline

#=================================================
# READ image CSV FILES
#=================================================
# データの種類
# (検証用) : valid_btY1, valid_snY2, valid_gmY3
# (学習用) : learn_btY1, learn_snY2, learn_gmY3
# ---------------------------
# 画像csvファイルを読み込み
def read_partscsv(file_readcsv): 
 
    # ---------------------------
    # 画像csvファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    #print(df)
    # ---------------------------
    # 原因系Xsマトリックス
    mx_Xs = df.loc[:,"X0":"X3"].values
    #print("----- mx_Xs:{0} -----".format(file_readcsv))
    #print(mx_Xs)
  
    return mx_Xs

# -----
# DB引用先
list_learn = ['learn_btY1_rgb_class', 'learn_snY2_rgb_class', 'learn_gmY3_rgb_class']
list_valid = ['valid_btY1_rgb', 'valid_snY2_rgb', 'valid_gmY3_rgb']

# -----
# 学習用データベース(list_learn)
# -----
# BETA
file_learn = list_learn[0] + ".csv"  # ファイルパス名の生成 
#print(file_learn)
mx_beta = read_partscsv(file_learn)
# 正規化
mx_beta = mx_beta / np.mean(mx_beta)
# 転置
mx_beta_T = mx_beta.transpose()
print(mx_beta_T)
# -----
# ITA
file_learn = list_learn[1] + ".csv"  # ファイルパス名の生成 
mx_ita = read_partscsv(file_learn)
# 正規化
mx_ita = mx_ita / np.mean(mx_ita)
# 転置
mx_ita_T = mx_ita.transpose()
print(mx_ita_T)
# -----
# gamma
file_learn = list_learn[2] + ".csv"  # ファイルパス名の生成 
mx_gamma = read_partscsv(file_learn)
# 正規化
mx_gamma = mx_gamma / np.mean(mx_gamma)
# 転置
mx_gamma_T = mx_gamma.transpose()
print(mx_gamma_T)

# -----
# 検証用データベース(list_valid)
# -----
# query
file_valid = list_valid[0] + ".csv"  # ファイルパス名の生成 
#print(file_valid)
mx_beta_valid = read_partscsv(file_valid)
# 正規化
mx_beta_valid = mx_beta_valid / np.mean(mx_beta_valid)
print(mx_beta_valid)
# -----
# key
file_valid = list_valid[1] + ".csv"  # ファイルパス名の生成 
mx_ita_valid = read_partscsv(file_valid)
# 正規化
mx_ita_valid = mx_ita_valid / np.mean(mx_ita_valid)
print(mx_ita_valid)
# -----
# value
file_valid = list_valid[2] + ".csv"  # ファイルパス名の生成 
mx_gamma_valid = read_partscsv(file_valid)
# 正規化
mx_gamma_valid = mx_gamma_valid / np.mean(mx_gamma_valid)
print(mx_gamma_valid)

# ----
# CALCULATION OF ATTENTIONS
# ----
# import modules
from numpy import array
from numpy import random
from numpy import dot
from scipy.special import softmax

# ----
# input data(WORDS) SETUP
acc_words = []
for i in range(3):
    if i == 0:
        acc_words.append(mx_beta_valid)   # mx_beta(30 x 4)
    if i == 1:
        acc_words.append(mx_ita_valid)   # mx_ita(30 x 4)
    if i == 2:
        acc_words.append(mx_gamma_valid)   # mx_gamma(30 x 4)
#print(acc_words)

# ----
# CALCULATION OF ATTENTIONS
acc_att = []
for i in range(3):

    # ----------
    # INPUT(WORDS)を読み込み
    words = acc_words[i]

    # ----------
    # CALCULATION OF ATTENTION
    # generating the weight matrices
    W_Q = mx_gamma_T    # mxvalue -> gamma値_T (4 x 9)
    W_K = mx_beta_T    # mxquery -> 感度(beta値)_T (4 x 9)
    W_V = mx_ita_T      # mxkey -> SN比(ita値)_T (4 x 9)

    # generating the queries, keys and values
    Q = words @ W_Q     # Q->(30,9)
    K = words @ W_K     # K->(30,9)
    V = words @ W_V     # V->(30,9)

    # scoring the query vectors against all key vectors
    scores = Q @ K.transpose()

    # computing the weights by a softmax operation
    weights = softmax(scores / K.shape[1] ** 0.5, axis=1)

    # computing the attention by a weighted sum of the value vectors
    attention = weights @ V
    for row in range(30):
        for col in range(15):
            attention[row,col] = round(attention[row,col],4)
    acc_att.append(attention.tolist())
    
# ----
# 生データを出力する 
acc_att = np.array(acc_att)
print(acc_att)

# ----
# CSVに補正済データを出力する
def saveResult(filename_result, mx_result):
    # Save CSV file
    np.savetxt(filename_result, mx_result, delimiter=',')

# ----
# 出力された結果を補正する
acc_att2 = []
for i in range(3):
    attention2 = acc_att[i,:,:]
    for j in range(15):
        attention2[:,j] = attention2[:,j] - np.mean(attention2[:,j])
        attention2[:,j] = attention2[:,j]/(np.max(attention2[:,j]) - np.min(attention2[:,j]))
    for row in range(30):
        for col in range(15):
            attention2[row,col] = round(attention2[row,col],4)
    # --- 
    if i == 0:
        filename_result = "result_class_Beta.csv"
    if i == 1:
        filename_result = "result_class_Ita.csv" 
    if i == 2:
        filename_result = "result_class_Gamma.csv"
    saveResult(filename_result, attention2)   
    # ---  
    acc_att2.append(attention2.tolist())
# ----
acc_att2 = np.array(acc_att2)
print(acc_att2)

# ----
# 補正された結果を特徴量抽出して出力する
# ----
result     = np.zeros((30,9))
for i in range(30):
    arr_resultA  = [np.mean(acc_att2[0,i,0:5]), np.mean(acc_att2[0,i,5:10]), np.mean(acc_att2[0,i,10:15])]
    #print(arr_resultA)
    arr_resultB  = [np.mean(acc_att2[1,i,0:5]), np.mean(acc_att2[1,i,5:10]), np.mean(acc_att2[1,i,10:15])]
    arr_resultC  = [np.mean(acc_att2[2,i,0:5]), np.mean(acc_att2[2,i,5:10]), np.mean(acc_att2[2,i,10:15])]
    arr_result   = arr_resultA + arr_resultB + arr_resultC
    #print(arr_result)
    result[i,:]  = arr_result
print(result)

# ----
# 分割して出力する
# ----
print("---- NORMAL ----")
print(result[0:10])
# ----
print("---- ERROR(A) ----")
print(result[11:20])
# ----
print("---- ERROR(B) ----")
print(result[21:30])
```

QEU:FOUNDER ： “それでは、今回の計算結果を見てみましょう。ちょっと、残念な結果だが・・・。”

**（NORMAL）**

![imageJRL3-55-6](/2023-11-7-QEUR23_ATTNS15/imageJRL3-55-6.jpg)

**(ERROR-A)**

![imageJRL3-55-7](/2023-11-7-QEUR23_ATTNS15/imageJRL3-55-7.jpg)

**(ERROR-B)**

![imageJRL3-55-8](/2023-11-7-QEUR23_ATTNS15/imageJRL3-55-8.jpg)

C部長 : “表の列の数が6から9になってる・・・。この表のコラム（「列」）ってなんですか？”

QEU:FOUNDER ： “今回の審査員（QKVのメンバ数）が15人になりました。そのうち、norma1,errorA,errorB群が5人づつです。それに伴い、出力方法がさらに変わっているんです。”

### INPUT(1): Y1（β：感度）のnorma1,errorA,errorB群毎の平均値
### INPUT(2):  Y2(η:SN比)の同上
### INPUT(3):  Y3(γ:データ体積比)の同上

QEU:FOUNDER ： “**しっかりコードを読んで、出力の意味を理解してください。**”

C部長 : “ちょっとびっくり。私たちが思ったよりも、計算結果って変わらないんですねぇ・・・。しいていうと、より値の動きが複雑になって、もう訳が分からなくなりました。はっきりいって、このやり方は「使えない」ですね。”

QEU:FOUNDER ： “やっぱり画像データをRGBに分割したんだから、RTメトリックスも分割しないともったいないよね。それでは、このQ,K,Vメンバのままで、RTメトリックス出し方を変えてみましょう。現在、一歩一歩前進中。是非、カンパをお願いします！！”

### [＞寄付のお願い(click here)＜](<iframe width="560" height="315" src="https://www.youtube.com/embed/9NVQnJu23Mo?si=MZIRhc0RwThRO5EQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>)
 
D先生 ： “よろしくお願いします。”


## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

D先生(設定年齢65歳)  ： “そういえば、最近はオタクを無視している傾向があるわ・・・。「ちゃんとしてない人たち」だって・・・。“

QEU:FOUNDER(設定年齢65歳)  ： “「ちゃんとしている」という日本語の本質は、「周囲の期待に応える」という意味だからね。**モラルハラスメントそのもの**・・・。これから、「何かをしたい」というプラスのエネルギーを伸ばしていきたいのであれば、まずは**「オタクというマイノリティ」を育てて行かなければならない**。”

[![MOVIE1](http://img.youtube.com/vi/-mLu7o7biJU/0.jpg)](http://www.youtube.com/watch?v=-mLu7o7biJU "居港日裔茶記達人帶你新界搵食！精選3間特色店 入八鄉、古洞、流浮山 

D先生 ： “う～ん、（いいたいことは）よくわかる。でも、それでいいんかなぁ・・・。 “

QEU:FOUNDER： “いいアイデアだとおもうんだけど・・・。”

![imageJRL3-55-9](/2023-11-7-QEUR23_ATTNS15/imageJRL3-55-9.jpg)

D先生 ： “これ（↑）の、**Version2.0**（二の舞）じゃないの？“

QEU:FOUNDER： “思いっきりワロタ。”

