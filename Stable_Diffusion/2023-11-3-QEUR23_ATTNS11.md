---
title: QEUR23_ATTNS11: いよいよ、アテンション(ATTENTION)を始めましょう!
date: 2023-11-3
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_ATTNS11: いよいよ、アテンション(ATTENTION)を始めましょう!

## ～ さあて！いよいよ、「（小）発明」の段階がやってきた！ ～

C部長 : “SOART3法も、一応は（暫定）完成しています。それでは、いよいよATTENTIONへの応用に入りましょう。この技術は、ず～っと前に紹介しました。ボクもほとんど忘れていました。”

QEU:FOUNDER ： “以前紹介したATTENTIONのpythonプログラムは、もう一度使ってみたほうがいいです。今回も使いますので・・・。ちなみに、我らが大先生も同じくしょうかいしています。”

![imageJRL3-51-1](/2023-11-3-QEUR23_ATTNS11/imageJRL3-51-1.jpg)

C部長 : “ああ・・・。ディープラーニングを理解するときに、ずいぶんお世話になりました。Jeremy Howard（JH）の元で、より高度の応用を勉強し始めて遠ざかってしまいましたが・・・。”

QEU:FOUNDER ： “JHは応用の先生で、Jason Brownlee（JB）は基礎の先生です。最近は、JBはStable DiffusionやNLPについての説明を始めていますね。いつもながら丁寧で分かりやすい説明で、素人の小生としては、とても感謝しています。さて、さっそく「ネタ（データ）」を作成しましょうか。”

![imageJRL3-51-2](/2023-11-3-QEUR23_ATTNS11/imageJRL3-51-2.jpg)

C部長 : “あれあれ、ヘンテコな図ですね・・・（笑）。”

QEU:FOUNDER ： “適当に作りました（笑）。昔みたいに、Blenderのような高度のモノを使いません。もう面倒くさいから、Pythonで直接・・・。それでは、Pythonプログラムの紹介に入りますか。ドン・・・！”

```python

# 図形画像を描く
import numpy as np
from PIL import Image, ImageDraw

# ----
#im = Image.new('RGB', (500, 300), (88, 200, 88))
nam_dir = "./soart/"
nam_subdir1 = "learn/"
nam_subdir2 = "normal/"
nam_subdir3 = "error/"

##############################

# ----------
# 標準状態を描く
im2 = Image.new('RGB', (500, 500), (13, 77, 13))
draw = ImageDraw.Draw(im2)

# ----
# 円を描く（スミ）
draw.ellipse((40, 40, 160, 160), fill=(255, 10, 50), outline=(0, 0, 0))
draw.ellipse((340, 40, 460, 160), fill=(255, 50, 10), outline=(0, 0, 0))
draw.ellipse((40, 340, 160, 460), fill=(255, 10, 50), outline=(0, 0, 0))
draw.ellipse((340, 340, 460, 460), fill=(255, 50, 10), outline=(0, 0, 0))

# ----
# 線を描く（スミ）
draw.line((50, 100, 150, 100), fill=(10, 130, 250), width=30)
draw.line((100, 50, 100, 150), fill=(10, 130, 250), width=30)
draw.line((350, 400, 450, 400), fill=(40, 80, 250), width=30)
draw.line((400, 350, 400, 450), fill=(40, 80, 250), width=30)

# ----
# 正方形（中央）
draw.rectangle((150, 150, 350, 350), fill=(50, 250, 10), outline=(0, 0, 0))

# ----
# バツ印（中央）
draw.line((200, 200, 300, 300), fill=(50, 10, 250), width=60)
draw.line((300, 200, 200, 300), fill=(50, 10, 250), width=60)

# ----
# 欠円（上下左右）
draw.chord((30, 200, 130, 300), start=30, end=270, fill=(200, 55, 200), outline=(0, 0, 0))
draw.chord((370, 200, 470, 300), start=120, end=360, fill=(200, 55, 200), outline=(0, 0, 0))
draw.chord((200, 30, 300, 130), start=30, end=270, fill=(200, 55, 200), outline=(0, 0, 0))
draw.chord((200, 370, 300, 470), start=120, end=360, fill=(200, 55, 200), outline=(0, 0, 0))

# ----
im2.save(nam_dir+'image_standard.jpg', quality=95)
### 画像を表示する
#im2.show()

```

QEU:FOUNDER ： “これがたたき台です。これに**「ゆらぎ」**をつけたり、**「エラー（異常事象）」**を作成することもできます。”

![imageJRL3-51-3](/2023-11-3-QEUR23_ATTNS11/imageJRL3-51-3.jpg)

C部長 : “これが実験用のネタの生成ですね。”

QEU:FOUNDER ： “もちろん、これらの画像をそのまま使えないので、今回はCSVデータに変換します。ちなみに、白黒画像にしています。これも、プログラムをドン。”

```python
# ----------
# 画像をグレースケール、モザイク化し、CSV数値に保存する
# ----------
import cv2
import numpy as np

nam_dir = "./soart/"
nam_subdir1 = "learn/"
nam_subdir2 = "normal/"
nam_subdir3 = "error/"

# ---
def mosaic(src, ratio=0.1):
    small = cv2.resize(src, None, fx=ratio, fy=ratio, interpolation=cv2.INTER_NEAREST)
    return cv2.resize(small, src.shape[:2][::-1], interpolation=cv2.INTER_NEAREST), small

def image_process(src):

    dst_005, small = mosaic(src, ratio=0.06)
    #cv2.imshow('WindowName2', dst_005)
    #cv2.waitKey(0)
    #cv2.destroyAllWindows()

    # ---
    # Convert to grayscale
    dst_mosaic = cv2.cvtColor(dst_005, cv2.COLOR_BGR2GRAY)
    dst_small  = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
    #print(dst_small.shape)

    # ---
    # Display image
    #cv2.imshow('Grayscale Image', dst_mosaic)
    #cv2.waitKey(0)
    #cv2.destroyAllWindows()
    
    return dst_small

# -----
# MAIN ROUNTINE
list_image = []

# ---
image_nameA = 'image_standard'
list_image.append(image_nameA)
#print(arr_nameA)

# 学習用-通常(ゆらぎ)
for i in range(50):
    image_nameB = nam_subdir1+'image_base_fluctuate_{}'.format(i)
    list_image.append(image_nameB)
#print(arr_nameB)

# 検証用-通常
for i in range(10):
    image_nameC = nam_subdir2+'image_normal_{}'.format(i)
    list_image.append(image_nameC)
#print(arr_nameC)

# 検証用-エラーA
for i in range(10):
    image_nameC = nam_subdir3+'image_errorA_{}'.format(i)
    list_image.append(image_nameC)
#print(arr_nameC)

# 検証用-エラーB
for i in range(10):
    image_nameD = nam_subdir3+'image_errorB_{}'.format(i)
    list_image.append(image_nameD)
#print(arr_nameD)

# リストの統合
#list_image = [arr_nameA, arr_nameB, arr_nameC, arr_nameD]
print(list_image)

# PROCESS
for i in range(len(list_image)):

    # Read data
    src = cv2.imread(nam_dir+list_image[i]+'.jpg')

    # Process data
    dst_small = image_process(src)

    # Save CSV file
    np.savetxt(nam_dir+list_image[i]+'.csv', dst_small, delimiter=',')

```

QEU:FOUNDER ： “モザイク化して、***30x30のデータ(0-255)***にしました。”

![imageJRL3-51-4](/2023-11-3-QEUR23_ATTNS11/imageJRL3-51-4.jpg)

C部長 : “どうかなぁ・・・。***グレースケール(GS)***って、かなりの情報をオミットしてしまいましたね。”

D先生 ： “まあ、実験なのでシンプルなパターンから始めたいですね。これをSOART3の処理をするわけですね。”

QEU:FOUNDER  ： “いよいよ、行きましょう！是非、カンパをお願いします！！”

### [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-created&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)
 
 
D先生 ： “これは「発明」です。小さいですがね・・・。”


## ～ まとめ ～

D先生(設定年齢65歳) ： “今回はATTENTIONの実質の最初のブログになるので、ちょっとATTENTIONの技術について話をしたいのですが・・・。 “

QEU:FOUNDER(設定年齢65歳) ： “いろいろ調べてたんですが、小生のアタマでうまく理解できる記事が見つからなかったです。でも、D先生ならわかるかもしれない。こんなモノ（↓）ですが・・・。わかる？”

![imageJRL3-51-5](/2023-11-3-QEUR23_ATTNS11/imageJRL3-51-5.jpg)

QEU:FOUNDER ： “日本語に翻訳して差し上げました。あの、どういう意味か、教えてくれない・・・？”

Bahdanau et al.のアテンションメカニズムは、アライメントスコア、重み、およびコンテキスト ・ベクトルの段階的な計算に分けられていることに注意してください。
- 1.アラインメント・スコア: アライメント モデルは、エンコードされた隠れ状態 h_iと前のデコーダー出力 s_t-1 を使用して、入力シーケンスの要素が位置tで現在の出力とどの程度整列しているかを示すスコア e_t,i を計算します。線形モデルは、関数 a(.) で表され、フィードフォワードニューラルネットワークで実装できます。
et,i = a(st−1,ℎi)
- 2.重み: 重み α_t,i は、以前に計算されたアラインメント・スコアにソフトマックス演算を適用することによって計算されます。
αt,i=softmax (et,i)
- 3.コンテキスト ・ベクトル: 一意のコンテキスト ・ベクトル c_t が各タイム ステップでデコーダーに供給されます。これは、すべての T エンコーダーの隠れ状態の加重和によって計算されます。
ct=∑αt,i,ℎi

D先生 ： “ぜんぜん、わかりません・・・。 “

QEU:FOUNDER ： “実は、ATTENTIONのプログラムを見るともっとわかりやすいよ。小生は、こんな感じの構造のモノ（↓）だと思っています。”

![imageJRL3-51-6](/2023-11-3-QEUR23_ATTNS11/imageJRL3-51-6.jpg)

C部長 ： “なんと、アテンションとは**「コンクールの採点作業」**ですか・・・。“

D先生 ： “・・・ということは、**Q,K,Vのマトリックスの中には「採点者が大量に詰まっている」**んですね。そして、採点者が「この人、好き」、「いや～ん、この人」としてコンクール出場者に向けて数字を出力するということですね。 “

QEU:FOUNDER ： “こういうノリでATTENTIONメトリックスを見ると、あとでわかりやすくなりますよ。”

