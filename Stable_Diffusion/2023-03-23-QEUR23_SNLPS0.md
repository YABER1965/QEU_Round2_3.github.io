---
title: QEUR23_SNLPS0:　簡単な自然言語処理事例(：NLP, Yelp Review, その1)
date: 2023-03-23
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_SNLPS0:　簡単な自然言語処理事例(：NLP, Yelp Review, その1)

## ～　いやぁ・・・、やっぱり「最先端は重い」よねえ・・・　～

D先生 ： “今回からしばらくの間、**「自然言語分析(Natural Language Processing)」をやります**。そんなに高度なことはやりません。・・・というか、我々にはできない（笑）。”

![imageJRL3-10-1](/2023-03-23-QEUR23_SNLPS0/imageJRL3-10-1.jpg)

QEU:FOUNDER  ： “そんなにレベルの高いNLP（自然言語処理）をするつもりはありません。・・・ただし、**この最先端の領域に全く入らなくて言語処理の話をするのも視野が狭くなります**。そこで、今回はこの本(↓)を参考とします。”

![imageJRL3-10-2](/2023-03-23-QEUR23_SNLPS0/imageJRL3-10-2.jpg)

QEU:FOUNDER  ： “**こんな最先端の話題が(github)プログラム付きで教育用にリリースさせる時代になったのか・・・。時代の進化にしみじみしますわ**。さて、この本では当然ながら学習のためにニューラル・ネットを使用しています。我々はこの学習計算のために、かなり良いGPUを使ったつもりだが、思いのほか学習に時間がかかって驚いたよ。さすがに自然言語処理の計算規模は大変だ・・・。それではプログラムの紹介を始めますよ。この本のgithubがWebで検索すれば手に入るので、そこから例題のプログラムを開いてほしいです。”

![imageJRL3-10-3](/2023-03-23-QEUR23_SNLPS0/imageJRL3-10-3.jpg)

D先生 ： “これは何を予測するプログラムですか？”

**(ポジティブなコメントの集合)**

![imageJRL3-10-4](/2023-03-23-QEUR23_SNLPS0/imageJRL3-10-4.jpg)

QEU:FOUNDER ： “一言でいうと、**「Sentiment Analysis（文章の情感の分析）」**です。そして、解析に使うデータのYelp_Reviewというのは「口コミサイト」という意味です。この本はレストランの口コミの事例を使いま。このデータで代表的なポジティブな表現は「おいしい」であり。”

**(ネガティブなコメントの集合)**

![imageJRL3-10-5](/2023-03-23-QEUR23_SNLPS0/imageJRL3-10-5.jpg)

D先生 ： “その逆のネガティブの代表例は「まずい」になりますね。”

QEU:FOUNDER ： “計算結果を紹介するために便宜的にコードを晒しています。しかし、コードに中略が激しいので気をつけて、自分でオリジナルを見つけてね。それではプログラムをドン！！”

```python
# Classifying Yelp Reviews
# Imports
from argparse import Namespace
from collections import Counter
import json
import os
import re
import string
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from tqdm import notebook

# ------
# Data Vectorization classes
# The Vocabulary
class Vocabulary(object):
    """Class to process text and extract vocabulary for mapping"""

    def __init__(self, token_to_idx=None, add_unk=True, unk_token="<UNK>"):
        """
        Args:
            token_to_idx (dict): a pre-existing map of tokens to indices
            add_unk (bool): a flag that indicates whether to add the UNK token
            unk_token (str): the UNK token to add into the Vocabulary
        """

        if token_to_idx is None:
            token_to_idx = {}
        self._token_to_idx = token_to_idx

        self._idx_to_token = {idx: token 
                              for token, idx in self._token_to_idx.items()}
        
        self._add_unk = add_unk
        self._unk_token = unk_token
        
        self.unk_index = -1
        if add_unk:
            self.unk_index = self.add_token(unk_token) 
        
        
    def to_serializable(self):
        """ returns a dictionary that can be serialized """
        return {'token_to_idx': self._token_to_idx, 
                'add_unk': self._add_unk, 
                'unk_token': self._unk_token}

    @classmethod
    def from_serializable(cls, contents):
        """ instantiates the Vocabulary from a serialized dictionary """
        return cls(**contents)

    def add_token(self, token):
        """Update mapping dicts based on the token.

        Args:
            token (str): the item to add into the Vocabulary
        Returns:
            index (int): the integer corresponding to the token
        """
        if token in self._token_to_idx:
            index = self._token_to_idx[token]
        else:
            index = len(self._token_to_idx)
            self._token_to_idx[token] = index
            self._idx_to_token[index] = token
        return index
    
    def add_many(self, tokens):
        """Add a list of tokens into the Vocabulary
        
        Args:
            tokens (list): a list of string tokens
        Returns:
            indices (list): a list of indices corresponding to the tokens
        """
        return [self.add_token(token) for token in tokens]

    def lookup_token(self, token):
        """Retrieve the index associated with the token 
          or the UNK index if token isn't present.
        
        Args:
            token (str): the token to look up 
        Returns:
            index (int): the index corresponding to the token
        Notes:
            `unk_index` needs to be >=0 (having been added into the Vocabulary) 
              for the UNK functionality 
        """
        if self.unk_index >= 0:
            return self._token_to_idx.get(token, self.unk_index)
        else:
            return self._token_to_idx[token]

    def lookup_index(self, index):
        """Return the token associated with the index
        
        Args: 
            index (int): the index to look up
        Returns:
            token (str): the token corresponding to the index
        Raises:
            KeyError: if the index is not in the Vocabulary
        """
        if index not in self._idx_to_token:
            raise KeyError("the index (%d) is not in the Vocabulary" % index)
        return self._idx_to_token[index]

    def __str__(self):
        return "<Vocabulary(size=%d)>" % len(self)

    def __len__(self):
        return len(self._token_to_idx)

# -----
# 中間をスキップしています： くわしくはgithubを見てね
# -----

# ------
# compute the loss & accuracy on the test set using the best available model
classifier.load_state_dict(torch.load(train_state['model_filename']))
classifier = classifier.to(args.device)

dataset.set_split('test')
batch_generator = generate_batches(dataset, 
                                   batch_size=args.batch_size, 
                                   device=args.device)
running_loss = 0.
running_acc = 0.
classifier.eval()

for batch_index, batch_dict in enumerate(batch_generator):
    # compute the output
    y_pred = classifier(x_in=batch_dict['x_data'].float())

    # compute the loss
    loss = loss_func(y_pred, batch_dict['y_target'].float())
    loss_t = loss.item()
    running_loss += (loss_t - running_loss) / (batch_index + 1)

    # compute the accuracy
    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])
    running_acc += (acc_t - running_acc) / (batch_index + 1)

train_state['test_loss'] = running_loss
train_state['test_acc'] = running_acc

print("Test loss: {:.3f}".format(train_state['test_loss']))
print("Test Accuracy: {:.2f}".format(train_state['test_acc']))

# ------
# Inference(推論)
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r"([.,!?])", r" \1 ", text)
    text = re.sub(r"[^a-zA-Z.,!?]+", r" ", text)
    return text

def predict_rating(review, classifier, vectorizer, decision_threshold=0.5):
    """Predict the rating of a review
    
    Args:
        review (str): the text of the review
        classifier (ReviewClassifier): the trained model
        vectorizer (ReviewVectorizer): the corresponding vectorizer
        decision_threshold (float): The numerical boundary which separates the rating classes
    """
    review = preprocess_text(review)
    
    vectorized_review = torch.tensor(vectorizer.vectorize(review))
    result = classifier(vectorized_review.view(1, -1))
    
    probability_value = torch.sigmoid(result).item()
    index = 1
    if probability_value < decision_threshold:
        index = 0

    return vectorizer.rating_vocab.lookup_index(index)

#test_review = "this is a pretty awesome book"
test_review = "this book is terrible!"

classifier = classifier.cpu()
prediction = predict_rating(test_review, classifier, vectorizer, decision_threshold=0.5)
print("{} -> {}".format(test_review, prediction))

```

QEU:FOUNDER ： “今回で学習したデータベースはレストランのものですが、学習した内容は他のコメントのsentimentを推定するのに、**ある程度は使う**ことができます。それではやってみましょう。”

![imageJRL3-10-6](/2023-03-23-QEUR23_SNLPS0/imageJRL3-10-6.jpg)

D先生 ： “この場合は本の評判のコメントを書いています。さしあたりは、うまく判別しているようですね。”

QEU:FOUNDER  ： “そして、まとめとして、**ポジティブとネガティブを決める重要な単語**をリストアップしました。”

```python
# ------
# Sort weights
fc1_weights = classifier.fc1.weight.detach()[0]
_, indices = torch.sort(fc1_weights, dim=0, descending=True)
indices = indices.numpy().tolist()

# Top 20 words
print("Influential words in Positive Reviews:")
print("--------------------------------------")
for i in range(20):
    print(vectorizer.review_vocab.lookup_index(indices[i]))
    
print("====\n\n\n")

# Top 20 negative words
print("Influential words in Negative Reviews:")
print("--------------------------------------")
indices.reverse()
for i in range(20):
    print(vectorizer.review_vocab.lookup_index(indices[i]))
```

D先生 ： “なるほどね。それらしい単語群が出力されていますね。”

**(POSITIVE WORD: BEST20)**

![imageJRL3-10-7](/2023-03-23-QEUR23_SNLPS0/imageJRL3-10-7.jpg)

**(NEGATIVE WORD: BEST20)**

![imageJRL3-10-8](/2023-03-23-QEUR23_SNLPS0/imageJRL3-10-8.jpg)

D先生 ： “ディープラーニングでやって答えがやっと出るものを、**あの簡単なT法(2)でやれる**んですか？”

QEU:FOUNDER ： “その質問の回答はアトで・・・、次もさらに寄り道します。”



## ～　まとめ　～

QEU:FOUNDER ： “これ（↓）が決定版だね。”

[![MOVIE1](http://img.youtube.com/vi/AKT8wCM522E/0.jpg)](http://www.youtube.com/watch?v=AKT8wCM522E "三浦瑠麗氏、夫逮捕で会社でスタッフ共々ヤケクソ酒盛り。その上、自身の逮捕について否定せず。")

C部長 : “なにが？”

![imageJRL3-10-9](/2023-03-23-QEUR23_SNLPS0/imageJRL3-10-9.jpg)

QEU:FOUNDER ： “とうとうJ国の衰退の原因がわかった。それは**「コミュ力」・・・、その正体は「ハラスメント」・・・**。”

### おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」

### オッサン（＠車中、N社検査不正について）：　「“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ・・・」

C部長 : “**お前が変われ、俺は変わらん**・・・(笑)。特に、硬直化した組織と、その**思想にかぶれたオッサン**が危ない。”

QEU:FOUNDER ： “しかし、**急激に変化する世の中では、「俺(組織)は変わらん」という考え方は通用しない**・・・。”

![imageJRL3-10-10](/2023-03-23-QEUR23_SNLPS0/imageJRL3-10-10.jpg)

QEU:FOUNDER ： “一方、組織（+くるくるしたオッサンなど）は従業員に**絶え間ないハラスメント**を与えているので、会社には変化に適用するためのパワーが内部からは生まれないんですね。”

C部長 : “当たり前でしょ？**会社で生き残りたいのであれば、組織を変えるような言動はやらない**ですよ。ん・・・と、結局、この件（↓）と同じですね。”

[![MOVIE2](/2023-03-23-QEUR23_SNLPS0/imageJRL3-10-11.jpg)](http://www.youtube.com/watch?v=EQWvXpOZZjE "獵食者：日本流行音樂的秘密醜聞")

QEU:FOUNDER ： “確かに根本的な構造は近いですね。ただし、**コレ（↑）は犯罪です**・・・（笑）。”

