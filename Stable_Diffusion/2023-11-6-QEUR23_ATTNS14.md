---
title: QEUR23_ATTNS14: グレースケールからRGBへ
date: 2023-11-6
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "Stable_Diffusion", "Collaborative filtering", "AI art"]
excerpt: T法(2)をテクノメトリックスとして使ったAIアートの最適化
---

## QEUR23_ATTNS14: グレースケールからRGBへ

## ～ RGBで精度はよくなるのか？ ～

QEU:FOUNDER ： “さて、グレースケールを使ったSOART3メトリックスでATTENTIONを計算してみました。ある程度の判別が可能だとわかりましたが、よりINPUT次元数が多くなり精度が高いと思われるRGBではどうなのか？”

![imageJRL3-54-1](/2023-11-6-QEUR23_ATTNS16/imageJRL3-54-1.jpg)

C部長 : “あとはINPUTデータ(words)のN数を上げたいですね。各水準でN=3だと、実際のところはよくわかりません。”

QEU:FOUNDER ： “それでは、RGBによる評価を、N=10でいきましょう。”

![imageJRL3-54-2](/2023-11-6-QEUR23_ATTNS16/imageJRL3-54-2.jpg)

QEU:FOUNDER ： “今回の晒しプログラムは、SOART3メトリックスの計算部分のみです。ドン！！”

```python
# ---------------- 
# 標準パターンファイルを読み込み、SOARTメトリックスを計算する(検証用-RGB)
# ---------------- 
# 数値計算のﾗｲﾌﾞﾗﾘ読み込み
import math
import numpy as np
import copy, random, time
import pandas as pd
# ----------------
import torch
# ---------------- 
import matplotlib.pyplot as plt
#%matplotlib inline

#=================================================
# READ Convolutional CSV FILES
#=================================================
# 畳み込み部品パターンファイルを読み込み
def read_partscsv(file_readcsv, part_idx, part_col): 
 
    # ---------------------------
    # 畳み込み部品パターンファイルの読み込み
    df = pd.read_csv(file_readcsv, header=None) 
    #print(df)
    # ---------------------------
    # 原因系Xs
    mx_Xs = df.iloc[0:part_idx,0:part_col].values
    #print("----- mx_Xs:{0} -----".format(file_readcsv))
    #print(mx_Xs)
  
    return mx_Xs

# 計測対象パターンファイルを読み込み
def read_meascsv(file_readcsv, meas_idx, meas_col): 
 
    # ---------------------------
    # 畳み込み部品パターンファイルの読み込み
    df = pd.read_csv(file_readcsv, header=None) 
    #print(df)
    # ---------------------------
    # 原因系Xs
    mx_Xs = df.iloc[0:meas_idx,0:meas_col].values
    #print("----- mx_Xs:{0} -----".format(file_readcsv))
    #print(mx_Xs)
  
    return mx_Xs

#=================================================
# MAIN PRGRAM
#=================================================
# ---------------- 
# パラメータの定義
# ---------------- 
nam_dir = "./soart/"
nam_partdir = "SOART_PARTS/"
nam_subdir1 = "learn/"
nam_subdir2 = "normal/"
nam_subdir3 = "error/"

# ---------------- 
max_cnv_parts = 7

# ---------------- 
code_cnv_input = ['NA']*max_cnv_parts
code_cnv_input[0] = 'bend1'
code_cnv_input[1] = 'bend2'
code_cnv_input[2] = 'bend3'
code_cnv_input[3] = 'bend4'
code_cnv_input[4] = 'line1'
code_cnv_input[5] = 'line2'
code_cnv_input[6] = 'datum'
print(code_cnv_input)

# ---------------- 
# 畳み込み部品
max_cnv_idx = 5
max_cnv_col = 5

# ---------------- 
# 計測対象
max_meas_idx = 30
max_meas_col = 30

# -------------------------------
# 畳み込み用部品(8種類)を読み込む
for i_cnv in range(max_cnv_parts):    # max_cnv_parts
    # -----
    # 畳み込みファイル
    file_cnv_input = nam_dir + nam_partdir + code_cnv_input[i_cnv] + ".csv"  # ファイルパス名の生成 
    #print(file_cnv_input)
    # -----
    mx_conv = read_partscsv(file_cnv_input, max_cnv_idx, max_cnv_col)
    if i_cnv == 0:    
        tsr_bend1 = torch.tensor(mx_conv).float()
    elif i_cnv == 1:
        tsr_bend2 = torch.tensor(mx_conv).float()
    elif i_cnv == 2:
        tsr_bend3 = torch.tensor(mx_conv).float()
    elif i_cnv == 3:
        tsr_bend4 = torch.tensor(mx_conv).float()
    elif i_cnv == 4:
        tsr_line1 = torch.tensor(mx_conv).float()
    elif i_cnv == 5:
        tsr_line2 = torch.tensor(mx_conv).float()
    elif i_cnv == 6:
        tsr_datum = torch.tensor(mx_conv).float()

# -------------------------------
# 畳み込みカーネルを生成する
kernels = torch.stack([tsr_bend1, tsr_bend2, tsr_bend3, tsr_bend4, tsr_line1, tsr_line2, tsr_datum])
print(kernels)

# -------------------------------
# 標準画像を定義する
# -------------------------------
# [単位空間]image_standard
image_scale = 'image_standard'
#print(image_scale)

# -------------------------------
# 検証用画像(image_validation)のリストを生成する
# -------------------------------
# リストの初期化
list_image = []
# ---
# 検証用-NORMAL-ERROR(A)-ERROR(B)
# ---
# NORMAL
for i in range(10):
    image_name = nam_subdir2+'image_normal_{}'.format(i)
    list_image.append(image_name)
# ---
# ERROR(A)
for i in range(10):
    image_name = nam_subdir3+'image_errorA_{}'.format(i)
    list_image.append(image_name)
# ---
# ERROR(B)
for i in range(10):
    image_name = nam_subdir3+'image_errorB_{}'.format(i)
    list_image.append(image_name)
# リストの統合
print(list_image)


#=================================================
# CONVOLUTION FUNCTIONS
#=================================================
# インスタンス化
L1_loss  = torch.nn.L1Loss()
MSE_loss = torch.nn.MSELoss()

# ---------------- 
# 計測位置の定義
arr_str_idx = [0,5,10,15,20,25]
arr_str_col = [0,5,10,15,20,25]

up_str_idx    = [0,5,10]
down_str_idx  = [15,20,25]
left_str_col  = [0,5,10]
right_str_col = [15,20,25]

max_rtm_idx = 3
max_rtm_col = 3

# ---------------- 
# 畳み込み処理を実施する関数
def apply_kernel(kernel, mx_tensor):
    return (mx_tensor * kernel).sum()

# ---------------- 
# データ範囲を切り出すための関数
def cut_DataArea(str_idx, str_col, max_cnv_idx, max_cnv_col, mx_signal):
    return (mx_signal[str_idx:str_idx+max_cnv_idx,str_col:str_col+max_cnv_col])

###################################
# RT METRICS FUNCTIONS
###################################
# 単位空間を生成する
def create_tani(mx_scaleR, mx_scaleG, mx_scaleB): 

    # ---------------- 
    # 単位空間のリストの定義
    acc_tani_up_left    = [] # マトリックスのリスト
    acc_tani_up_right   = [] # マトリックスのリスト
    acc_tani_down_left  = [] # マトリックスのリスト
    acc_tani_down_right = [] # マトリックスのリスト
    arr_tani_up_left    = [] # 畳み込みのリスト
    arr_tani_up_right   = [] # 畳み込みのリスト
    arr_tani_down_left  = [] # 畳み込みのリスト
    arr_tani_down_right = [] # 畳み込みのリスト

    # ---------------- 
    # RGBマトリックスを累積する
    acc_scale = []
    acc_scale.append(mx_scaleR)
    acc_scale.append(mx_scaleG)
    acc_scale.append(mx_scaleB)

    # ---------------- 
    # 単位空間のデータ範囲の抽出、リスト化
    for i in arr_str_idx:
        for j in arr_str_col:
            for krgb in range(3):
                sign_idx = 'NA'
                sign_col = 'NA'
                mx_cut_tani = cut_DataArea(i, j, max_cnv_idx, max_cnv_col, acc_scale[krgb])
                # テンソル化する
                mx_tsr_tani = torch.tensor(mx_cut_tani).float()
                # ---
                if i in up_str_idx:
                    sign_idx = 'up'
                else:
                    sign_idx = 'down'
                # ---
                if j in left_str_col:
                    sign_col = 'left'
                else:
                    sign_col = 'right'
                # ---
                # リストへの追加
                if sign_idx == 'up' and sign_col == 'left':
                    acc_tani_up_left.append(mx_tsr_tani)
                    temp_arr = []
                    for k in range(7):
                        temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_tani).item(),3))
                    arr_tani_up_left.append(temp_arr)
                # ---
                if sign_idx == 'up' and sign_col == 'right':
                    acc_tani_up_right.append(mx_tsr_tani)
                    temp_arr = []
                    for k in range(7):
                        temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_tani).item(),3))
                    arr_tani_up_right.append(temp_arr)
                # ---
                if sign_idx == 'down' and sign_col == 'left':
                    acc_tani_down_left.append(mx_tsr_tani)
                    temp_arr = []
                    for k in range(7):
                        temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_tani).item(),3))
                    arr_tani_down_left.append(temp_arr)
                # ---
                if sign_idx == 'down' and sign_col == 'right':
                    acc_tani_down_right.append(mx_tsr_tani)
                    temp_arr = []
                    for k in range(7):
                        temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_tani).item(),3))
                    arr_tani_down_right.append(temp_arr)

    ###################################
    # データを束ねて、NUMPY配列に変換する(単位空間：4x63)
    mx_tani_all = []
    # ---
    mx_tani_up_left = np.array(arr_tani_up_left)
    #print(mx_tani_up_left.flatten())
    mx_tani_all.append(mx_tani_up_left.flatten())
    # ---
    mx_tani_up_right = np.array(arr_tani_up_right)
    mx_tani_all.append(mx_tani_up_right.flatten())
    # ---
    mx_tani_down_left = np.array(arr_tani_down_left)
    mx_tani_all.append(mx_tani_down_left.flatten())
    # ---
    mx_tani_down_right = np.array(arr_tani_down_right)
    mx_tani_all.append(mx_tani_down_right.flatten())
    # ---
    mx_tani_all = np.array(mx_tani_all)
    #print(mx_tani_all)
    #print(mx_tani_all.shape)

    return mx_tani_all

```

C部長 : “この関数部分あたり（↑）が、今回の**「グレースケール→RGB」**化で変わったところですね。”

QEU:FOUNDER ： “実はRGB化には2種類のやり方があります。これは、RTメトリックスの原理によるのだが・・・。”

![imageJRL3-54-3](/2023-11-6-QEUR23_ATTNS16/imageJRL3-54-3.jpg)

QEU:FOUNDER ： “RT法は、本来は非線形の挙動を示すデータでも、**標準データを設け、それを信号因子として0点比例式の横軸にする**んです。ですから、グレースケールのデータをRTメトリックスに変換する方法をそのまま使って、RGBデータでもRTメトリックスを生成します。”

C部長 : “今回は、INPUTベクトルの全体をRGBにしたんですか？”

QEU:FOUNDER ： “そうですよ、楽だからね。でも、R,G,BそれそれにRTメトリックスを計算しても、もちろん構いません。もし、こうなると精度は上がるでしょうね。上記は単位空間ですが、もちろん信号空間のRGB化でも同じです。では、続けましょう。”

```python
# ---------------------------
# 信号空間を生成する
def create_signals(mx_measR, mx_measG, mx_measB): 

    # ---------------- 
    # 信号空間のリストの定義
    acc_signal_up_left    = [] # マトリックスのリスト
    acc_signal_up_right   = [] # マトリックスのリスト
    acc_signal_down_left  = [] # マトリックスのリスト
    acc_signal_down_right = [] # マトリックスのリスト
    arr_signal_up_left    = [] # 畳み込みのリスト
    arr_signal_up_right   = [] # 畳み込みのリスト
    arr_signal_down_left  = [] # 畳み込みのリスト
    arr_signal_down_right = [] # 畳み込みのリスト

    # ---------------- 
    # RGBマトリックスを累積する
    acc_meas = []
    acc_meas.append(mx_measR)
    acc_meas.append(mx_measG)
    acc_meas.append(mx_measB)

    # ---------------- 
    # 信号空間のデータ範囲の抽出、リスト
    for i in arr_str_idx:
        for j in arr_str_col:
            for krgb in range(3):
                sign_idx = 'NA'
                sign_col = 'NA'
                mx_cut_signal = cut_DataArea(i, j, max_cnv_idx, max_cnv_col, acc_meas[krgb])     # データを切り出す 
                mx_tsr_signal = torch.tensor(mx_cut_signal).float()     # テンソル化する
                # ---
                if i in up_str_idx:
                    sign_idx = 'up'
                else:
                    sign_idx = 'down'
                # ---
                if j in left_str_col:
                    sign_col = 'left'
                else:
                    sign_col = 'right'
                # ---
                # リストへの追加
                if sign_idx == 'up' and sign_col == 'left':
                    acc_signal_up_left.append(mx_tsr_signal)
                    temp_arr = []
                    for k in range(7):
                        temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_signal).item(),3))
                    arr_signal_up_left.append(temp_arr)
                if sign_idx == 'up' and sign_col == 'right':
                    acc_signal_up_right.append(mx_tsr_signal)
                    temp_arr = []
                    for k in range(7):
                        temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_signal).item(),3))
                    arr_signal_up_right.append(temp_arr)
                if sign_idx == 'down' and sign_col == 'left':
                    acc_signal_down_left.append(mx_tsr_signal)
                    temp_arr = []
                    for k in range(7):
                        temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_signal).item(),3))
                    arr_signal_down_left.append(temp_arr)
                if sign_idx == 'down' and sign_col == 'right':
                    acc_signal_down_right.append(mx_tsr_signal)
                    temp_arr = []
                    for k in range(7):
                        temp_arr.append(round(apply_kernel(kernels[k], mx_tsr_signal).item(),3))
                    arr_signal_down_right.append(temp_arr)

    ###################################
    # データを束ねて、NUMPY配列に変換する(信号空間：4x63)
    mx_signal_all = []
    # ---
    mx_signal_up_left = np.array(arr_signal_up_left)
    #print(mx_signal_up_left.flatten())
    mx_signal_all.append(mx_signal_up_left.flatten())
    # ---
    mx_signal_up_right = np.array(arr_signal_up_right)
    mx_signal_all.append(mx_signal_up_right.flatten())
    # ---
    mx_signal_down_left = np.array(arr_signal_down_left)
    mx_signal_all.append(mx_signal_down_left.flatten())
    # ---
    mx_signal_down_right = np.array(arr_signal_down_right)
    mx_signal_all.append(mx_signal_down_right.flatten())
    # ---
    mx_signal_all = np.array(mx_signal_all)
    #print(mx_signal_all)
    #print(mx_signal_all.shape)

    return mx_signal_all

# ---------------------------
# soaRT(3 items version)メトリックスを計算する
def calc_soaRT3(L1_loss, MSE_loss, tsr_sig_array, tsr_tani_array): 

    # ---------------------------
    # テンソル化
    y = torch.tensor(tsr_sig_array).float()
    x = torch.tensor(tsr_tani_array).float()

    # 回転を計測(BETA)
    xx = torch.dot(x,x) + 0.0001
    xy = torch.dot(x,y) + 0.0001
    beta = xy/xx
    #print("iCmx:{}, beta:{}".format(iCmx, beta))

    # ユーグリッド距離(GAMMA) 
    gamma = MSE_loss(y, beta*x)
    
    # マンハッタン距離(ITA)
    mDistance   = L1_loss(y, beta*x)
    #print("mDistance: ", mDistance.item())
    
    # 値の対数変換（及び補正）
    log_beta  = math.log(beta.item())
    log_distance = math.log(mDistance.item()+1)
    log_gamma = 0.5*math.log(gamma.item()+1) - log_distance
    
    return round(log_beta,3), round(log_distance,3), round(log_gamma,3)

# ---------------------------
# 畳み込みテンソルイメージを生成する
def create_tsrConv(L1_loss, MSE_loss, mx_tani, mx_signal):

    # ----
    # 初期化
    arr_btY1 = []
    arr_snY2 = []
    arr_gmY3 = []

    # ----
    # パネルスコアを線形化する
    for i in range(4):

        tani_array   = mx_tani[i,:]
        signal_array = mx_signal[i,:]
        # soaRT(3 items version)メトリックスを計算する
        btY1, snY2, gmY3 = calc_soaRT3(L1_loss, MSE_loss, signal_array, tani_array)
        arr_btY1.append(btY1)
        arr_snY2.append(snY2)
        arr_gmY3.append(gmY3)

    #print("arr_btY1: ",arr_btY1)
    #print("arr_snY2: ",arr_snY2)
    #print("arr_gmY3: ",arr_gmY3)

    return np.array(arr_btY1),np.array(arr_snY2),np.array(arr_gmY3)


# ==================================================
# MAIN ROUTINE
# ==================================================
# ---------------------------
# 標準画像を読み込む
# ---------------------------
# [単位空間]畳み込みファイル
file_scale_inputR = nam_dir + image_scale + "R.csv"  # ファイルパス名の生成(R)
file_scale_inputG = nam_dir + image_scale + "G.csv"  # ファイルパス名の生成(G)
file_scale_inputB = nam_dir + image_scale + "B.csv"  # ファイルパス名の生成(B)
#print(file_scale_inputR)

# -----
# [単位空間]結果の表示
# Red
mx_scaleR = read_partscsv(file_scale_inputR, max_meas_idx, max_meas_col)
# Green
mx_scaleG = read_partscsv(file_scale_inputG, max_meas_idx, max_meas_col)
# Blue
mx_scaleB = read_partscsv(file_scale_inputB, max_meas_idx, max_meas_col)
#print(mx_scaleB)

# -----
# 単位空間を生成する
mx_tani = create_tani(mx_scaleR, mx_scaleG, mx_scaleB)
#print(mx_tani)
#print(mx_tani.shape)

# ---------------------------
# 検証用画像(image_validation)を読み込む
# ---------------------------
# 読み込み画像の数(image_validation)
max_images = 30

# 初期化
mx_btY1 = np.zeros((max_images,4))
mx_snY2 = np.zeros((max_images,4))
mx_gmY3 = np.zeros((max_images,4))

# <max_images>件の信号空間を読み込み
for i in range(max_images):

    # [信号空間]計測ファイル
    file_meas_inputR = nam_dir + list_image[i] + "R.csv"  # ファイルパス名の生成 
    file_meas_inputG = nam_dir + list_image[i] + "G.csv"  # ファイルパス名の生成 
    file_meas_inputB = nam_dir + list_image[i] + "B.csv"  # ファイルパス名の生成 
    #print(file_meas_inputR)

    # -----
    # [信号空間]検証用画像の結果の表示（mx_measR,G,B）
    mx_measR = read_meascsv(file_meas_inputR, max_meas_idx, max_meas_col)
    mx_measG = read_meascsv(file_meas_inputG, max_meas_idx, max_meas_col)
    mx_measB = read_meascsv(file_meas_inputB, max_meas_idx, max_meas_col)
    #print(mx_measR)

    # -----
    # 信号空間を生成する
    mx_signal = create_signals(mx_measR, mx_measG, mx_measB)
    #print(mx_signal)
    #print(mx_signal.shape)

    # ---------------------------
    # 畳み込みRTイメージを生成する
    # ---------------------------
    arr_btY1, arr_snY2, arr_gmY3 = create_tsrConv(L1_loss, MSE_loss, mx_tani, mx_signal)
    # データを追加する
    mx_btY1[i] = arr_btY1
    mx_snY2[i] = arr_snY2
    mx_gmY3[i] = arr_gmY3
    # ---
    #print("--- {} ---".format(i))
    #print("arr_btY1: ",arr_btY1)
    #print("arr_snY2: ",arr_snY2)
    #print("arr_gmY3: ",arr_gmY3)
# ---
print("--- arr_btY1 ---")
print(mx_btY1)
print("--- arr_snY2 ---")
print(mx_snY2)
print("--- arr_gmY3 ---")
print(mx_gmY3)

# -----
# CSVデータを出力する
# -----
# dataframeに変換
df_btY1 = pd.DataFrame(mx_btY1)
df_snY2 = pd.DataFrame(mx_snY2)
df_gmY3 = pd.DataFrame(mx_gmY3)

# CSVファイルに出力
df_btY1.to_csv('valid_btY1_rgb.csv', index=False)
df_snY2.to_csv('valid_snY2_rgb.csv', index=False)
df_gmY3.to_csv('valid_gmY3_rgb.csv', index=False)

```

QEU:FOUNDER ： “おまちかねの計算結果を見てみましょうよ。ドン！”

**（NORMAL）**

![imageJRL3-54-4](/2023-11-6-QEUR23_ATTNS16/imageJRL3-54-4.jpg)

**(ERROR-A)**

![imageJRL3-54-5](/2023-11-6-QEUR23_ATTNS16/imageJRL3-54-5.jpg)
 
**(ERROR-B)**

![imageJRL3-54-6](/2023-11-6-QEUR23_ATTNS16/imageJRL3-54-6.jpg)

C部長 : “すんません、わすれました・・・。表の横軸（「列」）ってなんでしたっけ？”

QEU:FOUNDER ： “**INPUTデータが変わっている**んです。”

### INPUT(1): Y1（β：感度）のMAX-MIN値（要素アドレスも併記してます）
### INPUT(2): Y2(η:SN比)の同上
### INPUT(3): Y3(γ:データ体積比)の同上

C部長 : “あくまで「大まか」にいうと、NORMAL画像群とERROR-A画像群の間には、Y2(η:SN比)の符号(+/-)に差異がありますね。”

QEU:FOUNDER ： “同時に、NORMAL画像群とERROR-B画像群の間には、Y1（β：感度）の符号に差異がありますね。一方、Y3(γ:データ体積比)の挙動はより複雑ですね。もしIF文による簡単なロジックを設けて、大体70％ぐらいかなぁ・・・。異常検出力は・・・。C部長は、この程度の検出力でも工場に導入したい？”

C部長 : “これだけ低いリソース（コスト）、かつ楽ちんな定義でもそこそこ判別できるのであれば、「流出防止用」ではなく「参考用」として使うのはいいんじゃないですか？ものすごく低コストだし・・・。あれ・・・、**全工程の加工の前に材料確認用の検査機を設けるといい**んじゃないでしょうか。”

QEU:FOUNDER ： “そうなんだよね・・・。高価な検査機を最終工程に置くのは下策です。このお方（↓）の**「逐次検査(successive inspection)」**の考え方によればね。”

![imageJRL3-54-7](/2023-11-6-QEUR23_ATTNS16/imageJRL3-54-7.jpg)

C部長 : “以前、FOUNDERが調査してくれました。昔の時代の実績ですが、**逐次検査体制を導入することにより流出不良は3分の1まで低くなった**のですよね。”

QEU:FOUNDER ： “まあ、彼（↑）の時代の実績だからね。この効果を「うのみ」にはできない。それでも、シール貼りなんかは、いまでも自動化はできないので効果はあるんじゃなかなぁ・・・。”

C部長 : “つづいて、Q,K,Vマトリックスの中のメンバを変えてみたら、どうなるんでしょうかねえ？”

QEU:FOUNDER ： “やっぱり、それが気になるよね。それでは、Q,K,Vマトリックスを変えてみましょう。現在、一歩一歩前進中。是非、カンパをお願いします！！”

### [＞寄付のお願い(click here)＜](<iframe width="560" height="315" src="https://www.youtube.com/embed/9NVQnJu23Mo?si=MZIRhc0RwThRO5EQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>)

D先生 ： “よろしくお願いします。”


## ～ まとめ ～

QEU:FOUNDER(設定年齢65歳) ： “ああ・・・。失敗したわ・・・。前回は、このトリヲを持ち上げたのだが、やはり議論に**「幅がなかった」**かなぁ・・・。”

[![MOVIE1](http://img.youtube.com/vi/SUJsvJJXJh8/0.jpg)](http://www.youtube.com/watch?v=SUJsvJJXJh8 "Before生成AI ＆ After 生成AI【児玉龍彦×辻野晃一郎×金子勝の未来への対話】")

D先生(設定年齢65歳) ： “議論に「深み」はあるんですけどね・・・。じゃあ、FOUNDERにｔって、何が「（議論の）幅」に当たるんですか？“

[![MOVIE2](http://img.youtube.com/vi/-mLu7o7biJU/0.jpg)](http://www.youtube.com/watch?v=-mLu7o7biJU "居港日裔茶記達人帶你新界搵食！精選3間特色店 入八鄉、古洞、流浮山 拜訪私藏隱世茶餐廳！八鄉巨型特飲 流浮山炸雲吞")

D先生 ： “うっ、ん～！？**なんじゃ、コイツは・・・！？**“

QEU:FOUNDER(設定年齢65歳) ： “すごいでしょ？この人・・・（笑）。（笑）って、あまりのスゴさに「笑うしかない」のよ・・・。”

D先生 ： “10年前に海外のとある地方に移住し、６畳一間の部屋に１０年暮らす。彼は、**その地方特色のレストランが気に入り**、毎日最低１回は通っている。多い時には６回、そのレストランで食べる。そして、根っからの**バス好き**であり、地域内の「ありとあらゆる（その種の）レストラン」に通っており、そこで体験した内容をすべてメモにとっている。そして、そのレストランに関する知識は、本土人の知識をすでに**「はるかに超えている」**・・・。えっと・・・、いわゆる「オタク」ですよね。“

QEU:FOUNDER ： “**先ほどの御三人の議論には「オタクの役割」が抜けています**。単に供給側の創造性のみを論じています。しかし、J国に関する限り、**消費側に関しても創造はあります**。オタクの存在って、J国独特の創造のチャンネルなんです。”

D先生 ： “私は、オタクって「病理現象」だと思っていました（笑）。“

QEU:FOUNDER ： “特定のメディアの見過ぎでしょ？彼らは。モラルハラスメントのレンズからみると、あきらかに「バランスを崩した人」ですからね。でも、現実のところ、このような**「創造的消費者」たち**が世の中を発展させるんです。”

### おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」
### オッサン（＠車中、N社検査不正について）： 「“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ・・・」
### オッサン（海外工場のあいさつにて）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」

D先生 ： “そういえば、最近はオタクを無視している傾向があるわ・・・。「ちゃんとしてない人たち」だって・・・。“

QEU:FOUNDER ： “**「ちゃんとしている」という日本語の本質は、「周囲の期待に応える」という意味**だからね。モラルハラスメントそのもの・・・。これから、「何かをしたい」というプラスのエネルギーを伸ばしていきたいのであれば、まずは**「オタクというマイノリティ」を育てて行かなければならない**。”

D先生 ： “う～ん、（いいたいことは）よくわかる。でも、それでいいんかなぁ・・・。 “

