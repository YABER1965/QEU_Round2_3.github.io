---
title: QEUR23_LMABYS0:　INTRODUCTION～実際に使ってみたいね、LLM・・・
date: 2023-05-17
tags: ["QEUシステム", "メトリックス", "Python言語", "T法(2)", "LLM", "大規模言語モデル", "LangChain", "LlaMaIndex"]
excerpt: 大規模言語モデル(LLM)を活用する
---
## QEUR23_LMABYS0:　INTRODUCTION～実際に使ってみたいね、LLM・・・

## ～　現在進行形のイノベーションを実感したい　～

### ・・・ FOUNDERは、またまた気が変わり ・・・・

QEU:FOUNDER ： “**大規模言語モデル(LLM)**を使って、ちょっと遊んでみましょうか・・・。”

D先生 ： “あれ？Stable_Diffusionを続けるんじゃなかったんでしたっけ？確かに、前回で**Embeddingの代わりにT法メトリックスを使うというテストに成功した**ので、一区切りはついたとは言えますが・・・。”

![imageJRL4-1-1](/2023-05-17-QEUR23_LMABYS0/imageJRL4-1-1.jpg)

C部長： “以前、FOUNDERはボクに**「コンサルタントの代わりになる大言語モデルがあるといいなぁ」**といっていました。あと、GPTはQEUラウンド2.3の目指す方向(↑)にもあっているといえます。ちなみに**「高齢者によるイノベーション」は続いています**。高齢者の皆さま、いまイノベーションしてますか？”

QEU:FOUNDER ： “結局、小生も、今、世の中に渦巻いている**大きなイノベーションの渦を覗き込みたい**と思っているのでね。まあ、取り組む順序を少しだけ組み替えたと考えてくださいな・・・。Stable_Diffusionの特性を理解したとき、やはりテキスト処理も触れておきたいと思ったんです。”

**(Stable_Diffusion事例のプロンプト)**

### prompt   = '((1girl:1.3),blue eye,in style of {0},standing,looking at viewer), (beach, in style of {1}:1.1),　などなど ' 

***ここで、{0}と{1}にアーティスト名がつく***

QEU:FOUNDER ： “とある勉強会（↓）に参加し、思う所があった。”

[![MOVIE1](http://img.youtube.com/vi/PFPIZZQVjOM/0.jpg)](http://www.youtube.com/watch?v=PFPIZZQVjOM "【2023/02/09】【論文解説】Stable Diffusion 画像生成のしくみを解説")


D先生 ： “う～ん・・・。説明がとても丁寧・・・。この勉強会の説明は分かりやすいですね。海外のYoutubeのレクチャーを見ても、これほどうまく説明されていません。ちょっと持ち上げすぎ（笑）？”

![imageJRL4-1-2](/2023-05-17-QEUR23_LMABYS0/imageJRL4-1-2.jpg)

QEU:FOUNDER ： “Stable_Diffusionはいくつかのモジュールが組み合わさってできています。そのうち、我々がかかわってきたのテキスト関連の作業は、Text Encoderが担当しています。ユーザーが入力したテキスト（プロンプト）をベクトルに分解して、Denoising Autoencoderに入力するんですね。”

D先生 ： “この「ベクトルを入力する」というのが重要です。何なんですかね、これ（ベクトル）は・・・。そういえば、このシステムも「例のAttention(Transformer)の技術」を使っているんでしょ？”

![imageJRL4-1-3](/2023-05-17-QEUR23_LMABYS0/imageJRL4-1-3.jpg)

QEU:FOUNDER ： “そう・・・。拡散処理で画像を生成するためには**「KeyとValue」というペアで構成されたベクトル**が必要になります。つまり、「array=[(key,value),(key,value),…(key,value)]」みたいな・・・。”

D先生 ： “あっ！その（key,value）って、テキストの**Embeddingの事**でしょ？”

QEU:FOUNDER ： “そう・・・。我々はいままで、**テキストをそのまま使ってT法による分析**しようとしていました。でもね、それって本質的な意味があるのかな？・・・というわけで、一回休みだ！！GPTをやろう！とても小さなヤツを・・・。”

![imageJRL4-1-4](/2023-05-17-QEUR23_LMABYS0/imageJRL4-1-4.jpg)

D先生 ： “モデルの大きさはどのくらい？30GBぐらいですか？ ”

QEU:FOUNDER ： “**普通は３～４GBの間ですよね**。”

D先生 ： “そんなに小さいの？”

QEU:FOUNDER ： “もともとLlaMaベースなので小さいのに加え、**「量子化(Quantization)」**という技術を使ってさらに小さくしています。”

[![MOVIE1](http://img.youtube.com/vi/mii-xFaPCrA/0.jpg)](http://www.youtube.com/watch?v=mii-xFaPCrA "LLaMa GPTQ 4-Bit Quantization. Billions of Parameters Made Smaller and Smarter. How Does it Work?")

D先生 ： “量子化って、どんなマジックなんです？”

![imageJRL4-1-5](/2023-05-17-QEUR23_LMABYS0/imageJRL4-1-5.jpg)

QEU:FOUNDER ： “普通に考えると、ニューラルネットの重みの値は小数点付きの値になっているはずですよね。それを**整数値に変換した**んです！そうすれば、当然ながら**デジタル情報量は一気に小さくなります**。詳しくは、自分で勉強してください。小生としては、（詳細は知らなくとも）使えればいいんで・・・（笑）。じゃあ、いきなりGPT4ALL（GPT for all）という、パソコンでも動くGPTをやってみましょう。”

![imageJRL4-1-6](/2023-05-17-QEUR23_LMABYS0/imageJRL4-1-6.jpg)

D先生 ： “おおっ・・・。GPTさんが自分で（必要PCスペックを）白状しております・・・（笑）。”

QEU:FOUNDER ： “Windowsの場合、**インストーラ付きのアプリがあるのでGPT4Allを使うのはカンタン**です。5年前以内のモデルのパソコンに5GBぐらい余裕があれば遊べます。でも、我々の場合、Pythonでも動かしたいのでやってみました。それではプログラムをドン！！”

```python
from pygpt4all.models.gpt4all_j import GPT4All_J

model = GPT4All_J('D:./ggml-gpt4all-j-v1.3-groovy.bin')
# -----
question = "Please advise some sightseeing place in London."

for token in model.generate(question):
    print(token, end='', flush=True)
```

QEU:FOUNDER ： “ちょっとロンドンについて聞いてみました。このプロジェクトはE国のものらしいので・・・。”

![imageJRL4-1-7](/2023-05-17-QEUR23_LMABYS0/imageJRL4-1-7.jpg)

D先生 ： “へえ・・・。Pythonでも動くとは便利だ・・・。”

QEU:FOUNDER ： “・・・言っておくけど、Python版はアプリよりも反応が遅いよ。それは、ある意味しょうがないけどね。あと、小生の苦い経験を白状すると、これが動くまでに**多量のトライ・エラー**がありました。モデルによって使うべきインスタンスが違う（GPTAll or GPTAll_J）というノウハウがわからなかったんです。あと、これだけ頻繁にバージョンが変わっていますので、率直にいって今回晒したプログラムとモデルの相性も将来どうなるかもわかりません。”

D先生 ： “まあ、（GPTがPC上で）動くことが分かっただけでも、重大な一歩ですね。”

QEU:FOUNDER ： “次から、このプロジェクトが少しづつ多様化していきます。是非、カンパをください・・・。”

### [＞寄付のお願い(click here)＜](
https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-created&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038
)

D先生 ： “そういえば、**ノウハウをGPTに注入したい**んでしたっけ・・・。”


## ～　まとめ　～

C部長 : “すいません。ボクから質問です。GPT4Allって**J国語は使えます**か？”

![imageJRL4-1-8](/2023-05-17-QEUR23_LMABYS0/imageJRL4-1-8.jpg)

QEU:FOUNDER ： “本人(?)に聞いてみました。まだ苦手なようですよ。それでも、**だれかが(J語化を)やる**んじゃないかな？”

C部長 : “**オープン・ソース化**の威力はすごいですね。”

QEU:FOUNDER ： “技術をイノベーションさせるには、オープンソースが一番です。技術を**周回遅れ**させたいのであれば、**「家元制」が一番**・・・。”
